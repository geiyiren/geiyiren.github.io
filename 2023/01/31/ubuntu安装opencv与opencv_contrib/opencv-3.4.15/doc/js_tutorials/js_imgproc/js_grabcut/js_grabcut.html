<h1 id="Foreground-Extraction-using-GrabCut-Algorithm-tutorial-js-grabcut"><a href="#Foreground-Extraction-using-GrabCut-Algorithm-tutorial-js-grabcut" class="headerlink" title="Foreground Extraction using GrabCut Algorithm {#tutorial_js_grabcut}"></a>Foreground Extraction using GrabCut Algorithm {#tutorial_js_grabcut}</h1><h2 id="Goal"><a href="#Goal" class="headerlink" title="Goal"></a>Goal</h2><ul>
<li>We will learn GrabCut algorithm to extract foreground in images</li>
</ul>
<h2 id="Theory"><a href="#Theory" class="headerlink" title="Theory"></a>Theory</h2><p>GrabCut algorithm was designed by Carsten Rother, Vladimir Kolmogorov &amp; Andrew Blake from Microsoft<br>Research Cambridge, UK. in their paper, <a href="http://dl.acm.org/citation.cfm?id=1015720">“GrabCut”: interactive foreground extraction using iterated<br>graph cuts</a> . An algorithm was needed for foreground<br>extraction with minimal user interaction, and the result was GrabCut.</p>
<p>How it works from user point of view ? Initially user draws a rectangle around the foreground region<br>(foreground region should be completely inside the rectangle). Then algorithm segments it<br>iteratively to get the best result. Done. But in some cases, the segmentation won’t be fine, like,<br>it may have marked some foreground region as background and vice versa. In that case, user need to<br>do fine touch-ups. Just give some strokes on the images where some faulty results are there. Strokes<br>basically says <em>“Hey, this region should be foreground, you marked it background, correct it in next<br>iteration”</em> or its opposite for background. Then in the next iteration, you get better results.</p>
<p>What happens in background ?</p>
<ul>
<li>User inputs the rectangle. Everything outside this rectangle will be taken as sure background<br>(That is the reason it is mentioned before that your rectangle should include all the<br>objects). Everything inside rectangle is unknown. Similarly any user input specifying<br>foreground and background are considered as hard-labelling which means they won’t change in<br>the process.</li>
<li>Computer does an initial labelling depending on the data we gave. It labels the foreground and<br>background pixels (or it hard-labels)</li>
<li>Now a Gaussian Mixture Model(GMM) is used to model the foreground and background.</li>
<li>Depending on the data we gave, GMM learns and create new pixel distribution. That is, the<br>unknown pixels are labelled either probable foreground or probable background depending on its<br>relation with the other hard-labelled pixels in terms of color statistics (It is just like<br>clustering).</li>
<li>A graph is built from this pixel distribution. Nodes in the graphs are pixels. Additional two<br>nodes are added, <strong>Source node</strong> and <strong>Sink node</strong>. Every foreground pixel is connected to<br>Source node and every background pixel is connected to Sink node.</li>
<li>The weights of edges connecting pixels to source node&#x2F;end node are defined by the probability<br>of a pixel being foreground&#x2F;background. The weights between the pixels are defined by the edge<br>information or pixel similarity. If there is a large difference in pixel color, the edge<br>between them will get a low weight.</li>
<li>Then a mincut algorithm is used to segment the graph. It cuts the graph into two separating<br>source node and sink node with minimum cost function. The cost function is the sum of all<br>weights of the edges that are cut. After the cut, all the pixels connected to Source node<br>become foreground and those connected to Sink node become background.</li>
<li>The process is continued until the classification converges.</li>
</ul>
<p>It is illustrated in below image (Image Courtesy: <a href="http://www.cs.ru.ac.za/research/g02m1682/">http://www.cs.ru.ac.za/research/g02m1682/</a>)</p>
<p><img src="/images/grabcut_scheme.jpg" alt="image"></p>
<h2 id="Demo"><a href="#Demo" class="headerlink" title="Demo"></a>Demo</h2><p>We use the function: <strong>cv.grabCut (image, mask, rect, bgdModel, fgdModel, iterCount, mode &#x3D; cv.GC_EVAL)</strong></p>
<p>@param image      input 8-bit 3-channel image.<br>@param mask       input&#x2F;output 8-bit single-channel mask. The mask is initialized by the function when mode is set to GC_INIT_WITH_RECT. Its elements may have one of the cv.rabCutClasses.<br>@param rect       ROI containing a segmented object. The pixels outside of the ROI are marked as “obvious background”. The parameter is only used when mode&#x3D;&#x3D;GC_INIT_WITH_RECT.<br>@param bgdModel   temporary array for the background model. Do not modify it while you are processing the same image.<br>@param fgdModel   temporary arrays for the foreground model. Do not modify it while you are processing the same image.<br>@param iterCount  number of iterations the algorithm should make before returning the result. Note that the result can be refined with further calls with mode&#x3D;&#x3D;GC_INIT_WITH_MASK or mode&#x3D;&#x3D;GC_EVAL .<br>@param mode       operation mode that could be one of the cv::GrabCutModes</p>
<h2 id="Try-it"><a href="#Try-it" class="headerlink" title="Try it"></a>Try it</h2><p>\htmlonly</p>
<iframe src="../../js_grabcut_grabCut.html" width="100%"
        onload="this.style.height=this.contentDocument.body.scrollHeight +'px';">
</iframe>
\endhtmlonly