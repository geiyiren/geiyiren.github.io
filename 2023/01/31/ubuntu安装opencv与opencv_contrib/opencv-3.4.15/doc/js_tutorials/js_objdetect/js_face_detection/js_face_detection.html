<h1 id="Face-Detection-using-Haar-Cascades-tutorial-js-face-detection"><a href="#Face-Detection-using-Haar-Cascades-tutorial-js-face-detection" class="headerlink" title="Face Detection using Haar Cascades {#tutorial_js_face_detection}"></a>Face Detection using Haar Cascades {#tutorial_js_face_detection}</h1><h2 id="Goal"><a href="#Goal" class="headerlink" title="Goal"></a>Goal</h2><ul>
<li>learn the basics of face detection using Haar Feature-based Cascade Classifiers</li>
<li>extend the same for eye detection etc.</li>
</ul>
<h2 id="Basics"><a href="#Basics" class="headerlink" title="Basics"></a>Basics</h2><p>Object Detection using Haar feature-based cascade classifiers is an effective method proposed by Paul Viola and Michael Jones in the 2001 paper, “Rapid Object Detection using a<br>Boosted Cascade of Simple Features”. It is a machine learning based approach in which a cascade<br>function is trained from a lot of positive and negative images. It is then used to detect objects in<br>other images.</p>
<p>Here we will work with face detection. Initially, the algorithm needs a lot of positive images<br>(images of faces) and negative images (images without faces) to train the classifier. Then we need<br>to extract features from it. For this, Haar features shown in below image are used. They are just<br>like our convolutional kernel. Each feature is a single value obtained by subtracting the sum of pixels<br>under the white rectangle from the sum of pixels under the black rectangle.</p>
<p><img src="/images/haar_features.jpg" alt="image"></p>
<p>Now all possible sizes and locations of each kernel are used to calculate plenty of features. For each<br>feature calculation, we need to find the sum of the pixels under the white and black rectangles. To solve this,<br>they introduced the integral images. It simplifies calculation of the sum of the pixels, how large may be<br>the number of pixels, to an operation involving just four pixels.</p>
<p>But among all these features we calculated, most of them are irrelevant. For example, consider the<br>image below. Top row shows two good features. The first feature selected seems to focus on the<br>property that the region of the eyes is often darker than the region of the nose and cheeks. The<br>second feature selected relies on the property that the eyes are darker than the bridge of the nose.<br>But the same windows applying on cheeks or any other place is irrelevant. So how do we select the<br>best features out of 160000+ features? It is achieved by <strong>Adaboost</strong>.</p>
<p><img src="/images/haar.png" alt="image"></p>
<p>For this, we apply each and every feature on all the training images. For each feature, it finds the<br>best threshold which will classify the faces to positive and negative. But obviously, there will be<br>errors or misclassifications. We select the features with minimum error rate, which means they are<br>the features that best classifies the face and non-face images. (The process is not as simple as<br>this. Each image is given an equal weight in the beginning. After each classification, weights of<br>misclassified images are increased. Then again same process is done. New error rates are calculated.<br>Also new weights. The process is continued until required accuracy or error rate is achieved or<br>required number of features are found).</p>
<p>Final classifier is a weighted sum of these weak classifiers. It is called weak because it alone<br>can’t classify the image, but together with others forms a strong classifier. The paper says even<br>200 features provide detection with 95% accuracy. Their final setup had around 6000 features.<br>(Imagine a reduction from 160000+ features to 6000 features. That is a big gain).</p>
<p>So now you take an image. Take each 24x24 window. Apply 6000 features to it. Check if it is face or<br>not. Wow.. Wow.. Isn’t it a little inefficient and time consuming? Yes, it is. Authors have a good<br>solution for that.</p>
<p>In an image, most of the image region is non-face region. So it is a better idea to have a simple<br>method to check if a window is not a face region. If it is not, discard it in a single shot. Don’t<br>process it again. Instead focus on region where there can be a face. This way, we can find more time<br>to check a possible face region.</p>
<p>For this they introduced the concept of <strong>Cascade of Classifiers</strong>. Instead of applying all the 6000<br>features on a window, group the features into different stages of classifiers and apply one-by-one.<br>(Normally first few stages will contain very less number of features). If a window fails the first<br>stage, discard it. We don’t consider remaining features on it. If it passes, apply the second stage<br>of features and continue the process. The window which passes all stages is a face region. How is<br>the plan !!!</p>
<p>Authors’ detector had 6000+ features with 38 stages with 1, 10, 25, 25 and 50 features in first five<br>stages. (Two features in the above image is actually obtained as the best two features from<br>Adaboost). According to authors, on an average, 10 features out of 6000+ are evaluated per<br>sub-window.</p>
<p>So this is a simple intuitive explanation of how Viola-Jones face detection works. Read paper for<br>more details.</p>
<h2 id="Haar-cascade-Detection-in-OpenCV"><a href="#Haar-cascade-Detection-in-OpenCV" class="headerlink" title="Haar-cascade Detection in OpenCV"></a>Haar-cascade Detection in OpenCV</h2><p>Here we will deal with detection. OpenCV already contains many pre-trained classifiers for face,<br>eyes, smile etc. Those XML files are stored in opencv&#x2F;data&#x2F;haarcascades&#x2F; folder. Let’s create a face<br>and eye detector with OpenCV.</p>
<p>We use the function: <strong>detectMultiScale (image, objects, scaleFactor &#x3D; 1.1, minNeighbors &#x3D; 3, flags &#x3D; 0, minSize &#x3D; new cv.Size(0, 0), maxSize &#x3D; new cv.Size(0, 0))</strong></p>
<p>@param image               matrix of the type CV_8U containing an image where objects are detected.<br>@param objects             vector of rectangles where each rectangle contains the detected object. The rectangles may be partially outside the original image.<br>@param scaleFactor         parameter specifying how much the image size is reduced at each image scale.<br>@param minNeighbors        parameter specifying how many neighbors each candidate rectangle should have to retain it.<br>@param flags               parameter with the same meaning for an old cascade as in the function cvHaarDetectObjects. It is not used for a new cascade.<br>@param minSize             minimum possible object size. Objects smaller than this are ignored.<br>@param maxSize             maximum possible object size. Objects larger than this are ignored. If maxSize &#x3D;&#x3D; minSize model is evaluated on single scale.</p>
<p>@note Don’t forget to delete CascadeClassifier and RectVector!</p>
<h2 id="Try-it"><a href="#Try-it" class="headerlink" title="Try it"></a>Try it</h2><p>Try this demo using the code above. Canvas elements named haarCascadeDetectionCanvasInput and haarCascadeDetectionCanvasOutput have been prepared. Choose an image and<br>click <code>Try it</code> to see the result. You can change the code in the textbox to investigate more.</p>
<p>\htmlonly</p>
<iframe src="../../js_face_detection.html" width="100%"
        onload="this.style.height=this.contentDocument.body.scrollHeight +'px';">
</iframe>
\endhtmlonly