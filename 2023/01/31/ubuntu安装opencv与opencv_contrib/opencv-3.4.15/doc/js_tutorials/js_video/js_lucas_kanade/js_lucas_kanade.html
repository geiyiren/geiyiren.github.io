<h1 id="Optical-Flow-tutorial-js-lucas-kanade"><a href="#Optical-Flow-tutorial-js-lucas-kanade" class="headerlink" title="Optical Flow {#tutorial_js_lucas_kanade}"></a>Optical Flow {#tutorial_js_lucas_kanade}</h1><h2 id="Goal"><a href="#Goal" class="headerlink" title="Goal"></a>Goal</h2><ul>
<li>We will understand the concepts of optical flow and its estimation using Lucas-Kanade<br>method.</li>
<li>We will use functions like <strong>cv.calcOpticalFlowPyrLK()</strong> to track feature points in a<br>video.</li>
</ul>
<h2 id="Optical-Flow"><a href="#Optical-Flow" class="headerlink" title="Optical Flow"></a>Optical Flow</h2><p>Optical flow is the pattern of apparent motion of image objects between two consecutive frames<br>caused by the movement of object or camera. It is 2D vector field where each vector is a<br>displacement vector showing the movement of points from first frame to second. Consider the image<br>below (Image Courtesy: <a href="http://en.wikipedia.org/wiki/Optical_flow">Wikipedia article on Optical<br>Flow</a>).</p>
<p><img src="/images/optical_flow_basic1.jpg" alt="image"></p>
<p>It shows a ball moving in 5 consecutive frames. The arrow shows its displacement vector. Optical<br>flow has many applications in areas like :</p>
<ul>
<li>Structure from Motion</li>
<li>Video Compression</li>
<li>Video Stabilization ‚Ä¶</li>
</ul>
<p>Optical flow works on several assumptions:</p>
<p>-#  The pixel intensities of an object do not change between consecutive frames.<br>2.  Neighbouring pixels have similar motion.</p>
<p>Consider a pixel \f$I(x,y,t)\f$ in first frame (Check a new dimension, time, is added here. Earlier we<br>were working with images only, so no need of time). It moves by distance \f$(dx,dy)\f$ in next frame<br>taken after \f$dt\f$ time. So since those pixels are the same and intensity does not change, we can say,</p>
<p>\f[I(x,y,t) &#x3D; I(x+dx, y+dy, t+dt)\f]</p>
<p>Then take taylor series approximation of right-hand side, remove common terms and divide by \f$dt\f$ to<br>get the following equation:</p>
<p>\f[f_x u + f_y v + f_t &#x3D; 0 ;\f]</p>
<p>where:</p>
<p>\f[f_x &#x3D; \frac{\partial f}{\partial x} ; ; ; f_y &#x3D; \frac{\partial f}{\partial y}\f]\f[u &#x3D; \frac{dx}{dt} ; ; ; v &#x3D; \frac{dy}{dt}\f]</p>
<p>Above equation is called Optical Flow equation. In it, we can find \f$f_x\f$ and \f$f_y\f$, they are image<br>gradients. Similarly \f$f_t\f$ is the gradient along time. But \f$(u,v)\f$ is unknown. We cannot solve this<br>one equation with two unknown variables. So several methods are provided to solve this problem and<br>one of them is Lucas-Kanade.</p>
<h3 id="Lucas-Kanade-method"><a href="#Lucas-Kanade-method" class="headerlink" title="Lucas-Kanade method"></a>Lucas-Kanade method</h3><p>We have seen an assumption before, that all the neighbouring pixels will have similar motion.<br>Lucas-Kanade method takes a 3x3 patch around the point. So all the 9 points have the same motion. We<br>can find \f$(f_x, f_y, f_t)\f$ for these 9 points. So now our problem becomes solving 9 equations with<br>two unknown variables which is over-determined. A better solution is obtained with least square fit<br>method. Below is the final solution which is two equation-two unknown problem and solve to get the<br>solution.</p>
<p>\f[\begin{bmatrix} u \ v \end{bmatrix} &#x3D;<br>\begin{bmatrix}<br>    \sum_{i}{f_{x_i}}^2  &amp;  \sum_{i}{f_{x_i} f_{y_i} } \<br>    \sum_{i}{f_{x_i} f_{y_i}} &amp; \sum_{i}{f_{y_i}}^2<br>\end{bmatrix}^{-1}<br>\begin{bmatrix}<br>    - \sum_{i}{f_{x_i} f_{t_i}} \<br>    - \sum_{i}{f_{y_i} f_{t_i}}<br>\end{bmatrix}\f]</p>
<p>( Check similarity of inverse matrix with Harris corner detector. It denotes that corners are better<br>points to be tracked.)</p>
<p>So from user point of view, idea is simple, we give some points to track, we receive the optical<br>flow vectors of those points. But again there are some problems. Until now, we were dealing with<br>small motions. So it fails when there is large motion. So again we go for pyramids. When we go up in<br>the pyramid, small motions are removed and large motions becomes small motions. So applying<br>Lucas-Kanade there, we get optical flow along with the scale.</p>
<h2 id="Lucas-Kanade-Optical-Flow-in-OpenCV-js"><a href="#Lucas-Kanade-Optical-Flow-in-OpenCV-js" class="headerlink" title="Lucas-Kanade Optical Flow in OpenCV.js"></a>Lucas-Kanade Optical Flow in OpenCV.js</h2><p>We use the function: <strong>cv.calcOpticalFlowPyrLK (prevImg, nextImg, prevPts, nextPts, status, err, winSize &#x3D;<br>new cv.Size(21, 21), maxLevel &#x3D; 3, criteria &#x3D; new cv.TermCriteria(cv.TermCriteria_COUNT+<br>cv.TermCriteria_EPS, 30, 0.01), flags &#x3D; 0, minEigThreshold &#x3D; 1e-4)</strong>.<br>@param prevImg          first 8-bit input image or pyramid constructed by buildOpticalFlowPyramid.<br>@param nextImg          second input image or pyramid of the same size and the same type as prevImg.<br>@param prevPts          vector of 2D points for which the flow needs to be found; point coordinates must<br>be single-precision floating-point numbers.<br>@param nextPts          output vector of 2D points (with single-precision floating-point coordinates)<br>containing the calculated new positions of input features in the second image; when cv.OPTFLOW_USE_<br>INITIAL_FLOW flag is passed, the vector must have the same size as in the input.<br>@param status           output status vector (of unsigned chars); each element of the vector is set to 1<br>if the flow for the corresponding features has been found, otherwise, it is set to 0.<br>@param err              output vector of errors; each element of the vector is set to an error for the<br>corresponding feature, type of the error measure can be set in flags parameter; if the flow wasn‚Äôt<br>found then the error is not defined (use the status parameter to find such cases).<br>@param winSize          size of the search window at each pyramid level.<br>@param maxLevel         0-based maximal pyramid level number; if set to 0, pyramids are not used (single<br>level), if set to 1, two levels are used, and so on; if pyramids are passed to input then algorithm<br>will use as many levels as pyramids have but no more than maxLevel.<br>@param criteria         parameter, specifying the termination criteria of the iterative search algorithm<br>(after the specified maximum number of iterations criteria.maxCount or when the search window moves<br>by less than criteria.epsilon.<br>@param flags            operation flags:</p>
<ul>
<li>cv.OPTFLOW_USE_INITIAL_FLOW uses initial estimations, stored in nextPts; if the flag is not set,<br>then prevPts is copied to nextPts and is considered the initial estimate.</li>
<li>cv.OPTFLOW_LK_GET_MIN_EIGENVALS use minimum eigen values as an error measure (see minEigThreshold<br>description); if the flag is not set, then L1 distance between patches around the original and a moved<br>point, divided by number of pixels in a window, is used as a error measure.<br>@param minEigThreshold  the algorithm calculates the minimum eigen value of a 2x2 normal matrix of<br>optical flow equations, divided by number of pixels in a window; if this value is less than<br>minEigThreshold, then a corresponding feature is filtered out and its flow is not processed, so it<br>allows to remove bad points and get a performance boost.</li>
</ul>
<h3 id="Try-it"><a href="#Try-it" class="headerlink" title="Try it"></a>Try it</h3><p>\htmlonly</p>
<iframe src="../../js_optical_flow_lucas_kanade.html" width="100%"
        onload="this.style.height=this.contentDocument.body.scrollHeight +'px';">
</iframe>
\endhtmlonly

<p>(This code doesn‚Äôt check how correct are the next keypoints. So even if any feature point disappears<br>in image, there is a chance that optical flow finds the next point which may look close to it. So<br>actually for a robust tracking, corner points should be detected in particular intervals.)</p>
<h2 id="Dense-Optical-Flow-in-OpenCV-js"><a href="#Dense-Optical-Flow-in-OpenCV-js" class="headerlink" title="Dense Optical Flow in OpenCV.js"></a>Dense Optical Flow in OpenCV.js</h2><p>Lucas-Kanade method computes optical flow for a sparse feature set (in our example, corners detected<br>using Shi-Tomasi algorithm). OpenCV.js provides another algorithm to find the dense optical flow. It<br>computes the optical flow for all the points in the frame. It is based on Gunner Farneback‚Äôs<br>algorithm which is explained in ‚ÄúTwo-Frame Motion Estimation Based on Polynomial Expansion‚Äù by<br>Gunner Farneback in 2003.</p>
<p>We use the function: <strong>cv.calcOpticalFlowFarneback (prev, next, flow, pyrScale, levels, winsize,<br>iterations, polyN, polySigma, flags)</strong><br>@param prev        first 8-bit single-channel input image.<br>@param next        second input image of the same size and the same type as prev.<br>@param flow        computed flow image that has the same size as prev and type CV_32FC2.<br>@param pyrScale    parameter, specifying the image scale (&lt;1) to build pyramids for each image;<br>pyrScale&#x3D;0.5 means a classical pyramid, where each next layer is twice smaller than the previous one.<br>@param levels      number of pyramid layers including the initial image; levels&#x3D;1 means that no extra<br>layers are created and only the original images are used.<br>@param winsize     averaging window size; larger values increase the algorithm robustness to image noise<br>and give more chances for fast motion detection, but yield more blurred motion field.<br>@param iterations  number of iterations the algorithm does at each pyramid level.<br>@param polyN       size of the pixel neighborhood used to find polynomial expansion in each pixel; larger<br>values mean that the image will be approximated with smoother surfaces, yielding more robust algorithm<br>and more blurred motion field, typically polyN &#x3D;5 or 7.<br>@param polySigma   standard deviation of the Gaussian that is used to smooth derivatives used as a<br>basis for the polynomial expansion; for polyN&#x3D;5, you can set polySigma&#x3D;1.1, for polyN&#x3D;7, a good<br>value would be polySigma&#x3D;1.5.<br>@param flags       operation flags that can be a combination of the following:</p>
<ul>
<li>cv.OPTFLOW_USE_INITIAL_FLOW uses the input flow as an initial flow approximation.</li>
<li>cv.OPTFLOW_FARNEBACK_GAUSSIAN uses the Gaussian ùö†ùöíùöóùöúùöíùö£ùöé√óùö†ùöíùöóùöúùöíùö£ùöé filter instead of a box filter of<br>the same size for optical flow estimation; usually, this option gives z more accurate flow than with<br>a box filter, at the cost of lower speed; normally, winsize for a Gaussian window should be set to a<br>larger value to achieve the same level of robustness.</li>
</ul>
<h3 id="Try-it-1"><a href="#Try-it-1" class="headerlink" title="Try it"></a>Try it</h3><p>\htmlonly</p>
<iframe src="../../js_optical_flow_dense.html" width="100%"
        onload="this.style.height=this.contentDocument.body.scrollHeight +'px';">
</iframe>
\endhtmlonly
