<h1 id="BRIEF-Binary-Robust-Independent-Elementary-Features-tutorial-py-brief"><a href="#BRIEF-Binary-Robust-Independent-Elementary-Features-tutorial-py-brief" class="headerlink" title="BRIEF (Binary Robust Independent Elementary Features) {#tutorial_py_brief}"></a>BRIEF (Binary Robust Independent Elementary Features) {#tutorial_py_brief}</h1><h2 id="Goal"><a href="#Goal" class="headerlink" title="Goal"></a>Goal</h2><p>In this chapter<br>    -   We will see the basics of BRIEF algorithm</p>
<h2 id="Theory"><a href="#Theory" class="headerlink" title="Theory"></a>Theory</h2><p>We know SIFT uses 128-dim vector for descriptors. Since it is using floating point numbers, it takes<br>basically 512 bytes. Similarly SURF also takes minimum of 256 bytes (for 64-dim). Creating such a<br>vector for thousands of features takes a lot of memory which are not feasible for resource-constraint<br>applications especially for embedded systems. Larger the memory, longer the time it takes for<br>matching.</p>
<p>But all these dimensions may not be needed for actual matching. We can compress it using several<br>methods like PCA, LDA etc. Even other methods like hashing using LSH (Locality Sensitive Hashing) is<br>used to convert these SIFT descriptors in floating point numbers to binary strings. These binary<br>strings are used to match features using Hamming distance. This provides better speed-up because<br>finding hamming distance is just applying XOR and bit count, which are very fast in modern CPUs with<br>SSE instructions. But here, we need to find the descriptors first, then only we can apply hashing,<br>which doesn’t solve our initial problem on memory.</p>
<p>BRIEF comes into picture at this moment. It provides a shortcut to find the binary strings directly<br>without finding descriptors. It takes smoothened image patch and selects a set of \f$n_d\f$ (x,y)<br>location pairs in an unique way (explained in paper). Then some pixel intensity comparisons are done<br>on these location pairs. For eg, let first location pairs be \f$p\f$ and \f$q\f$. If \f$I(p) &lt; I(q)\f$, then its<br>result is 1, else it is 0. This is applied for all the \f$n_d\f$ location pairs to get a<br>\f$n_d\f$-dimensional bitstring.</p>
<p>This \f$n_d\f$ can be 128, 256 or 512. OpenCV supports all of these, but by default, it would be 256<br>(OpenCV represents it in bytes. So the values will be 16, 32 and 64). So once you get this, you can<br>use Hamming Distance to match these descriptors.</p>
<p>One important point is that BRIEF is a feature descriptor, it doesn’t provide any method to find the<br>features. So you will have to use any other feature detectors like SIFT, SURF etc. The paper<br>recommends to use CenSurE which is a fast detector and BRIEF works even slightly better for CenSurE<br>points than for SURF points.</p>
<p>In short, BRIEF is a faster method feature descriptor calculation and matching. It also provides<br>high recognition rate unless there is large in-plane rotation.</p>
<h2 id="STAR-CenSurE-in-OpenCV"><a href="#STAR-CenSurE-in-OpenCV" class="headerlink" title="STAR(CenSurE) in OpenCV"></a>STAR(CenSurE) in OpenCV</h2><h2 id="STAR-is-a-feature-detector-derived-from-CenSurE-Unlike-CenSurE-however-which-uses-polygons-like-squares-hexagons-and-octagons-to-approach-a-circle-Star-emulates-a-circle-with-2-overlapping-squares-1-upright-and-1-45-degree-rotated-These-polygons-are-bi-level-They-can-be-seen-as-polygons-with-thick-borders-The-borders-and-the-enclosed-area-have-weights-of-opposing-signs-This-has-better-computational-characteristics-than-other-scale-space-detectors-and-it-is-capable-of-real-time-implementation-In-contrast-to-SIFT-and-SURF-which-find-extrema-at-sub-sampled-pixels-that-compromises-accuracy-at-larger-scales-CenSurE-creates-a-feature-vector-using-full-spatial-resolution-at-all-scales-in-the-pyramid-BRIEF-in-OpenCV"><a href="#STAR-is-a-feature-detector-derived-from-CenSurE-Unlike-CenSurE-however-which-uses-polygons-like-squares-hexagons-and-octagons-to-approach-a-circle-Star-emulates-a-circle-with-2-overlapping-squares-1-upright-and-1-45-degree-rotated-These-polygons-are-bi-level-They-can-be-seen-as-polygons-with-thick-borders-The-borders-and-the-enclosed-area-have-weights-of-opposing-signs-This-has-better-computational-characteristics-than-other-scale-space-detectors-and-it-is-capable-of-real-time-implementation-In-contrast-to-SIFT-and-SURF-which-find-extrema-at-sub-sampled-pixels-that-compromises-accuracy-at-larger-scales-CenSurE-creates-a-feature-vector-using-full-spatial-resolution-at-all-scales-in-the-pyramid-BRIEF-in-OpenCV" class="headerlink" title="STAR is a feature detector derived from CenSurE.Unlike CenSurE however, which uses polygons like squares, hexagons and octagons to approach a circle,Star emulates a circle with 2 overlapping squares: 1 upright and 1 45-degree rotated. These polygons are bi-level.They can be seen as polygons with thick borders. The borders and the enclosed area have weights of opposing signs.This has better computational characteristics than other scale-space detectors and it is capable of real-time implementation.In contrast to SIFT and SURF, which find extrema at sub-sampled pixels that compromises accuracy at larger scales,CenSurE creates a feature vector using full spatial resolution at all scales in the pyramid.BRIEF in OpenCV"></a>STAR is a feature detector derived from CenSurE.<br>Unlike CenSurE however, which uses polygons like squares, hexagons and octagons to approach a circle,<br>Star emulates a circle with 2 overlapping squares: 1 upright and 1 45-degree rotated. These polygons are bi-level.<br>They can be seen as polygons with thick borders. The borders and the enclosed area have weights of opposing signs.<br>This has better computational characteristics than other scale-space detectors and it is capable of real-time implementation.<br>In contrast to SIFT and SURF, which find extrema at sub-sampled pixels that compromises accuracy at larger scales,<br>CenSurE creates a feature vector using full spatial resolution at all scales in the pyramid.<br>BRIEF in OpenCV</h2><p>Below code shows the computation of BRIEF descriptors with the help of CenSurE detector.</p>
<p>note, that you need <a href="https://github.com/opencv/opencv_contrib">opencv contrib</a>) to use this.<br>@code{.py}<br>import numpy as np<br>import cv2 as cv<br>from matplotlib import pyplot as plt</p>
<p>img &#x3D; cv.imread(‘simple.jpg’,0)</p>
<h1 id="Initiate-FAST-detector"><a href="#Initiate-FAST-detector" class="headerlink" title="Initiate FAST detector"></a>Initiate FAST detector</h1><p>star &#x3D; cv.xfeatures2d.StarDetector_create()</p>
<h1 id="Initiate-BRIEF-extractor"><a href="#Initiate-BRIEF-extractor" class="headerlink" title="Initiate BRIEF extractor"></a>Initiate BRIEF extractor</h1><p>brief &#x3D; cv.xfeatures2d.BriefDescriptorExtractor_create()</p>
<h1 id="find-the-keypoints-with-STAR"><a href="#find-the-keypoints-with-STAR" class="headerlink" title="find the keypoints with STAR"></a>find the keypoints with STAR</h1><p>kp &#x3D; star.detect(img,None)</p>
<h1 id="compute-the-descriptors-with-BRIEF"><a href="#compute-the-descriptors-with-BRIEF" class="headerlink" title="compute the descriptors with BRIEF"></a>compute the descriptors with BRIEF</h1><p>kp, des &#x3D; brief.compute(img, kp)</p>
<p>print( brief.descriptorSize() )<br>print( des.shape )<br>@endcode<br>The function brief.getDescriptorSize() gives the \f$n_d\f$ size used in bytes. By default it is 32. Next one<br>is matching, which will be done in another chapter.</p>
<h2 id="Additional-Resources"><a href="#Additional-Resources" class="headerlink" title="Additional Resources"></a>Additional Resources</h2><p>-#  Michael Calonder, Vincent Lepetit, Christoph Strecha, and Pascal Fua, “BRIEF: Binary Robust<br>    Independent Elementary Features”, 11th European Conference on Computer Vision (ECCV), Heraklion,<br>    Crete. LNCS Springer, September 2010.<br>2.  <a href="https://en.wikipedia.org/wiki/Locality-sensitive_hashing">LSH (Locality Sensitive Hashing)</a> at wikipedia.</p>
