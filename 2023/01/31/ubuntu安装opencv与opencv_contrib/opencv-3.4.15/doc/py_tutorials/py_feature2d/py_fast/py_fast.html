<h1 id="FAST-Algorithm-for-Corner-Detection-tutorial-py-fast"><a href="#FAST-Algorithm-for-Corner-Detection-tutorial-py-fast" class="headerlink" title="FAST Algorithm for Corner Detection {#tutorial_py_fast}"></a>FAST Algorithm for Corner Detection {#tutorial_py_fast}</h1><h2 id="Goal"><a href="#Goal" class="headerlink" title="Goal"></a>Goal</h2><p>In this chapter,<br>    -   We will understand the basics of FAST algorithm<br>    -   We will find corners using OpenCV functionalities for FAST algorithm.</p>
<h2 id="Theory"><a href="#Theory" class="headerlink" title="Theory"></a>Theory</h2><p>We saw several feature detectors and many of them are really good. But when looking from a real-time<br>application point of view, they are not fast enough. One best example would be SLAM (Simultaneous<br>Localization and Mapping) mobile robot which have limited computational resources.</p>
<p>As a solution to this, FAST (Features from Accelerated Segment Test) algorithm was proposed by<br>Edward Rosten and Tom Drummond in their paper “Machine learning for high-speed corner detection” in<br>2006 (Later revised it in 2010). A basic summary of the algorithm is presented below. Refer original<br>paper for more details (All the images are taken from original paper).</p>
<h3 id="Feature-Detection-using-FAST"><a href="#Feature-Detection-using-FAST" class="headerlink" title="Feature Detection using FAST"></a>Feature Detection using FAST</h3><p>-#  Select a pixel \f$p\f$ in the image which is to be identified as an interest point or not. Let its<br>    intensity be \f$I_p\f$.<br>2.  Select appropriate threshold value \f$t\f$.<br>3.  Consider a circle of 16 pixels around the pixel under test. (See the image below)</p>
<pre><code>![image](images/fast_speedtest.jpg)
</code></pre>
<p>-#  Now the pixel \f$p\f$ is a corner if there exists a set of \f$n\f$ contiguous pixels in the circle (of<br>    16 pixels) which are all brighter than \f$I_p + t\f$, or all darker than \f$I_p − t\f$. (Shown as white<br>    dash lines in the above image). \f$n\f$ was chosen to be 12.<br>5.  A <strong>high-speed test</strong> was proposed to exclude a large number of non-corners. This test examines<br>    only the four pixels at 1, 9, 5 and 13 (First 1 and 9 are tested if they are too brighter or<br>    darker. If so, then checks 5 and 13). If \f$p\f$ is a corner, then at least three of these must all<br>    be brighter than \f$I_p + t\f$ or darker than \f$I_p − t\f$. If neither of these is the case, then \f$p\f$<br>    cannot be a corner. The full segment test criterion can then be applied to the passed candidates<br>    by examining all pixels in the circle. This detector in itself exhibits high performance, but<br>    there are several weaknesses:</p>
<pre><code>-   It does not reject as many candidates for n \&lt; 12.
-   The choice of pixels is not optimal because its efficiency depends on ordering of the
    questions and distribution of corner appearances.
-   Results of high-speed tests are thrown away.
-   Multiple features are detected adjacent to one another.
</code></pre>
<p>First 3 points are addressed with a machine learning approach. Last one is addressed using<br>non-maximal suppression.</p>
<h3 id="Machine-Learning-a-Corner-Detector"><a href="#Machine-Learning-a-Corner-Detector" class="headerlink" title="Machine Learning a Corner Detector"></a>Machine Learning a Corner Detector</h3><p>-#  Select a set of images for training (preferably from the target application domain)<br>2.  Run FAST algorithm in every images to find feature points.<br>3.  For every feature point, store the 16 pixels around it as a vector. Do it for all the images to<br>    get feature vector \f$P\f$.<br>4.  Each pixel (say \f$x\f$) in these 16 pixels can have one of the following three states:</p>
<pre><code>![image](images/fast_eqns.jpg)
</code></pre>
<p>-#  Depending on these states, the feature vector \f$P\f$ is subdivided into 3 subsets, \f$P_d\f$, \f$P_s\f$,<br>    \f$P_b\f$.<br>6.  Define a new boolean variable, \f$K_p\f$, which is true if \f$p\f$ is a corner and false otherwise.<br>7.  Use the ID3 algorithm (decision tree classifier) to query each subset using the variable \f$K_p\f$<br>    for the knowledge about the true class. It selects the \f$x\f$ which yields the most information<br>    about whether the candidate pixel is a corner, measured by the entropy of \f$K_p\f$.<br>8.  This is recursively applied to all the subsets until its entropy is zero.<br>9.  The decision tree so created is used for fast detection in other images.</p>
<h3 id="Non-maximal-Suppression"><a href="#Non-maximal-Suppression" class="headerlink" title="Non-maximal Suppression"></a>Non-maximal Suppression</h3><p>Detecting multiple interest points in adjacent locations is another problem. It is solved by using<br>Non-maximum Suppression.</p>
<p>-#  Compute a score function, \f$V\f$ for all the detected feature points. \f$V\f$ is the sum of absolute<br>    difference between \f$p\f$ and 16 surrounding pixels values.<br>2.  Consider two adjacent keypoints and compute their \f$V\f$ values.<br>3.  Discard the one with lower \f$V\f$ value.</p>
<h3 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h3><p>It is several times faster than other existing corner detectors.</p>
<p>But it is not robust to high levels of noise. It is dependent on a threshold.</p>
<h2 id="FAST-Feature-Detector-in-OpenCV"><a href="#FAST-Feature-Detector-in-OpenCV" class="headerlink" title="FAST Feature Detector in OpenCV"></a>FAST Feature Detector in OpenCV</h2><p>It is called as any other feature detector in OpenCV. If you want, you can specify the threshold,<br>whether non-maximum suppression to be applied or not, the neighborhood to be used etc.</p>
<p>For the neighborhood, three flags are defined, cv.FAST_FEATURE_DETECTOR_TYPE_5_8,<br>cv.FAST_FEATURE_DETECTOR_TYPE_7_12 and cv.FAST_FEATURE_DETECTOR_TYPE_9_16. Below is a<br>simple code on how to detect and draw the FAST feature points.<br>@code{.py}<br>import numpy as np<br>import cv2 as cv<br>from matplotlib import pyplot as plt</p>
<p>img &#x3D; cv.imread(‘simple.jpg’,0)</p>
<h1 id="Initiate-FAST-object-with-default-values"><a href="#Initiate-FAST-object-with-default-values" class="headerlink" title="Initiate FAST object with default values"></a>Initiate FAST object with default values</h1><p>fast &#x3D; cv.FastFeatureDetector_create()</p>
<h1 id="find-and-draw-the-keypoints"><a href="#find-and-draw-the-keypoints" class="headerlink" title="find and draw the keypoints"></a>find and draw the keypoints</h1><p>kp &#x3D; fast.detect(img,None)<br>img2 &#x3D; cv.drawKeypoints(img, kp, None, color&#x3D;(255,0,0))</p>
<h1 id="Print-all-default-params"><a href="#Print-all-default-params" class="headerlink" title="Print all default params"></a>Print all default params</h1><p>print( “Threshold: {}”.format(fast.getThreshold()) )<br>print( “nonmaxSuppression:{}”.format(fast.getNonmaxSuppression()) )<br>print( “neighborhood: {}”.format(fast.getType()) )<br>print( “Total Keypoints with nonmaxSuppression: {}”.format(len(kp)) )</p>
<p>cv.imwrite(‘fast_true.png’,img2)</p>
<h1 id="Disable-nonmaxSuppression"><a href="#Disable-nonmaxSuppression" class="headerlink" title="Disable nonmaxSuppression"></a>Disable nonmaxSuppression</h1><p>fast.setNonmaxSuppression(0)<br>kp &#x3D; fast.detect(img,None)</p>
<p>print( “Total Keypoints without nonmaxSuppression: {}”.format(len(kp)) )</p>
<p>img3 &#x3D; cv.drawKeypoints(img, kp, None, color&#x3D;(255,0,0))</p>
<p>cv.imwrite(‘fast_false.png’,img3)<br>@endcode<br>See the results. First image shows FAST with nonmaxSuppression and second one without<br>nonmaxSuppression:</p>
<p><img src="/images/fast_kp.jpg" alt="image"></p>
<h2 id="Additional-Resources"><a href="#Additional-Resources" class="headerlink" title="Additional Resources"></a>Additional Resources</h2><p>-#  Edward Rosten and Tom Drummond, “Machine learning for high speed corner detection” in 9th<br>    European Conference on Computer Vision, vol. 1, 2006, pp. 430–443.<br>2.  Edward Rosten, Reid Porter, and Tom Drummond, “Faster and better: a machine learning approach to<br>    corner detection” in IEEE Trans. Pattern Analysis and Machine Intelligence, 2010, vol 32, pp.<br>    105-119.</p>
<h2 id="Exercises"><a href="#Exercises" class="headerlink" title="Exercises"></a>Exercises</h2>