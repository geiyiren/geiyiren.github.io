<h1 id="Introduction-to-SURF-Speeded-Up-Robust-Features-tutorial-py-surf-intro"><a href="#Introduction-to-SURF-Speeded-Up-Robust-Features-tutorial-py-surf-intro" class="headerlink" title="Introduction to SURF (Speeded-Up Robust Features) {#tutorial_py_surf_intro}"></a>Introduction to SURF (Speeded-Up Robust Features) {#tutorial_py_surf_intro}</h1><h2 id="Goal"><a href="#Goal" class="headerlink" title="Goal"></a>Goal</h2><p>In this chapter,<br>    -   We will see the basics of SURF<br>    -   We will see SURF functionalities in OpenCV</p>
<h2 id="Theory"><a href="#Theory" class="headerlink" title="Theory"></a>Theory</h2><p>In last chapter, we saw SIFT for keypoint detection and description. But it was comparatively slow<br>and people needed more speeded-up version. In 2006, three people, Bay, H., Tuytelaars, T. and Van<br>Gool, L, published another paper, “SURF: Speeded Up Robust Features” which introduced a new<br>algorithm called SURF. As name suggests, it is a speeded-up version of SIFT.</p>
<p>In SIFT, Lowe approximated Laplacian of Gaussian with Difference of Gaussian for finding<br>scale-space. SURF goes a little further and approximates LoG with Box Filter. Below image shows a<br>demonstration of such an approximation. One big advantage of this approximation is that, convolution<br>with box filter can be easily calculated with the help of integral images. And it can be done in<br>parallel for different scales. Also the SURF rely on determinant of Hessian matrix for both scale<br>and location.</p>
<p><img src="/images/surf_boxfilter.jpg" alt="image"></p>
<p>For orientation assignment, SURF uses wavelet responses in horizontal and vertical direction for a<br>neighbourhood of size 6s. Adequate gaussian weights are also applied to it. Then they are plotted in<br>a space as given in below image. The dominant orientation is estimated by calculating the sum of all<br>responses within a sliding orientation window of angle 60 degrees. Interesting thing is that,<br>wavelet response can be found out using integral images very easily at any scale. For many<br>applications, rotation invariance is not required, so no need of finding this orientation, which<br>speeds up the process. SURF provides such a functionality called Upright-SURF or U-SURF. It improves<br>speed and is robust upto \f$\pm 15^{\circ}\f$. OpenCV supports both, depending upon the flag,<br><strong>upright</strong>. If it is 0, orientation is calculated. If it is 1, orientation is not calculated and it<br>is faster.</p>
<p><img src="/images/surf_orientation.jpg" alt="image"></p>
<p>For feature description, SURF uses Wavelet responses in horizontal and vertical direction (again,<br>use of integral images makes things easier). A neighbourhood of size 20sX20s is taken around the<br>keypoint where s is the size. It is divided into 4x4 subregions. For each subregion, horizontal and<br>vertical wavelet responses are taken and a vector is formed like this,<br>\f$v&#x3D;( \sum{d_x}, \sum{d_y}, \sum{|d_x|}, \sum{|d_y|})\f$. This when represented as a vector gives SURF<br>feature descriptor with total 64 dimensions. Lower the dimension, higher the speed of computation<br>and matching, but provide better distinctiveness of features.</p>
<p>For more distinctiveness, SURF feature descriptor has an extended 128 dimension version. The sums of<br>\f$d_x\f$ and \f$|d_x|\f$ are computed separately for \f$d_y &lt; 0\f$ and \f$d_y \geq 0\f$. Similarly, the sums of<br>\f$d_y\f$ and \f$|d_y|\f$ are split up according to the sign of \f$d_x\f$ , thereby doubling the number of<br>features. It doesn’t add much computation complexity. OpenCV supports both by setting the value of<br>flag <strong>extended</strong> with 0 and 1 for 64-dim and 128-dim respectively (default is 128-dim)</p>
<p>Another important improvement is the use of sign of Laplacian (trace of Hessian Matrix) for<br>underlying interest point. It adds no computation cost since it is already computed during<br>detection. The sign of the Laplacian distinguishes bright blobs on dark backgrounds from the reverse<br>situation. In the matching stage, we only compare features if they have the same type of contrast<br>(as shown in image below). This minimal information allows for faster matching, without reducing the<br>descriptor’s performance.</p>
<p><img src="/images/surf_matching.jpg" alt="image"></p>
<p>In short, SURF adds a lot of features to improve the speed in every step. Analysis shows it is 3<br>times faster than SIFT while performance is comparable to SIFT. SURF is good at handling images with<br>blurring and rotation, but not good at handling viewpoint change and illumination change.</p>
<h2 id="SURF-in-OpenCV"><a href="#SURF-in-OpenCV" class="headerlink" title="SURF in OpenCV"></a>SURF in OpenCV</h2><p>OpenCV provides SURF functionalities just like SIFT. You initiate a SURF object with some optional<br>conditions like 64&#x2F;128-dim descriptors, Upright&#x2F;Normal SURF etc. All the details are well explained<br>in docs. Then as we did in SIFT, we can use SURF.detect(), SURF.compute() etc for finding keypoints<br>and descriptors.</p>
<p>First we will see a simple demo on how to find SURF keypoints and descriptors and draw it. All<br>examples are shown in Python terminal since it is just same as SIFT only.<br>@code{.py}</p>
<blockquote>
<blockquote>
<blockquote>
<p>img &#x3D; cv.imread(‘fly.png’,0)</p>
</blockquote>
</blockquote>
</blockquote>
<h1 id="Create-SURF-object-You-can-specify-params-here-or-later"><a href="#Create-SURF-object-You-can-specify-params-here-or-later" class="headerlink" title="Create SURF object. You can specify params here or later."></a>Create SURF object. You can specify params here or later.</h1><h1 id="Here-I-set-Hessian-Threshold-to-400"><a href="#Here-I-set-Hessian-Threshold-to-400" class="headerlink" title="Here I set Hessian Threshold to 400"></a>Here I set Hessian Threshold to 400</h1><blockquote>
<blockquote>
<blockquote>
<p>surf &#x3D; cv.xfeatures2d.SURF_create(400)</p>
</blockquote>
</blockquote>
</blockquote>
<h1 id="Find-keypoints-and-descriptors-directly"><a href="#Find-keypoints-and-descriptors-directly" class="headerlink" title="Find keypoints and descriptors directly"></a>Find keypoints and descriptors directly</h1><blockquote>
<blockquote>
<blockquote>
<p>kp, des &#x3D; surf.detectAndCompute(img,None)</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p>len(kp)<br> 699<br>@endcode<br>1199 keypoints is too much to show in a picture. We reduce it to some 50 to draw it on an image.<br>While matching, we may need all those features, but not now. So we increase the Hessian Threshold.<br>@code{.py}</p>
</blockquote>
</blockquote>
</blockquote>
<h1 id="Check-present-Hessian-threshold"><a href="#Check-present-Hessian-threshold" class="headerlink" title="Check present Hessian threshold"></a>Check present Hessian threshold</h1><blockquote>
<blockquote>
<blockquote>
<p>print( surf.getHessianThreshold() )<br>400.0</p>
</blockquote>
</blockquote>
</blockquote>
<h1 id="We-set-it-to-some-50000-Remember-it-is-just-for-representing-in-picture"><a href="#We-set-it-to-some-50000-Remember-it-is-just-for-representing-in-picture" class="headerlink" title="We set it to some 50000. Remember, it is just for representing in picture."></a>We set it to some 50000. Remember, it is just for representing in picture.</h1><h1 id="In-actual-cases-it-is-better-to-have-a-value-300-500"><a href="#In-actual-cases-it-is-better-to-have-a-value-300-500" class="headerlink" title="In actual cases, it is better to have a value 300-500"></a>In actual cases, it is better to have a value 300-500</h1><blockquote>
<blockquote>
<blockquote>
<p>surf.setHessianThreshold(50000)</p>
</blockquote>
</blockquote>
</blockquote>
<h1 id="Again-compute-keypoints-and-check-its-number"><a href="#Again-compute-keypoints-and-check-its-number" class="headerlink" title="Again compute keypoints and check its number."></a>Again compute keypoints and check its number.</h1><blockquote>
<blockquote>
<blockquote>
<p>kp, des &#x3D; surf.detectAndCompute(img,None)</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p>print( len(kp) )<br>47<br>@endcode<br>It is less than 50. Let’s draw it on the image.<br>@code{.py}<br>img2 &#x3D; cv.drawKeypoints(img,kp,None,(255,0,0),4)</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p>plt.imshow(img2),plt.show()<br>@endcode<br>See the result below. You can see that SURF is more like a blob detector. It detects the white blobs<br>on wings of butterfly. You can test it with other images.</p>
</blockquote>
</blockquote>
</blockquote>
<p><img src="/images/surf_kp1.jpg" alt="image"></p>
<p>Now I want to apply U-SURF, so that it won’t find the orientation.<br>@code{.py}</p>
<h1 id="Check-upright-flag-if-it-False-set-it-to-True"><a href="#Check-upright-flag-if-it-False-set-it-to-True" class="headerlink" title="Check upright flag, if it False, set it to True"></a>Check upright flag, if it False, set it to True</h1><blockquote>
<blockquote>
<blockquote>
<p>print( surf.getUpright() )<br>False</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p>surf.setUpright(True)</p>
</blockquote>
</blockquote>
</blockquote>
<h1 id="Recompute-the-feature-points-and-draw-it"><a href="#Recompute-the-feature-points-and-draw-it" class="headerlink" title="Recompute the feature points and draw it"></a>Recompute the feature points and draw it</h1><blockquote>
<blockquote>
<blockquote>
<p>kp &#x3D; surf.detect(img,None)<br>img2 &#x3D; cv.drawKeypoints(img,kp,None,(255,0,0),4)</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p>plt.imshow(img2),plt.show()<br>@endcode<br>See the results below. All the orientations are shown in same direction. It is faster than<br>previous. If you are working on cases where orientation is not a problem (like panorama stitching)<br>etc, this is better.</p>
</blockquote>
</blockquote>
</blockquote>
<p><img src="/images/surf_kp2.jpg" alt="image"></p>
<p>Finally we check the descriptor size and change it to 128 if it is only 64-dim.<br>@code{.py}</p>
<h1 id="Find-size-of-descriptor"><a href="#Find-size-of-descriptor" class="headerlink" title="Find size of descriptor"></a>Find size of descriptor</h1><blockquote>
<blockquote>
<blockquote>
<p>print( surf.descriptorSize() )<br>64</p>
</blockquote>
</blockquote>
</blockquote>
<h1 id="That-means-flag-“extended”-is-False"><a href="#That-means-flag-“extended”-is-False" class="headerlink" title="That means flag, “extended” is False."></a>That means flag, “extended” is False.</h1><blockquote>
<blockquote>
<blockquote>
<p>surf.getExtended()<br> False</p>
</blockquote>
</blockquote>
</blockquote>
<h1 id="So-we-make-it-to-True-to-get-128-dim-descriptors"><a href="#So-we-make-it-to-True-to-get-128-dim-descriptors" class="headerlink" title="So we make it to True to get 128-dim descriptors."></a>So we make it to True to get 128-dim descriptors.</h1><blockquote>
<blockquote>
<blockquote>
<p>surf.setExtended(True)<br>kp, des &#x3D; surf.detectAndCompute(img,None)<br>print( surf.descriptorSize() )<br>128<br>print( des.shape )<br>(47, 128)<br>@endcode<br>Remaining part is matching which we will do in another chapter.</p>
</blockquote>
</blockquote>
</blockquote>
<h2 id="Additional-Resources"><a href="#Additional-Resources" class="headerlink" title="Additional Resources"></a>Additional Resources</h2><h2 id="Exercises"><a href="#Exercises" class="headerlink" title="Exercises"></a>Exercises</h2>