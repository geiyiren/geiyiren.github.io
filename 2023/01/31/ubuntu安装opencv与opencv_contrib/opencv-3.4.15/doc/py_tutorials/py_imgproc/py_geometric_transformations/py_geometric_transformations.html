<h1 id="Geometric-Transformations-of-Images-tutorial-py-geometric-transformations"><a href="#Geometric-Transformations-of-Images-tutorial-py-geometric-transformations" class="headerlink" title="Geometric Transformations of Images {#tutorial_py_geometric_transformations}"></a>Geometric Transformations of Images {#tutorial_py_geometric_transformations}</h1><h2 id="Goals"><a href="#Goals" class="headerlink" title="Goals"></a>Goals</h2><ul>
<li>Learn to apply different geometric transformations to images, like translation, rotation, affine<br>transformation etc.</li>
<li>You will see these functions: <strong>cv.getPerspectiveTransform</strong></li>
</ul>
<h2 id="Transformations"><a href="#Transformations" class="headerlink" title="Transformations"></a>Transformations</h2><p>OpenCV provides two transformation functions, <strong>cv.warpAffine</strong> and <strong>cv.warpPerspective</strong>, with<br>which you can perform all kinds of transformations. <strong>cv.warpAffine</strong> takes a 2x3 transformation<br>matrix while <strong>cv.warpPerspective</strong> takes a 3x3 transformation matrix as input.</p>
<h3 id="Scaling"><a href="#Scaling" class="headerlink" title="Scaling"></a>Scaling</h3><p>Scaling is just resizing of the image. OpenCV comes with a function <strong>cv.resize()</strong> for this<br>purpose. The size of the image can be specified manually, or you can specify the scaling factor.<br>Different interpolation methods are used. Preferable interpolation methods are <strong>cv.INTER_AREA</strong><br>for shrinking and <strong>cv.INTER_CUBIC</strong> (slow) &amp; <strong>cv.INTER_LINEAR</strong> for zooming. By default,<br>the interpolation method <strong>cv.INTER_LINEAR</strong> is used for all resizing purposes. You can resize an<br>input image with either of following methods:<br>@code{.py}<br>import numpy as np<br>import cv2 as cv</p>
<p>img &#x3D; cv.imread(‘messi5.jpg’)</p>
<p>res &#x3D; cv.resize(img,None,fx&#x3D;2, fy&#x3D;2, interpolation &#x3D; cv.INTER_CUBIC)</p>
<p>#OR</p>
<p>height, width &#x3D; img.shape[:2]<br>res &#x3D; cv.resize(img,(2<em>width, 2</em>height), interpolation &#x3D; cv.INTER_CUBIC)<br>@endcode</p>
<h3 id="Translation"><a href="#Translation" class="headerlink" title="Translation"></a>Translation</h3><p>Translation is the shifting of an object’s location. If you know the shift in the (x,y) direction and let it<br>be \f$(t_x,t_y)\f$, you can create the transformation matrix \f$\textbf{M}\f$ as follows:</p>
<p>\f[M &#x3D; \begin{bmatrix} 1 &amp; 0 &amp; t_x \ 0 &amp; 1 &amp; t_y  \end{bmatrix}\f]</p>
<p>You can take make it into a Numpy array of type np.float32 and pass it into the <strong>cv.warpAffine()</strong><br>function. See the below example for a shift of (100,50):<br>@code{.py}<br>import numpy as np<br>import cv2 as cv</p>
<p>img &#x3D; cv.imread(‘messi5.jpg’,0)<br>rows,cols &#x3D; img.shape</p>
<p>M &#x3D; np.float32([[1,0,100],[0,1,50]])<br>dst &#x3D; cv.warpAffine(img,M,(cols,rows))</p>
<p>cv.imshow(‘img’,dst)<br>cv.waitKey(0)<br>cv.destroyAllWindows()<br>@endcode<br><strong>warning</strong></p>
<p>The third argument of the <strong>cv.warpAffine()</strong> function is the size of the output image, which should<br>be in the form of <strong>(width, height)</strong>. Remember width &#x3D; number of columns, and height &#x3D; number of<br>rows.</p>
<p>See the result below:</p>
<p><img src="/images/translation.jpg" alt="image"></p>
<h3 id="Rotation"><a href="#Rotation" class="headerlink" title="Rotation"></a>Rotation</h3><p>Rotation of an image for an angle \f$\theta\f$ is achieved by the transformation matrix of the form</p>
<p>\f[M &#x3D; \begin{bmatrix} cos\theta &amp; -sin\theta \ sin\theta &amp; cos\theta   \end{bmatrix}\f]</p>
<p>But OpenCV provides scaled rotation with adjustable center of rotation so that you can rotate at any<br>location you prefer. The modified transformation matrix is given by</p>
<p>\f[\begin{bmatrix} \alpha &amp;  \beta &amp; (1- \alpha )  \cdot center.x -  \beta \cdot center.y \ - \beta &amp;  \alpha &amp;  \beta \cdot center.x + (1- \alpha )  \cdot center.y \end{bmatrix}\f]</p>
<p>where:</p>
<p>\f[\begin{array}{l} \alpha &#x3D;  scale \cdot \cos \theta , \ \beta &#x3D;  scale \cdot \sin \theta \end{array}\f]</p>
<p>To find this transformation matrix, OpenCV provides a function, <strong>cv.getRotationMatrix2D</strong>. Check out the<br>below example which rotates the image by 90 degree with respect to center without any scaling.<br>@code{.py}<br>img &#x3D; cv.imread(‘messi5.jpg’,0)<br>rows,cols &#x3D; img.shape</p>
<h1 id="cols-1-and-rows-1-are-the-coordinate-limits"><a href="#cols-1-and-rows-1-are-the-coordinate-limits" class="headerlink" title="cols-1 and rows-1 are the coordinate limits."></a>cols-1 and rows-1 are the coordinate limits.</h1><p>M &#x3D; cv.getRotationMatrix2D(((cols-1)&#x2F;2.0,(rows-1)&#x2F;2.0),90,1)<br>dst &#x3D; cv.warpAffine(img,M,(cols,rows))<br>@endcode<br>See the result:</p>
<p><img src="/images/rotation.jpg" alt="image"></p>
<h3 id="Affine-Transformation"><a href="#Affine-Transformation" class="headerlink" title="Affine Transformation"></a>Affine Transformation</h3><p>In affine transformation, all parallel lines in the original image will still be parallel in the<br>output image. To find the transformation matrix, we need three points from the input image and their<br>corresponding locations in the output image. Then <strong>cv.getAffineTransform</strong> will create a 2x3 matrix<br>which is to be passed to <strong>cv.warpAffine</strong>.</p>
<p>Check the below example, and also look at the points I selected (which are marked in green color):<br>@code{.py}<br>img &#x3D; cv.imread(‘drawing.png’)<br>rows,cols,ch &#x3D; img.shape</p>
<p>pts1 &#x3D; np.float32([[50,50],[200,50],[50,200]])<br>pts2 &#x3D; np.float32([[10,100],[200,50],[100,250]])</p>
<p>M &#x3D; cv.getAffineTransform(pts1,pts2)</p>
<p>dst &#x3D; cv.warpAffine(img,M,(cols,rows))</p>
<p>plt.subplot(121),plt.imshow(img),plt.title(‘Input’)<br>plt.subplot(122),plt.imshow(dst),plt.title(‘Output’)<br>plt.show()<br>@endcode<br>See the result:</p>
<p><img src="/images/affine.jpg" alt="image"></p>
<h3 id="Perspective-Transformation"><a href="#Perspective-Transformation" class="headerlink" title="Perspective Transformation"></a>Perspective Transformation</h3><p>For perspective transformation, you need a 3x3 transformation matrix. Straight lines will remain<br>straight even after the transformation. To find this transformation matrix, you need 4 points on the<br>input image and corresponding points on the output image. Among these 4 points, 3 of them should not<br>be collinear. Then the transformation matrix can be found by the function<br><strong>cv.getPerspectiveTransform</strong>. Then apply <strong>cv.warpPerspective</strong> with this 3x3 transformation<br>matrix.</p>
<p>See the code below:<br>@code{.py}<br>img &#x3D; cv.imread(‘sudoku.png’)<br>rows,cols,ch &#x3D; img.shape</p>
<p>pts1 &#x3D; np.float32([[56,65],[368,52],[28,387],[389,390]])<br>pts2 &#x3D; np.float32([[0,0],[300,0],[0,300],[300,300]])</p>
<p>M &#x3D; cv.getPerspectiveTransform(pts1,pts2)</p>
<p>dst &#x3D; cv.warpPerspective(img,M,(300,300))</p>
<p>plt.subplot(121),plt.imshow(img),plt.title(‘Input’)<br>plt.subplot(122),plt.imshow(dst),plt.title(‘Output’)<br>plt.show()<br>@endcode<br>Result:</p>
<p><img src="/images/perspective.jpg" alt="image"></p>
<h2 id="Additional-Resources"><a href="#Additional-Resources" class="headerlink" title="Additional Resources"></a>Additional Resources</h2><p>-#  “Computer Vision: Algorithms and Applications”, Richard Szeliski</p>
<h2 id="Exercises"><a href="#Exercises" class="headerlink" title="Exercises"></a>Exercises</h2>