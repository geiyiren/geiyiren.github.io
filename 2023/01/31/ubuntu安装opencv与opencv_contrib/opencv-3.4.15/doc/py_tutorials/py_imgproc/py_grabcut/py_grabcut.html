<h1 id="Interactive-Foreground-Extraction-using-GrabCut-Algorithm-tutorial-py-grabcut"><a href="#Interactive-Foreground-Extraction-using-GrabCut-Algorithm-tutorial-py-grabcut" class="headerlink" title="Interactive Foreground Extraction using GrabCut Algorithm {#tutorial_py_grabcut}"></a>Interactive Foreground Extraction using GrabCut Algorithm {#tutorial_py_grabcut}</h1><h2 id="Goal"><a href="#Goal" class="headerlink" title="Goal"></a>Goal</h2><p>In this chapter<br>    -   We will see GrabCut algorithm to extract foreground in images<br>    -   We will create an interactive application for this.</p>
<h2 id="Theory"><a href="#Theory" class="headerlink" title="Theory"></a>Theory</h2><p>GrabCut algorithm was designed by Carsten Rother, Vladimir Kolmogorov &amp; Andrew Blake from Microsoft<br>Research Cambridge, UK. in their paper, <a href="http://dl.acm.org/citation.cfm?id=1015720">“GrabCut”: interactive foreground extraction using iterated<br>graph cuts</a> . An algorithm was needed for foreground<br>extraction with minimal user interaction, and the result was GrabCut.</p>
<p>How it works from user point of view ? Initially user draws a rectangle around the foreground region<br>(foreground region should be completely inside the rectangle). Then algorithm segments it<br>iteratively to get the best result. Done. But in some cases, the segmentation won’t be fine, like,<br>it may have marked some foreground region as background and vice versa. In that case, user need to<br>do fine touch-ups. Just give some strokes on the images where some faulty results are there. Strokes<br>basically says <em>“Hey, this region should be foreground, you marked it background, correct it in next<br>iteration”</em> or its opposite for background. Then in the next iteration, you get better results.</p>
<p>See the image below. First player and football is enclosed in a blue rectangle. Then some final<br>touchups with white strokes (denoting foreground) and black strokes (denoting background) is made.<br>And we get a nice result.</p>
<p><img src="/images/grabcut_output1.jpg" alt="image"></p>
<p>So what happens in background ?</p>
<ul>
<li>User inputs the rectangle. Everything outside this rectangle will be taken as sure background<br>(That is the reason it is mentioned before that your rectangle should include all the<br>objects). Everything inside rectangle is unknown. Similarly any user input specifying<br>foreground and background are considered as hard-labelling which means they won’t change in<br>the process.</li>
<li>Computer does an initial labelling depending on the data we gave. It labels the foreground and<br>background pixels (or it hard-labels)</li>
<li>Now a Gaussian Mixture Model(GMM) is used to model the foreground and background.</li>
<li>Depending on the data we gave, GMM learns and create new pixel distribution. That is, the<br>unknown pixels are labelled either probable foreground or probable background depending on its<br>relation with the other hard-labelled pixels in terms of color statistics (It is just like<br>clustering).</li>
<li>A graph is built from this pixel distribution. Nodes in the graphs are pixels. Additional two<br>nodes are added, <strong>Source node</strong> and <strong>Sink node</strong>. Every foreground pixel is connected to<br>Source node and every background pixel is connected to Sink node.</li>
<li>The weights of edges connecting pixels to source node&#x2F;end node are defined by the probability<br>of a pixel being foreground&#x2F;background. The weights between the pixels are defined by the edge<br>information or pixel similarity. If there is a large difference in pixel color, the edge<br>between them will get a low weight.</li>
<li>Then a mincut algorithm is used to segment the graph. It cuts the graph into two separating<br>source node and sink node with minimum cost function. The cost function is the sum of all<br>weights of the edges that are cut. After the cut, all the pixels connected to Source node<br>become foreground and those connected to Sink node become background.</li>
<li>The process is continued until the classification converges.</li>
</ul>
<p>It is illustrated in below image (Image Courtesy: <a href="http://www.cs.ru.ac.za/research/g02m1682/">http://www.cs.ru.ac.za/research/g02m1682/</a>)</p>
<p><img src="/images/grabcut_scheme.jpg" alt="image"></p>
<h2 id="Demo"><a href="#Demo" class="headerlink" title="Demo"></a>Demo</h2><p>Now we go for grabcut algorithm with OpenCV. OpenCV has the function, <strong>cv.grabCut()</strong> for this. We<br>will see its arguments first:</p>
<ul>
<li><em>img</em> - Input image</li>
<li><em>mask</em> - It is a mask image where we specify which areas are background, foreground or<br>probable background&#x2F;foreground etc. It is done by the following flags, <strong>cv.GC_BGD,<br>cv.GC_FGD, cv.GC_PR_BGD, cv.GC_PR_FGD</strong>, or simply pass 0,1,2,3 to image.</li>
<li><em>rect</em> - It is the coordinates of a rectangle which includes the foreground object in the<br>format (x,y,w,h)</li>
<li><em>bdgModel</em>, <em>fgdModel</em> - These are arrays used by the algorithm internally. You just create<br>two np.float64 type zero arrays of size (1,65).</li>
<li><em>iterCount</em> - Number of iterations the algorithm should run.</li>
<li><em>mode</em> - It should be <strong>cv.GC_INIT_WITH_RECT</strong> or <strong>cv.GC_INIT_WITH_MASK</strong> or combined<br>which decides whether we are drawing rectangle or final touchup strokes.</li>
</ul>
<p>First let’s see with rectangular mode. We load the image, create a similar mask image. We create<br><em>fgdModel</em> and <em>bgdModel</em>. We give the rectangle parameters. It’s all straight-forward. Let the<br>algorithm run for 5 iterations. Mode should be <em>cv.GC_INIT_WITH_RECT</em> since we are using<br>rectangle. Then run the grabcut. It modifies the mask image. In the new mask image, pixels will be<br>marked with four flags denoting background&#x2F;foreground as specified above. So we modify the mask such<br>that all 0-pixels and 2-pixels are put to 0 (ie background) and all 1-pixels and 3-pixels are put to<br>1(ie foreground pixels). Now our final mask is ready. Just multiply it with input image to get the<br>segmented image.<br>@code{.py}<br>import numpy as np<br>import cv2 as cv<br>from matplotlib import pyplot as plt</p>
<p>img &#x3D; cv.imread(‘messi5.jpg’)<br>mask &#x3D; np.zeros(img.shape[:2],np.uint8)</p>
<p>bgdModel &#x3D; np.zeros((1,65),np.float64)<br>fgdModel &#x3D; np.zeros((1,65),np.float64)</p>
<p>rect &#x3D; (50,50,450,290)<br>cv.grabCut(img,mask,rect,bgdModel,fgdModel,5,cv.GC_INIT_WITH_RECT)</p>
<p>mask2 &#x3D; np.where((mask&#x3D;&#x3D;2)|(mask&#x3D;&#x3D;0),0,1).astype(‘uint8’)<br>img &#x3D; img*mask2[:,:,np.newaxis]</p>
<p>plt.imshow(img),plt.colorbar(),plt.show()<br>@endcode<br>See the results below:</p>
<p><img src="/images/grabcut_rect.jpg" alt="image"></p>
<p>Oops, Messi’s hair is gone. <em>Who likes Messi without his hair?</em> We need to bring it back. So we will<br>give there a fine touchup with 1-pixel (sure foreground). At the same time, Some part of ground has<br>come to picture which we don’t want, and also some logo. We need to remove them. There we give some<br>0-pixel touchup (sure background). So we modify our resulting mask in previous case as we told now.</p>
<p><em>What I actually did is that, I opened input image in paint application and added another layer to<br>the image. Using brush tool in the paint, I marked missed foreground (hair, shoes, ball etc) with<br>white and unwanted background (like logo, ground etc) with black on this new layer. Then filled<br>remaining background with gray. Then loaded that mask image in OpenCV, edited original mask image we<br>got with corresponding values in newly added mask image. Check the code below:</em><br>@code{.py}</p>
<h1 id="newmask-is-the-mask-image-I-manually-labelled"><a href="#newmask-is-the-mask-image-I-manually-labelled" class="headerlink" title="newmask is the mask image I manually labelled"></a>newmask is the mask image I manually labelled</h1><p>newmask &#x3D; cv.imread(‘newmask.png’,0)</p>
<h1 id="wherever-it-is-marked-white-sure-foreground-change-mask-x3D-1"><a href="#wherever-it-is-marked-white-sure-foreground-change-mask-x3D-1" class="headerlink" title="wherever it is marked white (sure foreground), change mask&#x3D;1"></a>wherever it is marked white (sure foreground), change mask&#x3D;1</h1><h1 id="wherever-it-is-marked-black-sure-background-change-mask-x3D-0"><a href="#wherever-it-is-marked-black-sure-background-change-mask-x3D-0" class="headerlink" title="wherever it is marked black (sure background), change mask&#x3D;0"></a>wherever it is marked black (sure background), change mask&#x3D;0</h1><p>mask[newmask &#x3D;&#x3D; 0] &#x3D; 0<br>mask[newmask &#x3D;&#x3D; 255] &#x3D; 1</p>
<p>mask, bgdModel, fgdModel &#x3D; cv.grabCut(img,mask,None,bgdModel,fgdModel,5,cv.GC_INIT_WITH_MASK)</p>
<p>mask &#x3D; np.where((mask&#x3D;&#x3D;2)|(mask&#x3D;&#x3D;0),0,1).astype(‘uint8’)<br>img &#x3D; img*mask[:,:,np.newaxis]<br>plt.imshow(img),plt.colorbar(),plt.show()<br>@endcode<br>See the result below:</p>
<p><img src="/images/grabcut_mask.jpg" alt="image"></p>
<p>So that’s it. Here instead of initializing in rect mode, you can directly go into mask mode. Just<br>mark the rectangle area in mask image with 2-pixel or 3-pixel (probable background&#x2F;foreground). Then<br>mark our sure_foreground with 1-pixel as we did in second example. Then directly apply the grabCut<br>function with mask mode.</p>
<h2 id="Additional-Resources"><a href="#Additional-Resources" class="headerlink" title="Additional Resources"></a>Additional Resources</h2><h2 id="Exercises"><a href="#Exercises" class="headerlink" title="Exercises"></a>Exercises</h2><p>-#  OpenCV samples contain a sample grabcut.py which is an interactive tool using grabcut. Check it.<br>    Also watch this <a href="http://www.youtube.com/watch?v=kAwxLTDDAwU">youtube video</a> on how to use it.<br>-#  Here, you can make this into a interactive sample with drawing rectangle and strokes with mouse,<br>    create trackbar to adjust stroke width etc.</p>
