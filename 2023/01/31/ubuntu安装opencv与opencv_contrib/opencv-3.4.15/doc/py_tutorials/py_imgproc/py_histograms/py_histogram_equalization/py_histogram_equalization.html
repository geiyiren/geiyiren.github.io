<h1 id="Histograms-2-Histogram-Equalization-tutorial-py-histogram-equalization"><a href="#Histograms-2-Histogram-Equalization-tutorial-py-histogram-equalization" class="headerlink" title="Histograms - 2: Histogram Equalization {#tutorial_py_histogram_equalization}"></a>Histograms - 2: Histogram Equalization {#tutorial_py_histogram_equalization}</h1><h2 id="Goal"><a href="#Goal" class="headerlink" title="Goal"></a>Goal</h2><p>In this section,</p>
<ul>
<li>We will learn the concepts of histogram equalization and use it to improve the contrast of our<br>images.</li>
</ul>
<h2 id="Theory"><a href="#Theory" class="headerlink" title="Theory"></a>Theory</h2><p>Consider an image whose pixel values are confined to some specific range of values only. For eg,<br>brighter image will have all pixels confined to high values. But a good image will have pixels from<br>all regions of the image. So you need to stretch this histogram to either ends (as given in below<br>image, from wikipedia) and that is what Histogram Equalization does (in simple words). This normally<br>improves the contrast of the image.</p>
<p><img src="/images/histogram_equalization.png" alt="image"></p>
<p>I would recommend you to read the wikipedia page on <a href="http://en.wikipedia.org/wiki/Histogram_equalization">Histogram<br>Equalization</a> for more details about it. It has<br>a very good explanation with worked out examples, so that you would understand almost everything<br>after reading that. Instead, here we will see its Numpy implementation. After that, we will see<br>OpenCV function.<br>@code{.py}<br>import numpy as np<br>import cv2 as cv<br>from matplotlib import pyplot as plt</p>
<p>img &#x3D; cv.imread(‘wiki.jpg’,0)</p>
<p>hist,bins &#x3D; np.histogram(img.flatten(),256,[0,256])</p>
<p>cdf &#x3D; hist.cumsum()<br>cdf_normalized &#x3D; cdf * float(hist.max()) &#x2F; cdf.max()</p>
<p>plt.plot(cdf_normalized, color &#x3D; ‘b’)<br>plt.hist(img.flatten(),256,[0,256], color &#x3D; ‘r’)<br>plt.xlim([0,256])<br>plt.legend((‘cdf’,’histogram’), loc &#x3D; ‘upper left’)<br>plt.show()<br>@endcode<br><img src="/images/histeq_numpy1.jpg" alt="image"></p>
<p>You can see histogram lies in brighter region. We need the full spectrum. For that, we need a<br>transformation function which maps the input pixels in brighter region to output pixels in full<br>region. That is what histogram equalization does.</p>
<p>Now we find the minimum histogram value (excluding 0) and apply the histogram equalization equation<br>as given in wiki page. But I have used here, the masked array concept array from Numpy. For masked<br>array, all operations are performed on non-masked elements. You can read more about it from Numpy<br>docs on masked arrays.<br>@code{.py}<br>cdf_m &#x3D; np.ma.masked_equal(cdf,0)<br>cdf_m &#x3D; (cdf_m - cdf_m.min())*255&#x2F;(cdf_m.max()-cdf_m.min())<br>cdf &#x3D; np.ma.filled(cdf_m,0).astype(‘uint8’)<br>@endcode<br>Now we have the look-up table that gives us the information on what is the output pixel value for<br>every input pixel value. So we just apply the transform.<br>@code{.py}<br>img2 &#x3D; cdf[img]<br>@endcode<br>Now we calculate its histogram and cdf as before ( you do it) and result looks like below :</p>
<p><img src="/images/histeq_numpy2.jpg" alt="image"></p>
<p>Another important feature is that, even if the image was a darker image (instead of a brighter one<br>we used), after equalization we will get almost the same image as we got. As a result, this is used<br>as a “reference tool” to make all images with same lighting conditions. This is useful in many<br>cases. For example, in face recognition, before training the face data, the images of faces are<br>histogram equalized to make them all with same lighting conditions.</p>
<h2 id="Histograms-Equalization-in-OpenCV"><a href="#Histograms-Equalization-in-OpenCV" class="headerlink" title="Histograms Equalization in OpenCV"></a>Histograms Equalization in OpenCV</h2><p>OpenCV has a function to do this, <strong>cv.equalizeHist()</strong>. Its input is just grayscale image and<br>output is our histogram equalized image.</p>
<p>Below is a simple code snippet showing its usage for same image we used :<br>@code{.py}<br>img &#x3D; cv.imread(‘wiki.jpg’,0)<br>equ &#x3D; cv.equalizeHist(img)<br>res &#x3D; np.hstack((img,equ)) #stacking images side-by-side<br>cv.imwrite(‘res.png’,res)<br>@endcode<br><img src="/images/equalization_opencv.jpg" alt="image"></p>
<p>So now you can take different images with different light conditions, equalize it and check the<br>results.</p>
<p>Histogram equalization is good when histogram of the image is confined to a particular region. It<br>won’t work good in places where there is large intensity variations where histogram covers a large<br>region, ie both bright and dark pixels are present. Please check the SOF links in Additional<br>Resources.</p>
<h2 id="CLAHE-Contrast-Limited-Adaptive-Histogram-Equalization"><a href="#CLAHE-Contrast-Limited-Adaptive-Histogram-Equalization" class="headerlink" title="CLAHE (Contrast Limited Adaptive Histogram Equalization)"></a>CLAHE (Contrast Limited Adaptive Histogram Equalization)</h2><p>The first histogram equalization we just saw, considers the global contrast of the image. In many<br>cases, it is not a good idea. For example, below image shows an input image and its result after<br>global histogram equalization.</p>
<p><img src="/images/clahe_1.jpg" alt="image"></p>
<p>It is true that the background contrast has improved after histogram equalization. But compare the<br>face of statue in both images. We lost most of the information there due to over-brightness. It is<br>because its histogram is not confined to a particular region as we saw in previous cases (Try to<br>plot histogram of input image, you will get more intuition).</p>
<p>So to solve this problem, <strong>adaptive histogram equalization</strong> is used. In this, image is divided<br>into small blocks called “tiles” (tileSize is 8x8 by default in OpenCV). Then each of these blocks<br>are histogram equalized as usual. So in a small area, histogram would confine to a small region<br>(unless there is noise). If noise is there, it will be amplified. To avoid this, <strong>contrast<br>limiting</strong> is applied. If any histogram bin is above the specified contrast limit (by default 40 in<br>OpenCV), those pixels are clipped and distributed uniformly to other bins before applying histogram<br>equalization. After equalization, to remove artifacts in tile borders, bilinear interpolation is<br>applied.</p>
<p>Below code snippet shows how to apply CLAHE in OpenCV:<br>@code{.py}<br>import numpy as np<br>import cv2 as cv</p>
<p>img &#x3D; cv.imread(‘tsukuba_l.png’,0)</p>
<h1 id="create-a-CLAHE-object-Arguments-are-optional"><a href="#create-a-CLAHE-object-Arguments-are-optional" class="headerlink" title="create a CLAHE object (Arguments are optional)."></a>create a CLAHE object (Arguments are optional).</h1><p>clahe &#x3D; cv.createCLAHE(clipLimit&#x3D;2.0, tileGridSize&#x3D;(8,8))<br>cl1 &#x3D; clahe.apply(img)</p>
<p>cv.imwrite(‘clahe_2.jpg’,cl1)<br>@endcode<br>See the result below and compare it with results above, especially the statue region:</p>
<p><img src="/images/clahe_2.jpg" alt="image"></p>
<h2 id="Additional-Resources"><a href="#Additional-Resources" class="headerlink" title="Additional Resources"></a>Additional Resources</h2><p>-#  Wikipedia page on <a href="http://en.wikipedia.org/wiki/Histogram_equalization">Histogram Equalization</a><br>2.  <a href="http://docs.scipy.org/doc/numpy/reference/maskedarray.html">Masked Arrays in Numpy</a></p>
<p>Also check these SOF questions regarding contrast adjustment:</p>
<p>-#  <a href="http://stackoverflow.com/questions/10549245/how-can-i-adjust-contrast-in-opencv-in-c">How can I adjust contrast in OpenCV in<br>    C?</a><br>4.  <a href="http://stackoverflow.com/questions/10561222/how-do-i-equalize-contrast-brightness-of-images-using-opencv">How do I equalize contrast &amp; brightness of images using<br>    opencv?</a></p>
<h2 id="Exercises"><a href="#Exercises" class="headerlink" title="Exercises"></a>Exercises</h2>