<h1 id="Fourier-Transform-tutorial-py-fourier-transform"><a href="#Fourier-Transform-tutorial-py-fourier-transform" class="headerlink" title="Fourier Transform {#tutorial_py_fourier_transform}"></a>Fourier Transform {#tutorial_py_fourier_transform}</h1><h2 id="Goal"><a href="#Goal" class="headerlink" title="Goal"></a>Goal</h2><p>In this section, we will learn<br>    -   To find the Fourier Transform of images using OpenCV<br>    -   To utilize the FFT functions available in Numpy<br>    -   Some applications of Fourier Transform<br>    -   We will see following functions : <strong>cv.dft()</strong>, <strong>cv.idft()</strong> etc</p>
<h2 id="Theory"><a href="#Theory" class="headerlink" title="Theory"></a>Theory</h2><p>Fourier Transform is used to analyze the frequency characteristics of various filters. For images,<br><strong>2D Discrete Fourier Transform (DFT)</strong> is used to find the frequency domain. A fast algorithm<br>called <strong>Fast Fourier Transform (FFT)</strong> is used for calculation of DFT. Details about these can be<br>found in any image processing or signal processing textbooks. Please see Additional Resources_<br>section.</p>
<p>For a sinusoidal signal, \f$x(t) &#x3D; A \sin(2 \pi ft)\f$, we can say \f$f\f$ is the frequency of signal, and<br>if its frequency domain is taken, we can see a spike at \f$f\f$. If signal is sampled to form a discrete<br>signal, we get the same frequency domain, but is periodic in the range \f$[- \pi, \pi]\f$ or \f$[0,2\pi]\f$<br>(or \f$[0,N]\f$ for N-point DFT). You can consider an image as a signal which is sampled in two<br>directions. So taking fourier transform in both X and Y directions gives you the frequency<br>representation of image.</p>
<p>More intuitively, for the sinusoidal signal, if the amplitude varies so fast in short time, you can<br>say it is a high frequency signal. If it varies slowly, it is a low frequency signal. You can extend<br>the same idea to images. Where does the amplitude varies drastically in images ? At the edge points,<br>or noises. So we can say, edges and noises are high frequency contents in an image. If there is no<br>much changes in amplitude, it is a low frequency component. ( Some links are added to<br>Additional Resources_ which explains frequency transform intuitively with examples).</p>
<p>Now we will see how to find the Fourier Transform.</p>
<h2 id="Fourier-Transform-in-Numpy"><a href="#Fourier-Transform-in-Numpy" class="headerlink" title="Fourier Transform in Numpy"></a>Fourier Transform in Numpy</h2><p>First we will see how to find Fourier Transform using Numpy. Numpy has an FFT package to do this.<br><strong>np.fft.fft2()</strong> provides us the frequency transform which will be a complex array. Its first<br>argument is the input image, which is grayscale. Second argument is optional which decides the size<br>of output array. If it is greater than size of input image, input image is padded with zeros before<br>calculation of FFT. If it is less than input image, input image will be cropped. If no arguments<br>passed, Output array size will be same as input.</p>
<p>Now once you got the result, zero frequency component (DC component) will be at top left corner. If<br>you want to bring it to center, you need to shift the result by \f$\frac{N}{2}\f$ in both the<br>directions. This is simply done by the function, <strong>np.fft.fftshift()</strong>. (It is more easier to<br>analyze). Once you found the frequency transform, you can find the magnitude spectrum.<br>@code{.py}<br>import cv2 as cv<br>import numpy as np<br>from matplotlib import pyplot as plt</p>
<p>img &#x3D; cv.imread(‘messi5.jpg’,0)<br>f &#x3D; np.fft.fft2(img)<br>fshift &#x3D; np.fft.fftshift(f)<br>magnitude_spectrum &#x3D; 20*np.log(np.abs(fshift))</p>
<p>plt.subplot(121),plt.imshow(img, cmap &#x3D; ‘gray’)<br>plt.title(‘Input Image’), plt.xticks([]), plt.yticks([])<br>plt.subplot(122),plt.imshow(magnitude_spectrum, cmap &#x3D; ‘gray’)<br>plt.title(‘Magnitude Spectrum’), plt.xticks([]), plt.yticks([])<br>plt.show()<br>@endcode<br>Result look like below:</p>
<p><img src="/images/fft1.jpg" alt="image"></p>
<p>See, You can see more whiter region at the center showing low frequency content is more.</p>
<p>So you found the frequency transform Now you can do some operations in frequency domain, like high<br>pass filtering and reconstruct the image, ie find inverse DFT. For that you simply remove the low<br>frequencies by masking with a rectangular window of size 60x60. Then apply the inverse shift using<br><strong>np.fft.ifftshift()</strong> so that DC component again come at the top-left corner. Then find inverse FFT<br>using <strong>np.ifft2()</strong> function. The result, again, will be a complex number. You can take its<br>absolute value.<br>@code{.py}<br>rows, cols &#x3D; img.shape<br>crow,ccol &#x3D; rows&#x2F;&#x2F;2 , cols&#x2F;&#x2F;2<br>fshift[crow-30:crow+31, ccol-30:ccol+31] &#x3D; 0<br>f_ishift &#x3D; np.fft.ifftshift(fshift)<br>img_back &#x3D; np.fft.ifft2(f_ishift)<br>img_back &#x3D; np.real(img_back)</p>
<p>plt.subplot(131),plt.imshow(img, cmap &#x3D; ‘gray’)<br>plt.title(‘Input Image’), plt.xticks([]), plt.yticks([])<br>plt.subplot(132),plt.imshow(img_back, cmap &#x3D; ‘gray’)<br>plt.title(‘Image after HPF’), plt.xticks([]), plt.yticks([])<br>plt.subplot(133),plt.imshow(img_back)<br>plt.title(‘Result in JET’), plt.xticks([]), plt.yticks([])</p>
<p>plt.show()<br>@endcode<br>Result look like below:</p>
<p><img src="/images/fft2.jpg" alt="image"></p>
<p>The result shows High Pass Filtering is an edge detection operation. This is what we have seen in<br>Image Gradients chapter. This also shows that most of the image data is present in the Low frequency<br>region of the spectrum. Anyway we have seen how to find DFT, IDFT etc in Numpy. Now let’s see how to<br>do it in OpenCV.</p>
<p>If you closely watch the result, especially the last image in JET color, you can see some artifacts<br>(One instance I have marked in red arrow). It shows some ripple like structures there, and it is<br>called <strong>ringing effects</strong>. It is caused by the rectangular window we used for masking. This mask is<br>converted to sinc shape which causes this problem. So rectangular windows is not used for filtering.<br>Better option is Gaussian Windows.</p>
<h2 id="Fourier-Transform-in-OpenCV"><a href="#Fourier-Transform-in-OpenCV" class="headerlink" title="Fourier Transform in OpenCV"></a>Fourier Transform in OpenCV</h2><p>OpenCV provides the functions <strong>cv.dft()</strong> and <strong>cv.idft()</strong> for this. It returns the same result<br>as previous, but with two channels. First channel will have the real part of the result and second<br>channel will have the imaginary part of the result. The input image should be converted to<br>np.float32 first. We will see how to do it.<br>@code{.py}<br>import numpy as np<br>import cv2 as cv<br>from matplotlib import pyplot as plt</p>
<p>img &#x3D; cv.imread(‘messi5.jpg’,0)</p>
<p>dft &#x3D; cv.dft(np.float32(img),flags &#x3D; cv.DFT_COMPLEX_OUTPUT)<br>dft_shift &#x3D; np.fft.fftshift(dft)</p>
<p>magnitude_spectrum &#x3D; 20*np.log(cv.magnitude(dft_shift[:,:,0],dft_shift[:,:,1]))</p>
<p>plt.subplot(121),plt.imshow(img, cmap &#x3D; ‘gray’)<br>plt.title(‘Input Image’), plt.xticks([]), plt.yticks([])<br>plt.subplot(122),plt.imshow(magnitude_spectrum, cmap &#x3D; ‘gray’)<br>plt.title(‘Magnitude Spectrum’), plt.xticks([]), plt.yticks([])<br>plt.show()<br>@endcode</p>
<p>@note You can also use <strong>cv.cartToPolar()</strong> which returns both magnitude and phase in a single shot</p>
<p>So, now we have to do inverse DFT. In previous session, we created a HPF, this time we will see how<br>to remove high frequency contents in the image, ie we apply LPF to image. It actually blurs the<br>image. For this, we create a mask first with high value (1) at low frequencies, ie we pass the LF<br>content, and 0 at HF region.</p>
<p>@code{.py}<br>rows, cols &#x3D; img.shape<br>crow,ccol &#x3D; rows&#x2F;2 , cols&#x2F;2</p>
<h1 id="create-a-mask-first-center-square-is-1-remaining-all-zeros"><a href="#create-a-mask-first-center-square-is-1-remaining-all-zeros" class="headerlink" title="create a mask first, center square is 1, remaining all zeros"></a>create a mask first, center square is 1, remaining all zeros</h1><p>mask &#x3D; np.zeros((rows,cols,2),np.uint8)<br>mask[crow-30:crow+30, ccol-30:ccol+30] &#x3D; 1</p>
<h1 id="apply-mask-and-inverse-DFT"><a href="#apply-mask-and-inverse-DFT" class="headerlink" title="apply mask and inverse DFT"></a>apply mask and inverse DFT</h1><p>fshift &#x3D; dft_shift*mask<br>f_ishift &#x3D; np.fft.ifftshift(fshift)<br>img_back &#x3D; cv.idft(f_ishift)<br>img_back &#x3D; cv.magnitude(img_back[:,:,0],img_back[:,:,1])</p>
<p>plt.subplot(121),plt.imshow(img, cmap &#x3D; ‘gray’)<br>plt.title(‘Input Image’), plt.xticks([]), plt.yticks([])<br>plt.subplot(122),plt.imshow(img_back, cmap &#x3D; ‘gray’)<br>plt.title(‘Magnitude Spectrum’), plt.xticks([]), plt.yticks([])<br>plt.show()<br>@endcode<br>See the result:</p>
<p><img src="/images/fft4.jpg" alt="image"></p>
<p>@note As usual, OpenCV functions <strong>cv.dft()</strong> and <strong>cv.idft()</strong> are faster than Numpy<br>counterparts. But Numpy functions are more user-friendly. For more details about performance issues,<br>see below section.</p>
<h1 id="Performance-Optimization-of-DFT"><a href="#Performance-Optimization-of-DFT" class="headerlink" title="Performance Optimization of DFT"></a>Performance Optimization of DFT</h1><p>Performance of DFT calculation is better for some array size. It is fastest when array size is power<br>of two. The arrays whose size is a product of 2’s, 3’s, and 5’s are also processed quite<br>efficiently. So if you are worried about the performance of your code, you can modify the size of<br>the array to any optimal size (by padding zeros) before finding DFT. For OpenCV, you have to<br>manually pad zeros. But for Numpy, you specify the new size of FFT calculation, and it will<br>automatically pad zeros for you.</p>
<p>So how do we find this optimal size ? OpenCV provides a function, <strong>cv.getOptimalDFTSize()</strong> for<br>this. It is applicable to both <strong>cv.dft()</strong> and <strong>np.fft.fft2()</strong>. Let’s check their performance<br>using IPython magic command %timeit.<br>@code{.py}<br>In [16]: img &#x3D; cv.imread(‘messi5.jpg’,0)<br>In [17]: rows,cols &#x3D; img.shape<br>In [18]: print(“{} {}”.format(rows,cols))<br>342 548</p>
<p>In [19]: nrows &#x3D; cv.getOptimalDFTSize(rows)<br>In [20]: ncols &#x3D; cv.getOptimalDFTSize(cols)<br>In [21]: print(“{} {}”.format(nrows,ncols))<br>360 576<br>@endcode<br>See, the size (342,548) is modified to (360, 576). Now let’s pad it with zeros (for OpenCV) and find<br>their DFT calculation performance. You can do it by creating a new big zero array and copy the data<br>to it, or use <strong>cv.copyMakeBorder()</strong>.<br>@code{.py}<br>nimg &#x3D; np.zeros((nrows,ncols))<br>nimg[:rows,:cols] &#x3D; img<br>@endcode<br>OR:<br>@code{.py}<br>right &#x3D; ncols - cols<br>bottom &#x3D; nrows - rows<br>bordertype &#x3D; cv.BORDER_CONSTANT #just to avoid line breakup in PDF file<br>nimg &#x3D; cv.copyMakeBorder(img,0,bottom,0,right,bordertype, value &#x3D; 0)<br>@endcode<br>Now we calculate the DFT performance comparison of Numpy function:<br>@code{.py}<br>In [22]: %timeit fft1 &#x3D; np.fft.fft2(img)<br>10 loops, best of 3: 40.9 ms per loop<br>In [23]: %timeit fft2 &#x3D; np.fft.fft2(img,[nrows,ncols])<br>100 loops, best of 3: 10.4 ms per loop<br>@endcode<br>It shows a 4x speedup. Now we will try the same with OpenCV functions.<br>@code{.py}<br>In [24]: %timeit dft1&#x3D; cv.dft(np.float32(img),flags&#x3D;cv.DFT_COMPLEX_OUTPUT)<br>100 loops, best of 3: 13.5 ms per loop<br>In [27]: %timeit dft2&#x3D; cv.dft(np.float32(nimg),flags&#x3D;cv.DFT_COMPLEX_OUTPUT)<br>100 loops, best of 3: 3.11 ms per loop<br>@endcode<br>It also shows a 4x speed-up. You can also see that OpenCV functions are around 3x faster than Numpy<br>functions. This can be tested for inverse FFT also, and that is left as an exercise for you.</p>
<h2 id="Why-Laplacian-is-a-High-Pass-Filter"><a href="#Why-Laplacian-is-a-High-Pass-Filter" class="headerlink" title="Why Laplacian is a High Pass Filter?"></a>Why Laplacian is a High Pass Filter?</h2><p>A similar question was asked in a forum. The question is, why Laplacian is a high pass filter? Why<br>Sobel is a HPF? etc. And the first answer given to it was in terms of Fourier Transform. Just take<br>the fourier transform of Laplacian for some higher size of FFT. Analyze it:<br>@code{.py}<br>import cv2 as cv<br>import numpy as np<br>from matplotlib import pyplot as plt</p>
<h1 id="simple-averaging-filter-without-scaling-parameter"><a href="#simple-averaging-filter-without-scaling-parameter" class="headerlink" title="simple averaging filter without scaling parameter"></a>simple averaging filter without scaling parameter</h1><p>mean_filter &#x3D; np.ones((3,3))</p>
<h1 id="creating-a-gaussian-filter"><a href="#creating-a-gaussian-filter" class="headerlink" title="creating a gaussian filter"></a>creating a gaussian filter</h1><p>x &#x3D; cv.getGaussianKernel(5,10)<br>gaussian &#x3D; x*x.T</p>
<h1 id="different-edge-detecting-filters"><a href="#different-edge-detecting-filters" class="headerlink" title="different edge detecting filters"></a>different edge detecting filters</h1><h1 id="scharr-in-x-direction"><a href="#scharr-in-x-direction" class="headerlink" title="scharr in x-direction"></a>scharr in x-direction</h1><p>scharr &#x3D; np.array([[-3, 0, 3],<br>                   [-10,0,10],<br>                   [-3, 0, 3]])</p>
<h1 id="sobel-in-x-direction"><a href="#sobel-in-x-direction" class="headerlink" title="sobel in x direction"></a>sobel in x direction</h1><p>sobel_x&#x3D; np.array([[-1, 0, 1],<br>                   [-2, 0, 2],<br>                   [-1, 0, 1]])</p>
<h1 id="sobel-in-y-direction"><a href="#sobel-in-y-direction" class="headerlink" title="sobel in y direction"></a>sobel in y direction</h1><p>sobel_y&#x3D; np.array([[-1,-2,-1],<br>                   [0, 0, 0],<br>                   [1, 2, 1]])</p>
<h1 id="laplacian"><a href="#laplacian" class="headerlink" title="laplacian"></a>laplacian</h1><p>laplacian&#x3D;np.array([[0, 1, 0],<br>                    [1,-4, 1],<br>                    [0, 1, 0]])</p>
<p>filters &#x3D; [mean_filter, gaussian, laplacian, sobel_x, sobel_y, scharr]<br>filter_name &#x3D; [‘mean_filter’, ‘gaussian’,’laplacian’, ‘sobel_x’, <br>                ‘sobel_y’, ‘scharr_x’]<br>fft_filters &#x3D; [np.fft.fft2(x) for x in filters]<br>fft_shift &#x3D; [np.fft.fftshift(y) for y in fft_filters]<br>mag_spectrum &#x3D; [np.log(np.abs(z)+1) for z in fft_shift]</p>
<p>for i in range(6):<br>    plt.subplot(2,3,i+1),plt.imshow(mag_spectrum[i],cmap &#x3D; ‘gray’)<br>    plt.title(filter_name[i]), plt.xticks([]), plt.yticks([])</p>
<p>plt.show()<br>@endcode<br>See the result:</p>
<p><img src="/images/fft5.jpg" alt="image"></p>
<p>From image, you can see what frequency region each kernel blocks, and what region it passes. From<br>that information, we can say why each kernel is a HPF or a LPF</p>
<h2 id="Additional-Resources"><a href="#Additional-Resources" class="headerlink" title="Additional Resources"></a>Additional Resources</h2><p>-#  <a href="http://cns-alumni.bu.edu/~slehar/fourier/fourier.html">An Intuitive Explanation of Fourier<br>    Theory</a> by Steven Lehar<br>2.  <a href="http://homepages.inf.ed.ac.uk/rbf/HIPR2/fourier.htm">Fourier Transform</a> at HIPR<br>3.  <a href="http://dsp.stackexchange.com/q/1637/818">What does frequency domain denote in case of images?</a></p>
<h2 id="Exercises"><a href="#Exercises" class="headerlink" title="Exercises"></a>Exercises</h2>