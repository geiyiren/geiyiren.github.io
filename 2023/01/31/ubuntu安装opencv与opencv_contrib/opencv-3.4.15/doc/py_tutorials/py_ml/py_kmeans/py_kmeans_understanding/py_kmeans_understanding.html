<h1 id="Understanding-K-Means-Clustering-tutorial-py-kmeans-understanding"><a href="#Understanding-K-Means-Clustering-tutorial-py-kmeans-understanding" class="headerlink" title="Understanding K-Means Clustering {#tutorial_py_kmeans_understanding}"></a>Understanding K-Means Clustering {#tutorial_py_kmeans_understanding}</h1><h2 id="Goal"><a href="#Goal" class="headerlink" title="Goal"></a>Goal</h2><p>In this chapter, we will understand the concepts of K-Means Clustering, how it works etc.</p>
<h2 id="Theory"><a href="#Theory" class="headerlink" title="Theory"></a>Theory</h2><p>We will deal this with an example which is commonly used.</p>
<h3 id="T-shirt-size-problem"><a href="#T-shirt-size-problem" class="headerlink" title="T-shirt size problem"></a>T-shirt size problem</h3><p>Consider a company, which is going to release a new model of T-shirt to market. Obviously they will<br>have to manufacture models in different sizes to satisfy people of all sizes. So the company make a<br>data of people’s height and weight, and plot them on to a graph, as below:</p>
<p><img src="/images/tshirt.jpg" alt="image"></p>
<p>Company can’t create t-shirts with all the sizes. Instead, they divide people to Small, Medium and<br>Large, and manufacture only these 3 models which will fit into all the people. This grouping of<br>people into three groups can be done by k-means clustering, and algorithm provides us best 3 sizes,<br>which will satisfy all the people. And if it doesn’t, company can divide people to more groups, may<br>be five, and so on. Check image below :</p>
<p><img src="/images/tshirt_grouped.jpg" alt="image"></p>
<h3 id="How-does-it-work"><a href="#How-does-it-work" class="headerlink" title="How does it work ?"></a>How does it work ?</h3><p>This algorithm is an iterative process. We will explain it step-by-step with the help of images.</p>
<p>Consider a set of data as below ( You can consider it as t-shirt problem). We need to cluster this<br>data into two groups.</p>
<p><img src="/images/testdata.jpg" alt="image"></p>
<p><strong>Step : 1</strong> - Algorithm randomly chooses two centroids, \f$C1\f$ and \f$C2\f$ (sometimes, any two data are<br>taken as the centroids).</p>
<p><strong>Step : 2</strong> - It calculates the distance from each point to both centroids. If a test data is more<br>closer to \f$C1\f$, then that data is labelled with ‘0’. If it is closer to \f$C2\f$, then labelled as ‘1’<br>(If more centroids are there, labelled as ‘2’,’3’ etc).</p>
<p>In our case, we will color all ‘0’ labelled with red, and ‘1’ labelled with blue. So we get<br>following image after above operations.</p>
<p><img src="/images/initial_labelling.jpg" alt="image"></p>
<p><strong>Step : 3</strong> - Next we calculate the average of all blue points and red points separately and that<br>will be our new centroids. That is \f$C1\f$ and \f$C2\f$ shift to newly calculated centroids. (Remember, the<br>images shown are not true values and not to true scale, it is just for demonstration only).</p>
<p>And again, perform step 2 with new centroids and label data to ‘0’ and ‘1’.</p>
<p>So we get result as below :</p>
<p><img src="/images/update_centroid.jpg" alt="image"></p>
<p>Now <strong>Step - 2</strong> and <strong>Step - 3</strong> are iterated until both centroids are converged to fixed points.<br><em>(Or it may be stopped depending on the criteria we provide, like maximum number of iterations, or a<br>specific accuracy is reached etc.)</em> <strong>These points are such that sum of distances between test data<br>and their corresponding centroids are minimum</strong>. Or simply, sum of distances between<br>\f$C1 \leftrightarrow Red_Points\f$ and \f$C2 \leftrightarrow Blue_Points\f$ is minimum.</p>
<p>\f[minimize ;\bigg[J &#x3D; \sum_{All: Red_Points}distance(C1,Red_Point) + \sum_{All: Blue_Points}distance(C2,Blue_Point)\bigg]\f]</p>
<p>Final result almost looks like below :</p>
<p><img src="/images/final_clusters.jpg" alt="image"></p>
<p>So this is just an intuitive understanding of K-Means Clustering. For more details and mathematical<br>explanation, please read any standard machine learning textbooks or check links in additional<br>resources. It is just a top layer of K-Means clustering. There are a lot of modifications to this<br>algorithm like, how to choose the initial centroids, how to speed up the iteration process etc.</p>
<h2 id="Additional-Resources"><a href="#Additional-Resources" class="headerlink" title="Additional Resources"></a>Additional Resources</h2><p>-#  <a href="https://www.coursera.org/course/ml">Machine Learning Course</a>, Video lectures by Prof. Andrew Ng<br>    (Some of the images are taken from this)</p>
<h2 id="Exercises"><a href="#Exercises" class="headerlink" title="Exercises"></a>Exercises</h2>