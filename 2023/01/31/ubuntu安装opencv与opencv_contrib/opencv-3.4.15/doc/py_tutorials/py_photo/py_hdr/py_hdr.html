<h1 id="High-Dynamic-Range-HDR-tutorial-py-hdr"><a href="#High-Dynamic-Range-HDR-tutorial-py-hdr" class="headerlink" title="High Dynamic Range (HDR) {#tutorial_py_hdr}"></a>High Dynamic Range (HDR) {#tutorial_py_hdr}</h1><h2 id="Goal"><a href="#Goal" class="headerlink" title="Goal"></a>Goal</h2><p>In this chapter, we will</p>
<ul>
<li>Learn how to generate and display HDR image from an exposure sequence.</li>
<li>Use exposure fusion to merge an exposure sequence.</li>
</ul>
<h2 id="Theory"><a href="#Theory" class="headerlink" title="Theory"></a>Theory</h2><p>High-dynamic-range imaging (HDRI or HDR) is a technique used in imaging and photography to reproduce<br>a greater dynamic range of luminosity than is possible with standard digital imaging or photographic<br>techniques. While the human eye can adjust to a wide range of light conditions, most imaging devices use 8-bits<br>per channel, so we are limited to only 256 levels. When we take photographs of a real<br>world scene, bright regions may be overexposed, while the dark ones may be underexposed, so we<br>can’t capture all details using a single exposure. HDR imaging works with images that use more<br>than 8 bits per channel (usually 32-bit float values), allowing much wider dynamic range.</p>
<p>There are different ways to obtain HDR images, but the most common one is to use photographs of<br>the scene taken with different exposure values. To combine these exposures it is useful to know your<br>camera’s response function and there are algorithms to estimate it. After the HDR image has been<br>merged, it has to be converted back to 8-bit to view it on usual displays. This process is called<br>tonemapping. Additional complexities arise when objects of the scene or camera move between shots,<br>since images with different exposures should be registered and aligned.</p>
<p>In this tutorial we show 2 algorithms (Debevec, Robertson) to generate and display HDR image from an<br>exposure sequence, and demonstrate an alternative approach called exposure fusion (Mertens), that<br>produces low dynamic range image and does not need the exposure times data.<br>Furthermore, we estimate the camera response function (CRF) which is of great value for many computer<br>vision algorithms.<br>Each step of HDR pipeline can be implemented using different algorithms and parameters, so take a<br>look at the reference manual to see them all.</p>
<h2 id="Exposure-sequence-HDR"><a href="#Exposure-sequence-HDR" class="headerlink" title="Exposure sequence HDR"></a>Exposure sequence HDR</h2><p>In this tutorial we will look on the following scene, where we have 4 exposure<br>images, with exposure times of: 15, 2.5, 1&#x2F;4 and 1&#x2F;30 seconds. (You can download<br>the images from <a href="https://en.wikipedia.org/wiki/High-dynamic-range_imaging">Wikipedia</a>)</p>
<p><img src="/images/exposures.jpg" alt="image"></p>
<h3 id="1-Loading-exposure-images-into-a-list"><a href="#1-Loading-exposure-images-into-a-list" class="headerlink" title="1. Loading exposure images into a list"></a>1. Loading exposure images into a list</h3><p>The first stage is simply loading all images into a list.<br>In addition, we will need the exposure times for the regular HDR algorithms.<br>Pay attention for the data types, as the images should be 1-channel or 3-channels<br>8-bit (np.uint8) and the exposure times need to be float32 and in seconds.</p>
<p>@code{.py}<br>import cv2 as cv<br>import numpy as np</p>
<h1 id="Loading-exposure-images-into-a-list"><a href="#Loading-exposure-images-into-a-list" class="headerlink" title="Loading exposure images into a list"></a>Loading exposure images into a list</h1><p>img_fn &#x3D; [“img0.jpg”, “img1.jpg”, “img2.jpg”, “img3.jpg”]<br>img_list &#x3D; [cv.imread(fn) for fn in img_fn]<br>exposure_times &#x3D; np.array([15.0, 2.5, 0.25, 0.0333], dtype&#x3D;np.float32)<br>@endcode</p>
<h3 id="2-Merge-exposures-into-HDR-image"><a href="#2-Merge-exposures-into-HDR-image" class="headerlink" title="2. Merge exposures into HDR image"></a>2. Merge exposures into HDR image</h3><p>In this stage we merge the exposure sequence into one HDR image, showing 2 possibilities<br>which we have in OpenCV. The first method is Debevec and the second one is Robertson.<br>Notice that the HDR image is of type float32, and not uint8, as it contains the<br>full dynamic range of all exposure images.</p>
<p>@code{.py}</p>
<h1 id="Merge-exposures-to-HDR-image"><a href="#Merge-exposures-to-HDR-image" class="headerlink" title="Merge exposures to HDR image"></a>Merge exposures to HDR image</h1><p>merge_debevec &#x3D; cv.createMergeDebevec()<br>hdr_debevec &#x3D; merge_debevec.process(img_list, times&#x3D;exposure_times.copy())<br>merge_robertson &#x3D; cv.createMergeRobertson()<br>hdr_robertson &#x3D; merge_robertson.process(img_list, times&#x3D;exposure_times.copy())<br>@endcode</p>
<h3 id="3-Tonemap-HDR-image"><a href="#3-Tonemap-HDR-image" class="headerlink" title="3. Tonemap HDR image"></a>3. Tonemap HDR image</h3><p>We map the 32-bit float HDR data into the range [0..1].<br>Actually, in some cases the values can be larger than 1 or lower the 0, so notice<br>we will later have to clip the data in order to avoid overflow.</p>
<p>@code{.py}</p>
<h1 id="Tonemap-HDR-image"><a href="#Tonemap-HDR-image" class="headerlink" title="Tonemap HDR image"></a>Tonemap HDR image</h1><p>tonemap1 &#x3D; cv.createTonemap(gamma&#x3D;2.2)<br>res_debevec &#x3D; tonemap1.process(hdr_debevec.copy())<br>@endcode</p>
<h3 id="4-Merge-exposures-using-Mertens-fusion"><a href="#4-Merge-exposures-using-Mertens-fusion" class="headerlink" title="4. Merge exposures using Mertens fusion"></a>4. Merge exposures using Mertens fusion</h3><p>Here we show an alternative algorithm to merge the exposure images, where<br>we do not need the exposure times. We also do not need to use any tonemap<br>algorithm because the Mertens algorithm already gives us the result in the<br>range of [0..1].</p>
<p>@code{.py}</p>
<h1 id="Exposure-fusion-using-Mertens"><a href="#Exposure-fusion-using-Mertens" class="headerlink" title="Exposure fusion using Mertens"></a>Exposure fusion using Mertens</h1><p>merge_mertens &#x3D; cv.createMergeMertens()<br>res_mertens &#x3D; merge_mertens.process(img_list)<br>@endcode</p>
<h3 id="5-Convert-to-8-bit-and-save"><a href="#5-Convert-to-8-bit-and-save" class="headerlink" title="5. Convert to 8-bit and save"></a>5. Convert to 8-bit and save</h3><p>In order to save or display the results, we need to convert the data into 8-bit<br>integers in the range of [0..255].</p>
<p>@code{.py}</p>
<h1 id="Convert-datatype-to-8-bit-and-save"><a href="#Convert-datatype-to-8-bit-and-save" class="headerlink" title="Convert datatype to 8-bit and save"></a>Convert datatype to 8-bit and save</h1><p>res_debevec_8bit &#x3D; np.clip(res_debevec<em>255, 0, 255).astype(‘uint8’)<br>res_robertson_8bit &#x3D; np.clip(res_robertson</em>255, 0, 255).astype(‘uint8’)<br>res_mertens_8bit &#x3D; np.clip(res_mertens*255, 0, 255).astype(‘uint8’)</p>
<p>cv.imwrite(“ldr_debevec.jpg”, res_debevec_8bit)<br>cv.imwrite(“ldr_robertson.jpg”, res_robertson_8bit)<br>cv.imwrite(“fusion_mertens.jpg”, res_mertens_8bit)<br>@endcode</p>
<h2 id="Results"><a href="#Results" class="headerlink" title="Results"></a>Results</h2><p>You can see the different results but consider that each algorithm have additional<br>extra parameters that you should fit to get your desired outcome. Best practice is<br>to try the different methods and see which one performs best for your scene.</p>
<h3 id="Debevec"><a href="#Debevec" class="headerlink" title="Debevec:"></a>Debevec:</h3><p><img src="/images/ldr_debevec.jpg" alt="image"></p>
<h3 id="Robertson"><a href="#Robertson" class="headerlink" title="Robertson:"></a>Robertson:</h3><p><img src="/images/ldr_robertson.jpg" alt="image"></p>
<h3 id="Mertenes-Fusion"><a href="#Mertenes-Fusion" class="headerlink" title="Mertenes Fusion:"></a>Mertenes Fusion:</h3><p><img src="/images/fusion_mertens.jpg" alt="image"></p>
<h2 id="Estimating-Camera-Response-Function"><a href="#Estimating-Camera-Response-Function" class="headerlink" title="Estimating Camera Response Function"></a>Estimating Camera Response Function</h2><p>The camera response function (CRF) gives us the connection between the scene radiance<br>to the measured intensity values. The CRF if of great importance in some computer vision<br>algorithms, including HDR algorithms. Here we estimate the inverse camera response<br>function and use it for the HDR merge.</p>
<p>@code{.py}</p>
<h1 id="Estimate-camera-response-function-CRF"><a href="#Estimate-camera-response-function-CRF" class="headerlink" title="Estimate camera response function (CRF)"></a>Estimate camera response function (CRF)</h1><p>cal_debevec &#x3D; cv.createCalibrateDebevec()<br>crf_debevec &#x3D; cal_debevec.process(img_list, times&#x3D;exposure_times)<br>hdr_debevec &#x3D; merge_debevec.process(img_list, times&#x3D;exposure_times.copy(), response&#x3D;crf_debevec.copy())<br>cal_robertson &#x3D; cv.createCalibrateRobertson()<br>crf_robertson &#x3D; cal_robertson.process(img_list, times&#x3D;exposure_times)<br>hdr_robertson &#x3D; merge_robertson.process(img_list, times&#x3D;exposure_times.copy(), response&#x3D;crf_robertson.copy())<br>@endcode</p>
<p>The camera response function is represented by a 256-length vector for each color channel.<br>For this sequence we got the following estimation:</p>
<p><img src="/images/crf.jpg" alt="image"></p>
<h2 id="Additional-Resources"><a href="#Additional-Resources" class="headerlink" title="Additional Resources"></a>Additional Resources</h2><ol>
<li>Paul E Debevec and Jitendra Malik. Recovering high dynamic range radiance maps from photographs. In ACM SIGGRAPH 2008 classes, page 31. ACM, 2008. @cite DM97</li>
<li>Mark A Robertson, Sean Borman, and Robert L Stevenson. Dynamic range improvement through multiple exposures. In Image Processing, 1999. ICIP 99. Proceedings. 1999 International Conference on, volume 3, pages 159–163. IEEE, 1999. @cite RB99</li>
<li>Tom Mertens, Jan Kautz, and Frank Van Reeth. Exposure fusion. In Computer Graphics and Applications, 2007. PG’07. 15th Pacific Conference on, pages 382–390. IEEE, 2007. @cite MK07</li>
<li>Images from <a href="https://en.wikipedia.org/wiki/High-dynamic-range_imaging">Wikipedia-HDR</a></li>
</ol>
<h2 id="Exercises"><a href="#Exercises" class="headerlink" title="Exercises"></a>Exercises</h2><ol>
<li>Try all tonemap algorithms: cv::TonemapDrago, cv::TonemapMantiuk and cv::TonemapReinhard</li>
<li>Try changing the parameters in the HDR calibration and tonemap methods.</li>
</ol>
