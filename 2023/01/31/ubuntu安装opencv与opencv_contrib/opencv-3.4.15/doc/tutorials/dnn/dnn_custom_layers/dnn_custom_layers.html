<h1 id="Custom-deep-learning-layers-support-tutorial-dnn-custom-layers"><a href="#Custom-deep-learning-layers-support-tutorial-dnn-custom-layers" class="headerlink" title="Custom deep learning layers support {#tutorial_dnn_custom_layers}"></a>Custom deep learning layers support {#tutorial_dnn_custom_layers}</h1><p>@prev_tutorial{tutorial_dnn_javascript}</p>
<h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>Deep learning is a fast growing area. The new approaches to build neural networks<br>usually introduce new types of layers. They could be modifications of existing<br>ones or implement outstanding researching ideas.</p>
<p>OpenCV gives an opportunity to import and run networks from different deep learning<br>frameworks. There are a number of the most popular layers. However you can face<br>a problem that your network cannot be imported using OpenCV because of unimplemented layers.</p>
<p>The first solution is to create a feature request at <a href="https://github.com/opencv/opencv/issues">https://github.com/opencv/opencv/issues</a><br>mentioning details such a source of model and type of new layer. A new layer could<br>be implemented if OpenCV community shares this need.</p>
<p>The second way is to define a <strong>custom layer</strong> so OpenCV’s deep learning engine<br>will know how to use it. This tutorial is dedicated to show you a process of deep<br>learning models import customization.</p>
<h2 id="Define-a-custom-layer-in-C"><a href="#Define-a-custom-layer-in-C" class="headerlink" title="Define a custom layer in C++"></a>Define a custom layer in C++</h2><p>Deep learning layer is a building block of network’s pipeline.<br>It has connections to <strong>input blobs</strong> and produces results to <strong>output blobs</strong>.<br>There are trained <strong>weights</strong> and <strong>hyper-parameters</strong>.<br>Layers’ names, types, weights and hyper-parameters are stored in files are generated by<br>native frameworks during training. If OpenCV mets unknown layer type it throws an<br>exception trying to read a model:</p>
<pre><code>Unspecified error: Can&#39;t create layer &quot;layer_name&quot; of type &quot;MyType&quot; in function getLayerInstance
</code></pre>
<p>To import the model correctly you have to derive a class from cv::dnn::Layer with<br>the following methods:</p>
<p>@snippet dnn&#x2F;custom_layers.hpp A custom layer interface</p>
<p>And register it before the import:</p>
<p>@snippet dnn&#x2F;custom_layers.hpp Register a custom layer</p>
<p>@note <code>MyType</code> is a type of unimplemented layer from the thrown exception.</p>
<p>Let’s see what all the methods do:</p>
<ul>
<li>Constructor</li>
</ul>
<p>@snippet dnn&#x2F;custom_layers.hpp MyLayer::MyLayer</p>
<p>Retrieves hyper-parameters from cv::dnn::LayerParams. If your layer has trainable<br>weights they will be already stored in the Layer’s member cv::dnn::Layer::blobs.</p>
<ul>
<li>A static method <code>create</code></li>
</ul>
<p>@snippet dnn&#x2F;custom_layers.hpp MyLayer::create</p>
<p>This method should create an instance of you layer and return cv::Ptr with it.</p>
<ul>
<li>Output blobs’ shape computation</li>
</ul>
<p>@snippet dnn&#x2F;custom_layers.hpp MyLayer::getMemoryShapes</p>
<p>Returns layer’s output shapes depends on input shapes. You may request an extra<br>memory using <code>internals</code>.</p>
<ul>
<li>Run a layer</li>
</ul>
<p>@snippet dnn&#x2F;custom_layers.hpp MyLayer::forward</p>
<p>Implement a layer’s logic here. Compute outputs for given inputs.</p>
<p>@note OpenCV manages memory allocated for layers. In the most cases the same memory<br>can be reused between layers. So your <code>forward</code> implementation should not rely that<br>the second invocation of <code>forward</code> will has the same data at <code>outputs</code> and <code>internals</code>.</p>
<ul>
<li>Optional <code>finalize</code> method</li>
</ul>
<p>@snippet dnn&#x2F;custom_layers.hpp MyLayer::finalize</p>
<p>The chain of methods are the following: OpenCV deep learning engine calls <code>create</code><br>method once then it calls <code>getMemoryShapes</code> for an every created layer then you<br>can make some preparations depends on known input dimensions at cv::dnn::Layer::finalize.<br>After network was initialized only <code>forward</code> method is called for an every network’s input.</p>
<p>@note Varying input blobs’ sizes such height or width or batch size you make OpenCV<br>reallocate all the internal memory. That leads efficiency gaps. Try to initialize<br>and deploy models using a fixed batch size and image’s dimensions.</p>
<h2 id="Example-custom-layer-from-Caffe"><a href="#Example-custom-layer-from-Caffe" class="headerlink" title="Example: custom layer from Caffe"></a>Example: custom layer from Caffe</h2><p>Let’s create a custom layer <code>Interp</code> from <a href="https://github.com/cdmh/deeplab-public">https://github.com/cdmh/deeplab-public</a>.<br>It’s just a simple resize that takes an input blob of size <code>N x C x Hi x Wi</code> and returns<br>an output blob of size <code>N x C x Ho x Wo</code> where <code>N</code> is a batch size, <code>C</code> is a number of channels,<br><code>Hi x Wi</code> and <code>Ho x Wo</code> are input and output <code>height x width</code> correspondingly.<br>This layer has no trainable weights but it has hyper-parameters to specify an output size.</p>
<p>In example,</p>
<pre><code>layer {
  name: &quot;output&quot;
  type: &quot;Interp&quot;
  bottom: &quot;input&quot;
  top: &quot;output&quot;
  interp_param {
    height: 9
    width: 8
  }
}
</code></pre>
<p>This way our implementation can look like:</p>
<p>@snippet dnn&#x2F;custom_layers.hpp InterpLayer</p>
<p>Next we need to register a new layer type and try to import the model.</p>
<p>@snippet dnn&#x2F;custom_layers.hpp Register InterpLayer</p>
<h2 id="Example-custom-layer-from-TensorFlow"><a href="#Example-custom-layer-from-TensorFlow" class="headerlink" title="Example: custom layer from TensorFlow"></a>Example: custom layer from TensorFlow</h2><p>This is an example of how to import a network with <a href="https://www.tensorflow.org/versions/master/api_docs/python/tf/image/resize_bilinear">tf.image.resize_bilinear</a><br>operation. This is also a resize but with an implementation different from OpenCV’s or <code>Interp</code> above.</p>
<p>Let’s create a single layer network:</p>
<pre><code class="{.py}">inp = tf.placeholder(tf.float32, [2, 3, 4, 5], &#39;input&#39;)
resized = tf.image.resize_bilinear(inp, size=[9, 8], name=&#39;resize_bilinear&#39;)
</code></pre>
<p>OpenCV sees that TensorFlow’s graph in the following way:</p>
<pre><code>node {
  name: &quot;input&quot;
  op: &quot;Placeholder&quot;
  attr {
    key: &quot;dtype&quot;
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: &quot;resize_bilinear/size&quot;
  op: &quot;Const&quot;
  attr {
    key: &quot;dtype&quot;
    value {
      type: DT_INT32
    }
  }
  attr {
    key: &quot;value&quot;
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: &quot;\t\000\000\000\010\000\000\000&quot;
      }
    }
  }
}
node {
  name: &quot;resize_bilinear&quot;
  op: &quot;ResizeBilinear&quot;
  input: &quot;input:0&quot;
  input: &quot;resize_bilinear/size&quot;
  attr {
    key: &quot;T&quot;
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: &quot;align_corners&quot;
    value {
      b: false
    }
  }
}
library {
}
</code></pre>
<p>Custom layers import from TensorFlow is designed to put all layer’s <code>attr</code> into<br>cv::dnn::LayerParams but input <code>Const</code> blobs into cv::dnn::Layer::blobs.<br>In our case resize’s output shape will be stored in layer’s <code>blobs[0]</code>.</p>
<p>@snippet dnn&#x2F;custom_layers.hpp ResizeBilinearLayer</p>
<p>Next we register a layer and try to import the model.</p>
<p>@snippet dnn&#x2F;custom_layers.hpp Register ResizeBilinearLayer</p>
<h2 id="Define-a-custom-layer-in-Python"><a href="#Define-a-custom-layer-in-Python" class="headerlink" title="Define a custom layer in Python"></a>Define a custom layer in Python</h2><p>The following example shows how to customize OpenCV’s layers in Python.</p>
<p>Let’s consider <a href="https://arxiv.org/abs/1504.06375">Holistically-Nested Edge Detection</a><br>deep learning model. That was trained with one and only difference comparing to<br>a current version of <a href="http://caffe.berkeleyvision.org/">Caffe framework</a>. <code>Crop</code><br>layers that receive two input blobs and crop the first one to match spatial dimensions<br>of the second one used to crop from the center. Nowadays Caffe’s layer does it<br>from the top-left corner. So using the latest version of Caffe or OpenCV you’ll<br>get shifted results with filled borders.</p>
<p>Next we’re going to replace OpenCV’s <code>Crop</code> layer that makes top-left cropping by<br>a centric one.</p>
<ul>
<li>Create a class with <code>getMemoryShapes</code> and <code>forward</code> methods</li>
</ul>
<p>@snippet dnn&#x2F;edge_detection.py CropLayer</p>
<p>@note Both methods should return lists.</p>
<ul>
<li>Register a new layer.</li>
</ul>
<p>@snippet dnn&#x2F;edge_detection.py Register</p>
<p>That’s it! We’ve replaced an implemented OpenCV’s layer to a custom one.<br>You may find a full script in the <a href="https://github.com/opencv/opencv/tree/3.4/samples/dnn/edge_detection.py">source code</a>.</p>
<table border="0">
<tr>
<td>![](js_tutorials/js_assets/lena.jpg)</td>
<td>![](images/lena_hed.jpg)</td>
</tr>
</table>
