<h1 id="Cascade-Classifier-tutorial-cascade-classifier"><a href="#Cascade-Classifier-tutorial-cascade-classifier" class="headerlink" title="Cascade Classifier {#tutorial_cascade_classifier}"></a>Cascade Classifier {#tutorial_cascade_classifier}</h1><p>@next_tutorial{tutorial_traincascade}</p>
<h2 id="Goal"><a href="#Goal" class="headerlink" title="Goal"></a>Goal</h2><p>In this tutorial,</p>
<ul>
<li>We will learn how the Haar cascade object detection works.</li>
<li>We will see the basics of face detection and eye detection using the Haar Feature-based Cascade Classifiers</li>
<li>We will use the @ref cv::CascadeClassifier class to detect objects in a video stream. Particularly, we<br>will use the functions:<ul>
<li>@ref cv::CascadeClassifier::load to load a .xml classifier file. It can be either a Haar or a LBP classifier</li>
<li>@ref cv::CascadeClassifier::detectMultiScale to perform the detection.</li>
</ul>
</li>
</ul>
<h2 id="Theory"><a href="#Theory" class="headerlink" title="Theory"></a>Theory</h2><p>Object Detection using Haar feature-based cascade classifiers is an effective object detection<br>method proposed by Paul Viola and Michael Jones in their paper, “Rapid Object Detection using a<br>Boosted Cascade of Simple Features” in 2001. It is a machine learning based approach where a cascade<br>function is trained from a lot of positive and negative images. It is then used to detect objects in<br>other images.</p>
<p>Here we will work with face detection. Initially, the algorithm needs a lot of positive images<br>(images of faces) and negative images (images without faces) to train the classifier. Then we need<br>to extract features from it. For this, Haar features shown in the below image are used. They are just<br>like our convolutional kernel. Each feature is a single value obtained by subtracting sum of pixels<br>under the white rectangle from sum of pixels under the black rectangle.</p>
<p><img src="/images/haar_features.jpg" alt="image"></p>
<p>Now, all possible sizes and locations of each kernel are used to calculate lots of features. (Just<br>imagine how much computation it needs? Even a 24x24 window results over 160000 features). For each<br>feature calculation, we need to find the sum of the pixels under white and black rectangles. To solve<br>this, they introduced the integral image. However large your image, it reduces the calculations for a<br>given pixel to an operation involving just four pixels. Nice, isn’t it? It makes things super-fast.</p>
<p>But among all these features we calculated, most of them are irrelevant. For example, consider the<br>image below. The top row shows two good features. The first feature selected seems to focus on the<br>property that the region of the eyes is often darker than the region of the nose and cheeks. The<br>second feature selected relies on the property that the eyes are darker than the bridge of the nose.<br>But the same windows applied to cheeks or any other place is irrelevant. So how do we select the<br>best features out of 160000+ features? It is achieved by <strong>Adaboost</strong>.</p>
<p><img src="/images/haar.png" alt="image"></p>
<p>For this, we apply each and every feature on all the training images. For each feature, it finds the<br>best threshold which will classify the faces to positive and negative. Obviously, there will be<br>errors or misclassifications. We select the features with minimum error rate, which means they are<br>the features that most accurately classify the face and non-face images. (The process is not as simple as<br>this. Each image is given an equal weight in the beginning. After each classification, weights of<br>misclassified images are increased. Then the same process is done. New error rates are calculated.<br>Also new weights. The process is continued until the required accuracy or error rate is achieved or<br>the required number of features are found).</p>
<p>The final classifier is a weighted sum of these weak classifiers. It is called weak because it alone<br>can’t classify the image, but together with others forms a strong classifier. The paper says even<br>200 features provide detection with 95% accuracy. Their final setup had around 6000 features.<br>(Imagine a reduction from 160000+ features to 6000 features. That is a big gain).</p>
<p>So now you take an image. Take each 24x24 window. Apply 6000 features to it. Check if it is face or<br>not. Wow.. Isn’t it a little inefficient and time consuming? Yes, it is. The authors have a good<br>solution for that.</p>
<p>In an image, most of the image is non-face region. So it is a better idea to have a simple<br>method to check if a window is not a face region. If it is not, discard it in a single shot, and don’t<br>process it again. Instead, focus on regions where there can be a face. This way, we spend more time<br>checking possible face regions.</p>
<p>For this they introduced the concept of <strong>Cascade of Classifiers</strong>. Instead of applying all 6000<br>features on a window, the features are grouped into different stages of classifiers and applied one-by-one.<br>(Normally the first few stages will contain very many fewer features). If a window fails the first<br>stage, discard it. We don’t consider the remaining features on it. If it passes, apply the second stage<br>of features and continue the process. The window which passes all stages is a face region. How is<br>that plan!</p>
<p>The authors’ detector had 6000+ features with 38 stages with 1, 10, 25, 25 and 50 features in the first five<br>stages. (The two features in the above image are actually obtained as the best two features from<br>Adaboost). According to the authors, on average 10 features out of 6000+ are evaluated per<br>sub-window.</p>
<p>So this is a simple intuitive explanation of how Viola-Jones face detection works. Read the paper for<br>more details or check out the references in the Additional Resources section.</p>
<h2 id="Haar-cascade-Detection-in-OpenCV"><a href="#Haar-cascade-Detection-in-OpenCV" class="headerlink" title="Haar-cascade Detection in OpenCV"></a>Haar-cascade Detection in OpenCV</h2><p>OpenCV provides a training method (see @ref tutorial_traincascade) or pretrained models, that can be read using the @ref cv::CascadeClassifier::load method.<br>The pretrained models are located in the data folder in the OpenCV installation or can be found <a href="https://github.com/opencv/opencv/tree/3.4/data">here</a>.</p>
<p>The following code example will use pretrained Haar cascade models to detect faces and eyes in an image.<br>First, a @ref cv::CascadeClassifier is created and the necessary XML file is loaded using the @ref cv::CascadeClassifier::load method.<br>Afterwards, the detection is done using the @ref cv::CascadeClassifier::detectMultiScale method, which returns boundary rectangles for the detected faces or eyes.</p>
<p>@add_toggle_cpp<br>This tutorial code’s is shown lines below. You can also download it from<br><a href="https://github.com/opencv/opencv/tree/3.4/samples/cpp/tutorial_code/objectDetection/objectDetection.cpp">here</a><br>@include samples&#x2F;cpp&#x2F;tutorial_code&#x2F;objectDetection&#x2F;objectDetection.cpp<br>@end_toggle</p>
<p>@add_toggle_java<br>This tutorial code’s is shown lines below. You can also download it from<br><a href="https://github.com/opencv/opencv/tree/3.4/samples/java/tutorial_code/objectDetection/cascade_classifier/ObjectDetectionDemo.java">here</a><br>@include samples&#x2F;java&#x2F;tutorial_code&#x2F;objectDetection&#x2F;cascade_classifier&#x2F;ObjectDetectionDemo.java<br>@end_toggle</p>
<p>@add_toggle_python<br>This tutorial code’s is shown lines below. You can also download it from<br><a href="https://github.com/opencv/opencv/tree/3.4/samples/python/tutorial_code/objectDetection/cascade_classifier/objectDetection.py">here</a><br>@include samples&#x2F;python&#x2F;tutorial_code&#x2F;objectDetection&#x2F;cascade_classifier&#x2F;objectDetection.py<br>@end_toggle</p>
<h2 id="Result"><a href="#Result" class="headerlink" title="Result"></a>Result</h2><p>-#  Here is the result of running the code above and using as input the video stream of a built-in<br>    webcam:</p>
<pre><code>![](images/Cascade_Classifier_Tutorial_Result_Haar.jpg)

Be sure the program will find the path of files *haarcascade_frontalface_alt.xml* and
*haarcascade_eye_tree_eyeglasses.xml*. They are located in
*opencv/data/haarcascades*
</code></pre>
<p>-#  This is the result of using the file <em>lbpcascade_frontalface.xml</em> (LBP trained) for the face<br>    detection. For the eyes we keep using the file used in the tutorial.</p>
<pre><code>![](images/Cascade_Classifier_Tutorial_Result_LBP.jpg)
</code></pre>
<h2 id="Additional-Resources"><a href="#Additional-Resources" class="headerlink" title="Additional Resources"></a>Additional Resources</h2><p>-#  Paul Viola and Michael J. Jones. Robust real-time face detection. International Journal of Computer Vision, 57(2):137–154, 2004. @cite Viola04<br>-#  Rainer Lienhart and Jochen Maydt. An extended set of haar-like features for rapid object detection. In Image Processing. 2002. Proceedings. 2002 International Conference on, volume 1, pages I–900. IEEE, 2002. @cite Lienhart02<br>-#  Video Lecture on <a href="https://www.youtube.com/watch?v=WfdYYNamHZ8">Face Detection and Tracking</a><br>-#  An interesting interview regarding Face Detection by <a href="https://web.archive.org/web/20171204220159/http://www.makematics.com/research/viola-jones/">Adam<br>    Harvey</a><br>-#  <a href="https://vimeo.com/12774628">OpenCV Face Detection: Visualized</a> on Vimeo by Adam Harvey</p>
