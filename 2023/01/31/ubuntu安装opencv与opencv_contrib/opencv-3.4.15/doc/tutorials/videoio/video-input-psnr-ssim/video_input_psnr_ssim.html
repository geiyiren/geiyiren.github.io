<h1 id="Video-Input-with-OpenCV-and-similarity-measurement-tutorial-video-input-psnr-ssim"><a href="#Video-Input-with-OpenCV-and-similarity-measurement-tutorial-video-input-psnr-ssim" class="headerlink" title="Video Input with OpenCV and similarity measurement {#tutorial_video_input_psnr_ssim}"></a>Video Input with OpenCV and similarity measurement {#tutorial_video_input_psnr_ssim}</h1><p>@next_tutorial{tutorial_video_write}</p>
<h2 id="Goal"><a href="#Goal" class="headerlink" title="Goal"></a>Goal</h2><p>Today it is common to have a digital video recording system at your disposal. Therefore, you will<br>eventually come to the situation that you no longer process a batch of images, but video streams.<br>These may be of two kinds: real-time image feed (in the case of a webcam) or prerecorded and hard<br>disk drive stored files. Luckily OpenCV treats these two in the same manner, with the same C++<br>class. So here’s what you’ll learn in this tutorial:</p>
<ul>
<li>How to open and read video streams</li>
<li>Two ways for checking image similarity: PSNR and SSIM</li>
</ul>
<h2 id="The-source-code"><a href="#The-source-code" class="headerlink" title="The source code"></a>The source code</h2><p>As a test case where to show off these using OpenCV I’ve created a small program that reads in two<br>video files and performs a similarity check between them. This is something you could use to check<br>just how well a new video compressing algorithms works. Let there be a reference (original) video<br>like <a href="https://github.com/opencv/opencv/tree/3.4/samples/data/Megamind.avi">this small Megamind clip
</a> and <a href="https://github.com/opencv/opencv/tree/3.4/samples/data/Megamind_bugy.avi">a compressed<br>version of it </a>.<br>You may also find the source code and these video file in the<br><code>samples/data</code> folder of the OpenCV source library.</p>
<p>@add_toggle_cpp<br>@include cpp&#x2F;tutorial_code&#x2F;videoio&#x2F;video-input-psnr-ssim&#x2F;video-input-psnr-ssim.cpp<br>@end_toggle</p>
<p>@add_toggle_python<br>@include samples&#x2F;python&#x2F;tutorial_code&#x2F;videoio&#x2F;video-input-psnr-ssim.py<br>@end_toggle</p>
<h2 id="How-to-read-a-video-stream-online-camera-or-offline-file"><a href="#How-to-read-a-video-stream-online-camera-or-offline-file" class="headerlink" title="How to read a video stream (online-camera or offline-file)?"></a>How to read a video stream (online-camera or offline-file)?</h2><p>Essentially, all the functionalities required for video manipulation is integrated in the @ref cv::VideoCapture<br>C++ class. This on itself builds on the FFmpeg open source library. This is a basic<br>dependency of OpenCV so you shouldn’t need to worry about this. A video is composed of a succession<br>of images, we refer to these in the literature as frames. In case of a video file there is a <em>frame<br>rate</em> specifying just how long is between two frames. While for the video cameras usually there is a<br>limit of just how many frames they can digitize per second, this property is less important as at<br>any time the camera sees the current snapshot of the world.</p>
<p>The first task you need to do is to assign to a @ref cv::VideoCapture class its source. You can do<br>this either via the @ref cv::VideoCapture::VideoCapture or its @ref cv::VideoCapture::open function. If this argument is an<br>integer then you will bind the class to a camera, a device. The number passed here is the ID of the<br>device, assigned by the operating system. If you have a single camera attached to your system its ID<br>will probably be zero and further ones increasing from there. If the parameter passed to these is a<br>string it will refer to a video file, and the string points to the location and name of the file.<br>For example, to the upper source code a valid command line is:<br>@code{.bash}<br>video&#x2F;Megamind.avi video&#x2F;Megamind_bug.avi  35 10<br>@endcode<br>We do a similarity check. This requires a reference and a test case video file. The first two<br>arguments refer to this. Here we use a relative address. This means that the application will look<br>into its current working directory and open the video folder and try to find inside this the<br><em>Megamind.avi</em> and the <em>Megamind_bug.avi</em>.<br>@code{.cpp}<br>const string sourceReference &#x3D; argv[1],sourceCompareWith &#x3D; argv[2];</p>
<p>VideoCapture captRefrnc(sourceReference);<br>&#x2F;&#x2F; or<br>VideoCapture captUndTst;<br>captUndTst.open(sourceCompareWith);<br>@endcode<br>To check if the binding of the class to a video source was successful or not use the @ref cv::VideoCapture::isOpened<br>function:<br>@code{.cpp}<br>if ( !captRefrnc.isOpened())<br>  {<br>  cout  &lt;&lt; “Could not open reference “ &lt;&lt; sourceReference &lt;&lt; endl;<br>  return -1;<br>  }<br>@endcode<br>Closing the video is automatic when the objects destructor is called. However, if you want to close<br>it before this you need to call its @ref cv::VideoCapture::release function. The frames of the video are just<br>simple images. Therefore, we just need to extract them from the @ref cv::VideoCapture object and put<br>them inside a *Mat* one. The video streams are sequential. You may get the frames one after another<br>by the @ref cv::VideoCapture::read or the overloaded &gt;&gt; operator:<br>@code{.cpp}<br>Mat frameReference, frameUnderTest;<br>captRefrnc &gt;&gt; frameReference;<br>captUndTst.read(frameUnderTest);<br>@endcode<br>The upper read operations will leave empty the <em>Mat</em> objects if no frame could be acquired (either<br>cause the video stream was closed or you got to the end of the video file). We can check this with a<br>simple if:<br>@code{.cpp}<br>if( frameReference.empty()  || frameUnderTest.empty())<br>{<br> &#x2F;&#x2F; exit the program<br>}<br>@endcode<br>A read method is made of a frame grab and a decoding applied on that. You may call explicitly these<br>two by using the @ref cv::VideoCapture::grab and then the @ref cv::VideoCapture::retrieve functions.</p>
<p>Videos have many-many information attached to them besides the content of the frames. These are<br>usually numbers, however in some case it may be short character sequences (4 bytes or less). Due to<br>this to acquire these information there is a general function named @ref cv::VideoCapture::get that returns double<br>values containing these properties. Use bitwise operations to decode the characters from a double<br>type and conversions where valid values are only integers. Its single argument is the ID of the<br>queried property. For example, here we get the size of the frames in the reference and test case<br>video file; plus the number of frames inside the reference.<br>@code{.cpp}<br>Size refS &#x3D; Size((int) captRefrnc.get(CAP_PROP_FRAME_WIDTH),<br>                 (int) captRefrnc.get(CAP_PROP_FRAME_HEIGHT)),</p>
<p>cout &lt;&lt; “Reference frame resolution: Width&#x3D;” &lt;&lt; refS.width &lt;&lt; “  Height&#x3D;” &lt;&lt; refS.height<br>     &lt;&lt; “ of nr#: “ &lt;&lt; captRefrnc.get(CAP_PROP_FRAME_COUNT) &lt;&lt; endl;<br>@endcode<br>When you are working with videos you may often want to control these values yourself. To do this<br>there is a @ref cv::VideoCapture::set function. Its first argument remains the name of the property you want to<br>change and there is a second of double type containing the value to be set. It will return true if<br>it succeeds and false otherwise. Good examples for this is seeking in a video file to a given time<br>or frame:<br>@code{.cpp}<br>captRefrnc.set(CAP_PROP_POS_MSEC, 1.2);  &#x2F;&#x2F; go to the 1.2 second in the video<br>captRefrnc.set(CAP_PROP_POS_FRAMES, 10); &#x2F;&#x2F; go to the 10th frame of the video<br>&#x2F;&#x2F; now a read operation would read the frame at the set position<br>@endcode<br>For properties you can read and change look into the documentation of the @ref cv::VideoCapture::get and<br>@ref cv::VideoCapture::set functions.</p>
<h3 id="Image-similarity-PSNR-and-SSIM"><a href="#Image-similarity-PSNR-and-SSIM" class="headerlink" title="Image similarity - PSNR and SSIM"></a>Image similarity - PSNR and SSIM</h3><p>We want to check just how imperceptible our video converting operation went, therefore we need a<br>system to check frame by frame the similarity or differences. The most common algorithm used for<br>this is the PSNR (aka <strong>Peak signal-to-noise ratio</strong>). The simplest definition of this starts out<br>from the <em>mean squared error</em>. Let there be two images: I1 and I2; with a two dimensional size i and<br>j, composed of c number of channels.</p>
<p>\f[MSE &#x3D; \frac{1}{c<em>i</em>j} \sum{(I_1-I_2)^2}\f]</p>
<p>Then the PSNR is expressed as:</p>
<p>\f[PSNR &#x3D; 10 \cdot \log_{10} \left( \frac{MAX_I^2}{MSE} \right)\f]</p>
<p>Here the \f$MAX_I\f$ is the maximum valid value for a pixel. In case of the simple single byte image<br>per pixel per channel this is 255. When two images are the same the MSE will give zero, resulting in<br>an invalid divide by zero operation in the PSNR formula. In this case the PSNR is undefined and as<br>we’ll need to handle this case separately. The transition to a logarithmic scale is made because the<br>pixel values have a very wide dynamic range. All this translated to OpenCV and a function looks<br>like:</p>
<p>@add_toggle_cpp<br>@snippet cpp&#x2F;tutorial_code&#x2F;videoio&#x2F;video-input-psnr-ssim&#x2F;video-input-psnr-ssim.cpp get-psnr<br>@end_toggle</p>
<p>@add_toggle_python<br>@snippet samples&#x2F;python&#x2F;tutorial_code&#x2F;videoio&#x2F;video-input-psnr-ssim.py get-psnr<br>@end_toggle</p>
<p>Typically result values are anywhere between 30 and 50 for video compression, where higher is<br>better. If the images significantly differ you’ll get much lower ones like 15 and so. This<br>similarity check is easy and fast to calculate, however in practice it may turn out somewhat<br>inconsistent with human eye perception. The <strong>structural similarity</strong> algorithm aims to correct<br>this.</p>
<p>Describing the methods goes well beyond the purpose of this tutorial. For that I invite you to read<br>the article introducing it. Nevertheless, you can get a good image of it by looking at the OpenCV<br>implementation below.</p>
<p>@note<br>    SSIM is described more in-depth in the: “Z. Wang, A. C. Bovik, H. R. Sheikh and E. P.<br>    Simoncelli, “Image quality assessment: From error visibility to structural similarity,” IEEE<br>    Transactions on Image Processing, vol. 13, no. 4, pp. 600-612, Apr. 2004.” article.</p>
<p>@add_toggle_cpp<br>@snippet samples&#x2F;cpp&#x2F;tutorial_code&#x2F;videoio&#x2F;video-input-psnr-ssim&#x2F;video-input-psnr-ssim.cpp get-mssim<br>@end_toggle</p>
<p>@add_toggle_python<br>@snippet samples&#x2F;python&#x2F;tutorial_code&#x2F;videoio&#x2F;video-input-psnr-ssim.py get-mssim<br>@end_toggle</p>
<p>This will return a similarity index for each channel of the image. This value is between zero and<br>one, where one corresponds to perfect fit. Unfortunately, the many Gaussian blurring is quite<br>costly, so while the PSNR may work in a real time like environment (24 frame per second) this will<br>take significantly more than to accomplish similar performance results.</p>
<p>Therefore, the source code presented at the start of the tutorial will perform the PSNR measurement<br>for each frame, and the SSIM only for the frames where the PSNR falls below an input value. For<br>visualization purpose we show both images in an OpenCV window and print the PSNR and MSSIM values to<br>the console. Expect to see something like:</p>
<p><img src="/images/outputVideoInput.png"></p>
<p>You may observe a runtime instance of this on the <a href="https://www.youtube.com/watch?v=iOcNljutOgg">YouTube here</a>.</p>
<p>@youtube{iOcNljutOgg}</p>
