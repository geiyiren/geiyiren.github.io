<h1 id="Introduction-intro"><a href="#Introduction-intro" class="headerlink" title="Introduction {#intro}"></a>Introduction {#intro}</h1><p>OpenCV (Open Source Computer Vision Library: <a href="http://opencv.org/">http://opencv.org</a>) is an open-source BSD-licensed<br>library that includes several hundreds of computer vision algorithms. The document describes the<br>so-called OpenCV 2.x API, which is essentially a C++ API, as opposed to the C-based OpenCV 1.x API<br>(C API is deprecated and not tested with “C” compiler since OpenCV 2.4 releases)</p>
<p>OpenCV has a modular structure, which means that the package includes several shared or static<br>libraries. The following modules are available:</p>
<ul>
<li>@ref core (<strong>core</strong>) - a compact module defining basic data structures, including the dense<br>multi-dimensional array Mat and basic functions used by all other modules.</li>
<li>@ref imgproc (<strong>imgproc</strong>) - an image processing module that includes linear and non-linear image filtering,<br>geometrical image transformations (resize, affine and perspective warping, generic table-based<br>remapping), color space conversion, histograms, and so on.</li>
<li>@ref video (<strong>video</strong>) - a video analysis module that includes motion estimation, background subtraction,<br>and object tracking algorithms.</li>
<li>@ref calib3d (<strong>calib3d</strong>) - basic multiple-view geometry algorithms, single and stereo camera calibration,<br>object pose estimation, stereo correspondence algorithms, and elements of 3D reconstruction.</li>
<li>@ref features2d (<strong>features2d</strong>) - salient feature detectors, descriptors, and descriptor matchers.</li>
<li>@ref objdetect (<strong>objdetect</strong>) - detection of objects and instances of the predefined classes (for example,<br>faces, eyes, mugs, people, cars, and so on).</li>
<li>@ref highgui (<strong>highgui</strong>) - an easy-to-use interface to simple UI capabilities.</li>
<li>@ref videoio (<strong>videoio</strong>) - an easy-to-use interface to video capturing and video codecs.</li>
<li>… some other helper modules, such as FLANN and Google test wrappers, Python bindings, and<br>others.</li>
</ul>
<p>The further chapters of the document describe functionality of each module. But first, make sure to<br>get familiar with the common API concepts used thoroughly in the library.</p>
<h2 id="API-Concepts"><a href="#API-Concepts" class="headerlink" title="API Concepts"></a>API Concepts</h2><h3 id="cv-Namespace"><a href="#cv-Namespace" class="headerlink" title="cv Namespace"></a>cv Namespace</h3><p>All the OpenCV classes and functions are placed into the <code>cv</code> namespace. Therefore, to access this<br>functionality from your code, use the <code>cv::</code> specifier or <code>using namespace cv;</code> directive:</p>
<pre><code class=".cpp">#include &quot;opencv2/core.hpp&quot;
...
cv::Mat H = cv::findHomography(points1, points2, cv::RANSAC, 5);
...
</code></pre>
<p>or :</p>
<pre><code class=".cpp">    #include &quot;opencv2/core.hpp&quot;
    using namespace cv;
    ...
    Mat H = findHomography(points1, points2, RANSAC, 5 );
    ...
</code></pre>
<p>Some of the current or future OpenCV external names may conflict with STL or other libraries. In<br>this case, use explicit namespace specifiers to resolve the name conflicts:</p>
<pre><code class=".cpp">    Mat a(100, 100, CV_32F);
    randu(a, Scalar::all(1), Scalar::all(std::rand()));
    cv::log(a, a);
    a /= std::log(2.);
</code></pre>
<h3 id="Automatic-Memory-Management"><a href="#Automatic-Memory-Management" class="headerlink" title="Automatic Memory Management"></a>Automatic Memory Management</h3><p>OpenCV handles all the memory automatically.</p>
<p>First of all, std::vector, cv::Mat, and other data structures used by the functions and methods have<br>destructors that deallocate the underlying memory buffers when needed. This means that the<br>destructors do not always deallocate the buffers as in case of Mat. They take into account possible<br>data sharing. A destructor decrements the reference counter associated with the matrix data buffer.<br>The buffer is deallocated if and only if the reference counter reaches zero, that is, when no other<br>structures refer to the same buffer. Similarly, when a Mat instance is copied, no actual data is<br>really copied. Instead, the reference counter is incremented to memorize that there is another owner<br>of the same data. There is also the Mat::clone method that creates a full copy of the matrix data.<br>See the example below:</p>
<pre><code class=".cpp">    // create a big 8Mb matrix
    Mat A(1000, 1000, CV_64F);

    // create another header for the same matrix;
    // this is an instant operation, regardless of the matrix size.
    Mat B = A;
    // create another header for the 3-rd row of A; no data is copied either
    Mat C = B.row(3);
    // now create a separate copy of the matrix
    Mat D = B.clone();
    // copy the 5-th row of B to C, that is, copy the 5-th row of A
    // to the 3-rd row of A.
    B.row(5).copyTo(C);
    // now let A and D share the data; after that the modified version
    // of A is still referenced by B and C.
    A = D;
    // now make B an empty matrix (which references no memory buffers),
    // but the modified version of A will still be referenced by C,
    // despite that C is just a single row of the original A
    B.release();

    // finally, make a full copy of C. As a result, the big modified
    // matrix will be deallocated, since it is not referenced by anyone
    C = C.clone();
</code></pre>
<p>You see that the use of Mat and other basic structures is simple. But what about high-level classes<br>or even user data types created without taking automatic memory management into account? For them,<br>OpenCV offers the cv::Ptr template class that is similar to std::shared_ptr from C++11. So, instead of<br>using plain pointers:</p>
<pre><code class=".cpp">    T* ptr = new T(...);
</code></pre>
<p>you can use:</p>
<pre><code class=".cpp">    Ptr&lt;T&gt; ptr(new T(...));
</code></pre>
<p>or:</p>
<pre><code class=".cpp">    Ptr&lt;T&gt; ptr = makePtr&lt;T&gt;(...);
</code></pre>
<p><code>Ptr&lt;T&gt;</code> encapsulates a pointer to a T instance and a reference counter associated with the pointer.<br>See the cv::Ptr description for details.</p>
<h3 id="Automatic-Allocation-of-the-Output-Data"><a href="#Automatic-Allocation-of-the-Output-Data" class="headerlink" title="Automatic Allocation of the Output Data"></a>Automatic Allocation of the Output Data</h3><p>OpenCV deallocates the memory automatically, as well as automatically allocates the memory for<br>output function parameters most of the time. So, if a function has one or more input arrays (cv::Mat<br>instances) and some output arrays, the output arrays are automatically allocated or reallocated. The<br>size and type of the output arrays are determined from the size and type of input arrays. If needed,<br>the functions take extra parameters that help to figure out the output array properties.</p>
<p>Example:</p>
<pre><code class=".cpp">    #include &quot;opencv2/imgproc.hpp&quot;
    #include &quot;opencv2/highgui.hpp&quot;

    using namespace cv;

    int main(int, char**)
    {
        VideoCapture cap(0);
        if(!cap.isOpened()) return -1;

        Mat frame, edges;
        namedWindow(&quot;edges&quot;, WINDOW_AUTOSIZE);
        for(;;)
        {
            cap &gt;&gt; frame;
            cvtColor(frame, edges, COLOR_BGR2GRAY);
            GaussianBlur(edges, edges, Size(7,7), 1.5, 1.5);
            Canny(edges, edges, 0, 30, 3);
            imshow(&quot;edges&quot;, edges);
            if(waitKey(30) &gt;= 0) break;
        }
        return 0;
    }
</code></pre>
<p>The array frame is automatically allocated by the <code>&gt;&gt;</code> operator since the video frame resolution and<br>the bit-depth is known to the video capturing module. The array edges is automatically allocated by<br>the cvtColor function. It has the same size and the bit-depth as the input array. The number of<br>channels is 1 because the color conversion code cv::COLOR_BGR2GRAY is passed, which means a color to<br>grayscale conversion. Note that frame and edges are allocated only once during the first execution<br>of the loop body since all the next video frames have the same resolution. If you somehow change the<br>video resolution, the arrays are automatically reallocated.</p>
<p>The key component of this technology is the Mat::create method. It takes the desired array size and<br>type. If the array already has the specified size and type, the method does nothing. Otherwise, it<br>releases the previously allocated data, if any (this part involves decrementing the reference<br>counter and comparing it with zero), and then allocates a new buffer of the required size. Most<br>functions call the Mat::create method for each output array, and so the automatic output data<br>allocation is implemented.</p>
<p>Some notable exceptions from this scheme are cv::mixChannels, cv::RNG::fill, and a few other<br>functions and methods. They are not able to allocate the output array, so you have to do this in<br>advance.</p>
<h3 id="Saturation-Arithmetics"><a href="#Saturation-Arithmetics" class="headerlink" title="Saturation Arithmetics"></a>Saturation Arithmetics</h3><p>As a computer vision library, OpenCV deals a lot with image pixels that are often encoded in a<br>compact, 8- or 16-bit per channel, form and thus have a limited value range. Furthermore, certain<br>operations on images, like color space conversions, brightness&#x2F;contrast adjustments, sharpening,<br>complex interpolation (bi-cubic, Lanczos) can produce values out of the available range. If you just<br>store the lowest 8 (16) bits of the result, this results in visual artifacts and may affect a<br>further image analysis. To solve this problem, the so-called <em>saturation</em> arithmetics is used. For<br>example, to store r, the result of an operation, to an 8-bit image, you find the nearest value<br>within the 0..255 range:</p>
<p>\f[I(x,y)&#x3D; \min ( \max (\textrm{round}(r), 0), 255)\f]</p>
<p>Similar rules are applied to 8-bit signed, 16-bit signed and unsigned types. This semantics is used<br>everywhere in the library. In C++ code, it is done using the <code>cv::saturate_cast&lt;&gt;</code> functions that<br>resemble standard C++ cast operations. See below the implementation of the formula provided above:</p>
<pre><code class=".cpp">    I.at&lt;uchar&gt;(y, x) = saturate_cast&lt;uchar&gt;(r);
</code></pre>
<p>where cv::uchar is an OpenCV 8-bit unsigned integer type. In the optimized SIMD code, such SSE2<br>instructions as paddusb, packuswb, and so on are used. They help achieve exactly the same behavior<br>as in C++ code.</p>
<p>@note Saturation is not applied when the result is 32-bit integer.</p>
<h3 id="Fixed-Pixel-Types-Limited-Use-of-Templates"><a href="#Fixed-Pixel-Types-Limited-Use-of-Templates" class="headerlink" title="Fixed Pixel Types. Limited Use of Templates"></a>Fixed Pixel Types. Limited Use of Templates</h3><p>Templates is a great feature of C++ that enables implementation of very powerful, efficient and yet<br>safe data structures and algorithms. However, the extensive use of templates may dramatically<br>increase compilation time and code size. Besides, it is difficult to separate an interface and<br>implementation when templates are used exclusively. This could be fine for basic algorithms but not<br>good for computer vision libraries where a single algorithm may span thousands lines of code.<br>Because of this and also to simplify development of bindings for other languages, like Python, Java,<br>Matlab that do not have templates at all or have limited template capabilities, the current OpenCV<br>implementation is based on polymorphism and runtime dispatching over templates. In those places<br>where runtime dispatching would be too slow (like pixel access operators), impossible (generic<br><code>cv::Ptr&lt;&gt;</code> implementation), or just very inconvenient (<code>cv::saturate_cast&lt;&gt;()</code>) the current implementation<br>introduces small template classes, methods, and functions. Anywhere else in the current OpenCV<br>version the use of templates is limited.</p>
<p>Consequently, there is a limited fixed set of primitive data types the library can operate on. That<br>is, array elements should have one of the following types:</p>
<ul>
<li>8-bit unsigned integer (uchar)</li>
<li>8-bit signed integer (schar)</li>
<li>16-bit unsigned integer (ushort)</li>
<li>16-bit signed integer (short)</li>
<li>32-bit signed integer (int)</li>
<li>32-bit floating-point number (float)</li>
<li>64-bit floating-point number (double)</li>
<li>a tuple of several elements where all elements have the same type (one of the above). An array<br>whose elements are such tuples, are called multi-channel arrays, as opposite to the<br>single-channel arrays, whose elements are scalar values. The maximum possible number of<br>channels is defined by the #CV_CN_MAX constant, which is currently set to 512.</li>
</ul>
<p>For these basic types, the following enumeration is applied:</p>
<pre><code class=".cpp">    enum { CV_8U=0, CV_8S=1, CV_16U=2, CV_16S=3, CV_32S=4, CV_32F=5, CV_64F=6 };
</code></pre>
<p>Multi-channel (n-channel) types can be specified using the following options:</p>
<ul>
<li>#CV_8UC1 … #CV_64FC4 constants (for a number of channels from 1 to 4)</li>
<li>CV_8UC(n) … CV_64FC(n) or CV_MAKETYPE(CV_8U, n) … CV_MAKETYPE(CV_64F, n) macros when<br>the number of channels is more than 4 or unknown at the compilation time.</li>
</ul>
<p>@note <code>#CV_32FC1 == #CV_32F, #CV_32FC2 == #CV_32FC(2) == #CV_MAKETYPE(CV_32F, 2)</code>, and<br><code>#CV_MAKETYPE(depth, n) == ((depth&amp;7) + ((n-1)&lt;&lt;3)</code>. This means that the constant type is formed from the<br>depth, taking the lowest 3 bits, and the number of channels minus 1, taking the next<br><code>log2(CV_CN_MAX)</code> bits.</p>
<p>Examples:</p>
<pre><code class=".cpp">    Mat mtx(3, 3, CV_32F); // make a 3x3 floating-point matrix
    Mat cmtx(10, 1, CV_64FC2); // make a 10x1 2-channel floating-point
                               // matrix (10-element complex vector)
    Mat img(Size(1920, 1080), CV_8UC3); // make a 3-channel (color) image
                                        // of 1920 columns and 1080 rows.
    Mat grayscale(image.size(), CV_MAKETYPE(image.depth(), 1)); // make a 1-channel image of
                                                                // the same size and same
                                                                // channel type as img
</code></pre>
<p>Arrays with more complex elements cannot be constructed or processed using OpenCV. Furthermore, each<br>function or method can handle only a subset of all possible array types. Usually, the more complex<br>the algorithm is, the smaller the supported subset of formats is. See below typical examples of such<br>limitations:</p>
<ul>
<li>The face detection algorithm only works with 8-bit grayscale or color images.</li>
<li>Linear algebra functions and most of the machine learning algorithms work with floating-point<br>arrays only.</li>
<li>Basic functions, such as cv::add, support all types.</li>
<li>Color space conversion functions support 8-bit unsigned, 16-bit unsigned, and 32-bit<br>floating-point types.</li>
</ul>
<p>The subset of supported types for each function has been defined from practical needs and could be<br>extended in future based on user requests.</p>
<h3 id="InputArray-and-OutputArray"><a href="#InputArray-and-OutputArray" class="headerlink" title="InputArray and OutputArray"></a>InputArray and OutputArray</h3><p>Many OpenCV functions process dense 2-dimensional or multi-dimensional numerical arrays. Usually,<br>such functions take cppMat as parameters, but in some cases it’s more convenient to use<br><code>std::vector&lt;&gt;</code> (for a point set, for example) or <code>cv::Matx&lt;&gt;</code> (for 3x3 homography matrix and such). To<br>avoid many duplicates in the API, special “proxy” classes have been introduced. The base “proxy”<br>class is cv::InputArray. It is used for passing read-only arrays on a function input. The derived from<br>InputArray class cv::OutputArray is used to specify an output array for a function. Normally, you should<br>not care of those intermediate types (and you should not declare variables of those types<br>explicitly) - it will all just work automatically. You can assume that instead of<br>InputArray&#x2F;OutputArray you can always use <code>Mat</code>, <code>std::vector&lt;&gt;</code>, <code>cv::Matx&lt;&gt;</code>, <code>cv::Vec&lt;&gt;</code> or <code>cv::Scalar</code>. When a<br>function has an optional input or output array, and you do not have or do not want one, pass<br>cv::noArray().</p>
<h3 id="Error-Handling"><a href="#Error-Handling" class="headerlink" title="Error Handling"></a>Error Handling</h3><p>OpenCV uses exceptions to signal critical errors. When the input data has a correct format and<br>belongs to the specified value range, but the algorithm cannot succeed for some reason (for example,<br>the optimization algorithm did not converge), it returns a special error code (typically, just a<br>boolean variable).</p>
<p>The exceptions can be instances of the cv::Exception class or its derivatives. In its turn,<br>cv::Exception is a derivative of std::exception. So it can be gracefully handled in the code using<br>other standard C++ library components.</p>
<p>The exception is typically thrown either using the <code>#CV_Error(errcode, description)</code> macro, or its<br>printf-like <code>#CV_Error_(errcode, (printf-spec, printf-args))</code> variant, or using the<br>#CV_Assert(condition) macro that checks the condition and throws an exception when it is not<br>satisfied. For performance-critical code, there is #CV_DbgAssert(condition) that is only retained in<br>the Debug configuration. Due to the automatic memory management, all the intermediate buffers are<br>automatically deallocated in case of a sudden error. You only need to add a try statement to catch<br>exceptions, if needed: :</p>
<pre><code class=".cpp">    try
    {
        ... // call OpenCV
    }
    catch (const cv::Exception&amp; e)
    {
        const char* err_msg = e.what();
        std::cout &lt;&lt; &quot;exception caught: &quot; &lt;&lt; err_msg &lt;&lt; std::endl;
    }
</code></pre>
<h3 id="Multi-threading-and-Re-enterability"><a href="#Multi-threading-and-Re-enterability" class="headerlink" title="Multi-threading and Re-enterability"></a>Multi-threading and Re-enterability</h3><p>The current OpenCV implementation is fully re-enterable.<br>That is, the same function or the same methods of different class instances<br>can be called from different threads.<br>Also, the same Mat can be used in different threads<br>because the reference-counting operations use the architecture-specific atomic instructions.</p>
