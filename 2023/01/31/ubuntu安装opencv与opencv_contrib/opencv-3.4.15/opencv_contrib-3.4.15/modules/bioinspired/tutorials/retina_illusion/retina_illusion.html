<h1 id="Processing-images-causing-optical-illusions-tutorial-bioinspired-retina-illusion"><a href="#Processing-images-causing-optical-illusions-tutorial-bioinspired-retina-illusion" class="headerlink" title="Processing images causing optical illusions {#tutorial_bioinspired_retina_illusion}"></a>Processing images causing optical illusions {#tutorial_bioinspired_retina_illusion}</h1><h2 id="Goal"><a href="#Goal" class="headerlink" title="Goal"></a>Goal</h2><p>I will show here how the bioinspired module can reproduce a well-known optical illusion that<br>our eyes perceive in certain light condition: The Adelson checkerboard.</p>
<h2 id="The-Adelson-checkerboard"><a href="#The-Adelson-checkerboard" class="headerlink" title="The Adelson checkerboard"></a>The Adelson checkerboard</h2><p>Looking at the checkerboard image below, human eyes perceive the “B” square lighter than the<br>“A” square, although they are pictured in the very same RGB color.<br>Of course in the physical world, checkerboard has a “B” square which is lighter than “A”, but in this image the<br>shadow of the green cylinder casting over the “B” square ends up in making the “A” and “B”<br>squares actually having the same luminance.</p>
<p><img src="/images/checkershadow_illusion4med.jpg" alt="Adelson checkerboard"></p>
<p>Our visual system does “compensate” for the shadow, making us perceive the “B” square lighter,<br>as the shadow wouldn’t be there. This is due to local adaptation process that is performed in the<br>foveal area.</p>
<p>You may find the original Adelson’s explanation <a href="http://web.mit.edu/persci/people/adelson/checkershadow_description.html">here</a>.</p>
<p>Proof: You can convince yourself by using an image manipulation program, cutting out a portion<br>of the two squares, and looking at them without any background. You can also measure the RGB<br>values of the two squares with the picker tool.</p>
<p>In this image I’ve cropped a little piece of the A and B squares and I’ve put them side-by-side.<br>It should be quite evident they have the same luminance.<br><img src="/images/checkershadow_illusion4med_proof.jpg" alt="Adelson checkerboard proof"></p>
<p>It’s worth to know that this illusion works because the checkerboard image, as you may see it<br>on your laptop, casts on your retina with dimensions that cause the retina local adaptation to take<br>into account both the two squares at the same time.</p>
<p>The foveal vision area is something like one inch at one meter (and because your eye moves<br>continuously, with the so called “saccades”, your brain is able to reconstruct the entire<br>color scene in real time). This means that one single letter, either A or B, can hit<br>your fovea at any time.</p>
<p>The point is that, even if you can’t see both letters at the same time in a single eye fixation,<br>when looking at one letter your fovea also takes into account light information from what is around it.<br>This means that the fovea actually perceives also the neighboring cells.</p>
<p>The net effect is that when looking at one area, your eye locally adapts to luminance, filters noise,<br>enforces contours, etc. considering what <em>surrounds</em> this area, and this makes the illusion work. We<br>say that <em>the retina works in a “center surround” manner</em>.</p>
<p>So, the “A” cell being surrounded by lighter cells can be perceived darker. As a comparison, cell “B” ‘s<br>neighborhood is darker and the cell “B” is then perceived lighter.</p>
<p>Finally, since shadow edges are soft, retina eliminates this information. Then shadows do not disrupt the overall chessboard observation making possible to “confidently being fooled” by the perceived cells luminance.</p>
<h2 id="Reproducing-the-illusion"><a href="#Reproducing-the-illusion" class="headerlink" title="Reproducing the illusion"></a>Reproducing the illusion</h2><p>The bioinspired module does mimic (also) the parvocellular retina process, that is our foveal<br>vision, and it does reproduce our eyes’ local adaptation.</p>
<p>This means we can expect the parvo channel output to really contain luminance values<br>similar to those we perceive with our eyes. Specifically, in this case we expect the “B” square<br>RGB values to be actually lighter than the “A” ones.</p>
<p>To correctly mimic what our eye does we need opencv to do the local adaptation on the right<br>image portion. This means we have to ensure that the opencv’s notion of “local” does match with our<br>image’s dimensions, otherwise the local adaptation wouldn’t work as expected.</p>
<p>For this reason we may have to adjust the <strong>hcellsSpatialConstant</strong> parameter (that technically<br>specifies the low spatial cut frequency, or slow luminance changes sensitivity) depending by<br>the image resolution.</p>
<p>For the image in this tutorial, the default retina parameters should be fine.</p>
<p>In order to feed the image to the bioinspired module, you can use either your own code or<br>the <em>example_bioinspired_retinaDemo</em> example that comes with the bioinspired module.</p>
<p>Running<br>@code{.sh}<br>example_bioinspired_retinaDemo -image checkershadow_illusion4med.jpg<br>@endcode</p>
<p>will cause our image to be processed in both parvocellular and magnocellular channels (we are interested<br>just in the first one).</p>
<p>If you choose to use your own code, please note that the parvocellular (and magnocellular)<br>channel does require some iterations (frames to be processed) before actually getting steady.</p>
<p>Actually parvo (and magno) channel do cares about temporal information. That is, when you start<br>feeding frames, it is similar to you with closed eyes; then you open them and you see the chessboard.</p>
<p>This is a static image but your retina just starts moving to a new context (eyes opening) and<br>has to adapt.</p>
<p>While in this transient state the luminance information do matters, and you see more or less<br>the absolute luminance values. Absolute luminance is exactly what you need <strong>not</strong> to look at in<br>order to reproduce the illusion..</p>
<p>As soon as steady state is reached, you receive more contextual luminance information. Your eyes work<br>in a center-surround manner and take into account the neighborhood luminance to evaluate the<br>region of interest luminance level. And that’s when our illusion comes out !</p>
<p>This is something that you don’t need to worry about when you process videos, because you are<br>naturally feeding the virtual retina with several frames, but you have to take care of it in<br>order to process a single frame.</p>
<p>What you will actually need to do when processing a single frame, and you only need steady state response,<br>is to repeatedly feed the retina with the same frame (this is what the example code does), as you<br>would do with a still video. Alternatively you can set retina temporal parameters to 0 to get steady state immediately<br>(<strong>photoreceptorsTemporalConstant</strong> and <strong>hcellsTemporalConstant</strong> parameters of the xml file); however<br>in this case you should be aware that you are now making experiments with something that is<br>deliberately less accurate in reproducing the behaviour of a real retina!</p>
<p>Here there is a small fragment of python code we used to process the image. It does 20<br>iterations. This is an arbitrary number that we found experimentally to be (more than)<br>enough</p>
<p>@code{.py}<br>import cv2 as cv</p>
<p>inputImage &#x3D; cv.imread(‘checkershadow_illusion4med.jpg’, 1)<br>retina &#x3D; cv.bioinspired.createRetina((inputImage.shape[1], inputImage.shape[0]))</p>
<h1 id="the-retina-object-is-created-with-default-parameters-If-you-want-to-read"><a href="#the-retina-object-is-created-with-default-parameters-If-you-want-to-read" class="headerlink" title="the retina object is created with default parameters. If you want to read"></a>the retina object is created with default parameters. If you want to read</h1><h1 id="the-parameters-from-an-external-XML-file-uncomment-the-next-line"><a href="#the-parameters-from-an-external-XML-file-uncomment-the-next-line" class="headerlink" title="the parameters from an external XML file, uncomment the next line"></a>the parameters from an external XML file, uncomment the next line</h1><p>#retina.setup(‘MyRetinaParameters.xml’)</p>
<h1 id="feed-the-retina-with-several-frames-in-order-to-reach-‘steady’-state"><a href="#feed-the-retina-with-several-frames-in-order-to-reach-‘steady’-state" class="headerlink" title="feed the retina with several frames, in order to reach ‘steady’ state"></a>feed the retina with several frames, in order to reach ‘steady’ state</h1><p>for i in range(20):<br>    retina.run(inputImage)</p>
<h1 id="get-our-processed-image"><a href="#get-our-processed-image" class="headerlink" title="get our processed image :)"></a>get our processed image :)</h1><p>retinaOut_parvo &#x3D; retina.getParvo()</p>
<h1 id="show-both-the-original-image-and-the-processed-one"><a href="#show-both-the-original-image-and-the-processed-one" class="headerlink" title="show both the original image and the processed one"></a>show both the original image and the processed one</h1><p>cv.imshow(‘image’, inputImage)<br>cv.imshow(‘retina parvo out’, retinaOut_parvo)</p>
<h1 id="wait-for-a-key-to-be-pressed-and-exit"><a href="#wait-for-a-key-to-be-pressed-and-exit" class="headerlink" title="wait for a key to be pressed and exit"></a>wait for a key to be pressed and exit</h1><p>cv.waitKey(0)<br>cv.destroyAllWindows()</p>
<h1 id="write-the-output-image-on-a-file"><a href="#write-the-output-image-on-a-file" class="headerlink" title="write the output image on a file"></a>write the output image on a file</h1><p>cv.imwrite(‘checkershadow_parvo.png’, retinaOut_parvo)<br>@endcode</p>
<p>Whatever method you used to process the image, you should end up<br>with something like this:</p>
<p><img src="/images/checkershadow_parvo.png" alt="Parvo output for adelson checkerboard"></p>
<h2 id="Analyzing-the-results"><a href="#Analyzing-the-results" class="headerlink" title="Analyzing the results"></a>Analyzing the results</h2><p>We expected that the “B” pixels in the parvo channel output are lighter than “A” ones.</p>
<p>.. And in fact that is!</p>
<p>Looking at the resulting image might not tell us so much at a first glance: the “B” square looks<br>lighter than “A” to our eyes, as it did in the input image. The difference is that, contrarily to<br>the input image, now the RGB values of the pixels are actually lighter; note that when looking at<br>the output image, we are actually  applying the parvocellular process<br>two times: first in the bioinspired module, then in our eyes.<br>We can convince ourselves that the illusion appeared<br>in the computed image by measuring the squares’ luminance with the image manipulation program<br>and the picker tool, or by cropping pieces of the squares and putting them side-by-side.</p>
<p>In the following image I cropped a portion of square “A” and a portion of square “B”, and I placed<br>them side-by-side, as I did for the original Adelson image.</p>
<p><img src="/images/checkershadow_parvo_proof.png" alt="Illusion reproduced"></p>
<p>It should be quite evident that the “B” square is really lighter than the “A” square! Congratulations: you have<br>just reproduced the Adelson illusion with the Bioinspired module!</p>
<h2 id="Credits"><a href="#Credits" class="headerlink" title="Credits"></a>Credits</h2><p>I want to thank:</p>
<p><strong>Alexandre Benoit</strong> - for being so kind of explaining me how this whole thing works, for giving me the<br>opportunity of writing this tutorial, and for reviewing it.</p>
<p><strong>Edward Adelson</strong> - for allowing me to freely use his checkerboard image.</p>
<p><strong>Antonio Cuni</strong>  - for reviewing this tutorial and for writing the Python code.</p>
