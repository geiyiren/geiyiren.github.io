<h1 id="Camera-Motion-Estimation-tutorial-sfm-trajectory-estimation"><a href="#Camera-Motion-Estimation-tutorial-sfm-trajectory-estimation" class="headerlink" title="Camera Motion Estimation {#tutorial_sfm_trajectory_estimation}"></a>Camera Motion Estimation {#tutorial_sfm_trajectory_estimation}</h1><h2 id="Goal"><a href="#Goal" class="headerlink" title="Goal"></a>Goal</h2><p>In this tutorial you will learn how to use the reconstruction api for camera motion estimation:</p>
<ul>
<li>Load a file with the tracked 2d points and build the container over all the frames.</li>
<li>Run libmv reconstruction pipeline.</li>
<li>Show obtained results using Viz.</li>
</ul>
<h2 id="Code"><a href="#Code" class="headerlink" title="Code"></a>Code</h2><p>@include sfm&#x2F;samples&#x2F;trajectory_reconstruction.cpp</p>
<h2 id="Explanation"><a href="#Explanation" class="headerlink" title="Explanation"></a>Explanation</h2><p>Firstly, we need to load the file containing the 2d points tracked over all the frames and construct the container to feed the reconstruction api. In this case the tracked 2d points will have the following structure, a vector of 2d points array, where each inner array represents a different frame. Every frame is composed by a list of 2d points which e.g. the first point in frame 1 is the same point in frame 2. If there is no point in a frame the assigned value will be (-1,-1):</p>
<p>@code{.cpp}<br>  &#x2F;* Build the following structure data<br>   *</p>
<ul>
<li><pre><code>       frame1           frame2           frameN
</code></pre>
</li>
<li>track1 | (x11,y11) | -&gt; | (x12,y12) | -&gt; | (x1N,y1N) |</li>
<li>track2 | (x21,y11) | -&gt; | (x22,y22) | -&gt; | (x2N,y2N) |</li>
<li>trackN | (xN1,yN1) | -&gt; | (xN2,yN2) | -&gt; | (xNN,yNN) |</li>
<li></li>
<li></li>
<li>In case a marker (x,y) does not appear in a frame its</li>
<li>values will be (-1,-1).<br>   *&#x2F;</li>
</ul>
<p>   …</p>
<p>  for (int i &#x3D; 0; i &lt; n_frames; ++i)<br>  {<br>    Mat_<double> frame(2, n_tracks);</p>
<pre><code>for (int j = 0; j &lt; n_tracks; ++j)
{
  frame(0,j) = tracks[j][i][0];
  frame(1,j) = tracks[j][i][1];
}
points2d.push_back(Mat(frame));
</code></pre>
<p>  }<br>@endcode</p>
<p>Secondly, the built container will be used to feed the reconstruction api. It is important outline that the estimated results must be stored in a vector<Mat>:</p>
<p>@code{.cpp}<br>  bool is_projective &#x3D; true;<br>  vector<Mat> Rs_est, ts_est, points3d_estimated;<br>  reconstruct(points2d, Rs_est, ts_est, K, points3d_estimated, is_projective);</p>
<p>  &#x2F;&#x2F; Print output</p>
<p>  cout &lt;&lt; “\n—————————-\n” &lt;&lt; endl;<br>  cout &lt;&lt; “Reconstruction: “ &lt;&lt; endl;<br>  cout &lt;&lt; “&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;” &lt;&lt; endl;<br>  cout &lt;&lt; “Estimated 3D points: “ &lt;&lt; points3d_estimated.size() &lt;&lt; endl;<br>  cout &lt;&lt; “Estimated cameras: “ &lt;&lt; Rs_est.size() &lt;&lt; endl;<br>  cout &lt;&lt; “Refined intrinsics: “ &lt;&lt; endl &lt;&lt; K &lt;&lt; endl &lt;&lt; endl;<br>@endcode</p>
<p>Finally, the obtained results will be shown in Viz, in this case reproducing the camera with an oscillation effect.</p>
<h2 id="Usage-and-Results"><a href="#Usage-and-Results" class="headerlink" title="Usage and Results"></a>Usage and Results</h2><p>In order to run this sample we need to specify the path to the tracked points file, the focal length of the camera in addition to the center projection coordinates (in pixels). You can find a sample file in samples&#x2F;data&#x2F;desktop_trakcks.txt</p>
<p>@code{.bash}<br>  .&#x2F;example_sfm_trajectory_reconstruction desktop_tracks.txt 1914 640 360<br>@endcode</p>
<p>The following picture shows the obtained camera motion obtained from the tracked 2d points:</p>
<p><img src="/pics/desktop_trajectory.png"></p>
