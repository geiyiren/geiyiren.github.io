<h1 id="Training-the-learning-based-white-balance-algorithm-tutorial-xphoto-training-white-balance"><a href="#Training-the-learning-based-white-balance-algorithm-tutorial-xphoto-training-white-balance" class="headerlink" title="Training the learning-based white balance algorithm {#tutorial_xphoto_training_white_balance}"></a>Training the learning-based white balance algorithm {#tutorial_xphoto_training_white_balance}</h1><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>Many traditional white balance algorithms are statistics-based, i.e. they rely on the fact that certain assumptions should hold in properly white-balanced images<br>like the well-known grey-world assumption. However, better results can often be achieved by leveraging large datasets of images with ground-truth<br>illuminants in a learning-based framework. This tutorial demonstrates how to train a learning-based white balance algorithm and evaluate the quality of the results.</p>
<h2 id="How-to-train-a-model"><a href="#How-to-train-a-model" class="headerlink" title="How to train a model"></a>How to train a model</h2><p>-#  Download a dataset for training. In this tutorial we will use the <a href="http://www.cs.sfu.ca/~colour/data/shi_gehler/">Gehler-Shi dataset </a>. Extract all 568 training images<br>    in one folder. A file containing ground-truth illuminant values (real_illum_568..mat) is downloaded separately.</p>
<p>-#  We will be using a <a href="https://github.com/opencv/opencv_contrib/tree/master/modules/xphoto/samples/learn_color_balance.py">Python script </a> for training.<br>    Call it with the following parameters:<br>    @code<br>        python learn_color_balance.py -i <path to the folder with training images> -g <path to real_illum_568..mat> -r 0,378 –num_trees 30 –max_tree_depth 6 –num_augmented 0<br>    @endcode<br>    This should start training a model on the first 378 images (2&#x2F;3 of the whole dataset). We set the size of the model to be 30 regression tree pairs per feature and limit<br>    the tree depth to be no more then 6. By default the resulting model will be saved to color_balance_model.yml</p>
<p>-#  Use the trained model by passing its path when constructing an instance of LearningBasedWB:<br>    @code{.cpp}<br>    Ptr<a href="xphoto::LearningBasedWB">xphoto::LearningBasedWB</a> wb &#x3D; xphoto::createLearningBasedWB(modelFilename);<br>    @endcode</p>
<h2 id="How-to-evaluate-a-model"><a href="#How-to-evaluate-a-model" class="headerlink" title="How to evaluate a model"></a>How to evaluate a model</h2><p>-#  We will use a <a href="https://github.com/opencv/opencv_contrib/tree/master/modules/xphoto/samples/color_balance_benchmark.py">benchmarking script </a> to compare<br>    the model that we’ve trained with the classic grey-world algorithm on the remaining 1&#x2F;3 of the dataset. Call the script with the following parameters:<br>    @code<br>        python color_balance_benchmark.py -a grayworld,learning_based:color_balance_model.yml -m <full path to folder containing the model> -i <path to the folder with training images> -g <path to real_illum_568..mat> -r 379,567 -d “img”<br>    @endcode</p>
<p>-# The objective evaluation results are stored in white_balance_eval_result.html and the resulting white-balanced images are stored in the img folder for a qualitative<br>   comparison of algorithms. Different algorithms are compared in terms of angular error between the estimated and ground-truth illuminants.</p>
