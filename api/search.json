[{"title":"常用图像坐标系变换","slug":"常用图像坐标系变换","url":"/2023/11/22/chang-yong-tu-xiang-zuo-biao-xi-bian-huan/","content":"$$\n\\begin{aligned}\n& Z_c\\left[\\begin{array}{l}\nu \\\\\nv \\\\\n1\n\\end{array}\\right]=\\left[\\begin{array}{cccc}\nf_x & 0 & c_x & 0 \\\\\n0 & f_y & c_y & 0 \\\\\n0 & 0 & 1 & 0\n\\end{array}\\right] \\cdot\\left[\\begin{array}{c}\nX_c \\\\\nY_c \\\\\nZ_c \\\\\n1\n\\end{array}\\right]=\\left[\\begin{array}{c}\nf_x X_c+c_x Z_c \\\\\nf_y Y_c+c_y Z_c \\\\\nZ_c\n\\end{array}\\right] \\\\\n& {\\left[\\begin{array}{c}\nu \\\\\nv \\\\\n1\n\\end{array}\\right]=\\left[\\begin{array}{cccc}\nf_x & 0 & c_x & 0 \\\\\n0 & f_y & c_y & 0 \\\\\n0 & 0 & 1 & 0\n\\end{array}\\right] \\cdot\\left[\\begin{array}{c}\nX_c \\\\\nY_c \\\\\nZ_c \\\\\n1\n\\end{array}\\right]=\\left[\\begin{array}{c}\nf_x X_c / Z_c+c_x \\\\\nf_y Y_c / Z_c+c_y \\\\\n1\n\\end{array}\\right]}\n\\end{aligned}\n$$\n\n\n\\begin{equation}\n\\begin{aligned}\n& Z_c\\left[\\begin{array}{l}\nu \\\\\nv \\\\\n1\n\\end{array}\\right]=\\left[\\begin{array}{cccc}\nf_x & 0 & c_x & 0 \\\\\n0 & f_y & c_y & 0 \\\\\n0 & 0 & 1 & 0\n\\end{array}\\right] \\cdot\\left[\\begin{array}{c}\nX_c \\\\\nY_c \\\\\nZ_c \\\\\n1\n\\end{array}\\right]=\\left[\\begin{array}{c}\nf_x X_c+c_x Z_c \\\\\nf_y Y_c+c_y Z_c \\\\\nZ_c\n\\end{array}\\right] \\\\\n& {\\left[\\begin{array}{c}\nu \\\\\nv \\\\\n1\n\\end{array}\\right]=\\left[\\begin{array}{cccc}\nf_x & 0 & c_x & 0 \\\\\n0 & f_y & c_y & 0 \\\\\n0 & 0 & 1 & 0\n\\end{array}\\right] \\cdot\\left[\\begin{array}{c}\nX_c \\\\\nY_c \\\\\nZ_c \\\\\n1\n\\end{array}\\right]=\\left[\\begin{array}{c}\nf_x X_c / Z_c+c_x \\\\\nf_y Y_c / Z_c+c_y \\\\\n1\n\\end{array}\\right]}\n\\end{aligned}\n\\end{equation}\n\n\n\\begin{aligned}\n& Z_c\\left[\\begin{array}{l}\nu \\\\\nv \\\\\n1\n\\end{array}\\right]=\\left[\\begin{array}{cccc}\nf_x & 0 & c_x & 0 \\\\\n0 & f_y & c_y & 0 \\\\\n0 & 0 & 1 & 0\n\\end{array}\\right] \\cdot\\left[\\begin{array}{c}\nX_c \\\\\nY_c \\\\\nZ_c \\\\\n1\n\\end{array}\\right]=\\left[\\begin{array}{c}\nf_x X_c+c_x Z_c \\\\\nf_y Y_c+c_y Z_c \\\\\nZ_c\n\\end{array}\\right] \\\\\n& {\\left[\\begin{array}{c}\nu \\\\\nv \\\\\n1\n\\end{array}\\right]=\\left[\\begin{array}{cccc}\nf_x & 0 & c_x & 0 \\\\\n0 & f_y & c_y & 0 \\\\\n0 & 0 & 1 & 0\n\\end{array}\\right] \\cdot\\left[\\begin{array}{c}\nX_c \\\\\nY_c \\\\\nZ_c \\\\\n1\n\\end{array}\\right]=\\left[\\begin{array}{c}\nf_x X_c / Z_c+c_x \\\\\nf_y Y_c / Z_c+c_y \\\\\n1\n\\end{array}\\right]}\n\\end{aligned}","tags":["坐标系变"],"categories":["坐标系变"]},{"title":"车载相机与地面的在线标定","slug":"车载相机与地面的在线标定","url":"/2023/11/16/che-zai-xiang-ji-yu-di-mian-de-zai-xian-biao-ding/","content":"\n\n# 摘要\n\n相机与地面的在线标定是一般指实时生成相机与道路平面之间的非刚体变换，现有的解决方案常常利用静态标定，在面对轮胎气压变化、车辆载重体积变化和道路表面多样性等环境变化时存在问题。其他在线解决方案利用道路元素或图像中重叠视图之间的光度一致性，这需要在道路上连续检测特定目标或借助多个摄像头来进行标定。\n\n这里提出一种在线的单目相机与地面标定解决方案，不需要在行驶过程中使用任何特定目标。通过轮速里程计进行粗到精的地面特征提取，并通过基于滑动窗口的因子图优化来估计相机与地面的标定参数。考虑到驾驶过程中相机与地面之间的非刚性变换，同时提供了衡量标定性能的指标和停止标准，用以发布满意的标定结果。使用真实的数据进行的广泛实验表明该算法有效，并且优于现有的技术。\n\n# 介绍\n\n现代车辆配备了各种摄像头，以获取与周围环境相关的丰富语义信息，并将特征统一在共享的鸟瞰图中，以支持可解释的运动规划任务。相机与地面的标定在确定相机坐标和地面坐标之间的特征位置的几何变换方面起着关键作用。它有助于消除相机的透视畸变，提供鸟瞰图表示空间，并且便于估算安装在车辆上的相机与地面上位置之间的距离，这在先进驾驶辅助系统（ADAS）和自动驾驶系统中被广泛应用。\n\n在过去的几十年中，已经提出了许多相机与地面的标定方法。这些方法通常可以分为两类，其一是静态标定，其二是行驶过程中的在线标定。第一类方法通常使用诸如棋盘格或手动标注的地面物体等各种模式，事先计算相机与地面之间的变换关系。然而，由于车辆在道路上行驶时，由于轮胎气压变化、车辆载荷变化、道路表面多样性和部件振动，此类变换是非刚性的。相机与地面的标定应在行驶过程中进行多次，以调整几何投影的变化。例如，由周围视图鱼眼相机捕获的图像在下图a中，静态标定在下图b中会导致BEV图像不准确。在线标定可以减小变换误差，确保适当地处理投影变化，并生成下图c中对齐良好的BEV图像。\n\n![](https://cdn.jsdelivr.net/gh/geiyiren/MyBlogImage1/车载相机与地面的在线标定/1.png)\n\n上图在给定的环视图鱼眼相机图像a中，静态标定包含了大量的相机到地面估计误差，导致BEV图像不匹配b，但是本文的方法在c中生成了一个对齐良好的BEV图像。第二类现有方法应用在线标定，这需要从道路上提取出特定的几何形状，例如单目相机的消失点和周围视图相机提取的车道标线，或者多个相机之间重叠区域的光度一致性，以辅助标定调整。然而，在各种行驶环境中很难保持这些要求。在这种情况下，需要在使用单个摄像头连续图像的情况下进行相机与地面的标定，而不依赖于任何特定的标定目标。\n\n# 内容\n\n本文采用了一种从粗到精的方法，在车辆行驶在道路上时，通过因子图优化获取地面特征并优化相机到地面的标定参数，而无需使用任何特定的标定目标。利用图像中水平线分离地面和非地面区域，通过轮式测程法预测地面特征的位置，并使用基于几何的方法验证地面特征。对三角测量的地面特征进行平面拟合，以获取地面的法向量和相机到地面的高度，并通过因子图优化进一步改进这些参数，以确定相机到地面的变换关系。考虑到在驾驶过程中相机到地面的非刚性变换，还提出了度量标定性能的指标和停止准则，以确保标定质量。\n\n下图展示了系统框图，主要包含以下模块。首先利用运动学自车模型恢复图像关键帧之间的相对运动，以便进行相机姿态估计和地面点三角测量。其次从关键帧中提取粗糙的地面特征，通过车辆运动进行特征预测，并进一步进行优化地面特征验证过程。然后进行地面平面拟合，获取地面法向量和相机到地面的高度。然后通过因子图优化来细化相机姿态和相机到地面的变换参数，并提出了一个停止标定准则，确定何时发布相机到地面的标定结果。\n\n![](https://cdn.jsdelivr.net/gh/geiyiren/MyBlogImage1/车载相机与地面的在线标定/2.png)\n\n## 通过轮速里程计测量的相机运动\n\n利用CAN总线系统提供的连续车轮里程读数估计车辆随时间的姿态变化，并确定相机关键帧之间的相对运动，以恢复单目相机系统的尺度因子。\n\n## 连续关键帧的地面提取\n\n地面特征（即车辆所行驶的道路表面上的特征）在相机与地面标定中起着重要作用。在城市/郊区环境中，大多数地面特征位于具有相似纹理的混凝土或沥青道路表面上，这些特征很难提取和匹配。这里提出了一种新颖的粗到细的地面特征提取架构，用于稳健的相机与地面标定。\n\n首先，引入地平线提取方法，通过车辆运动预测地面特征的位置，以便进行特征匹配。然后，利用几何方法来验证地面特征，并进行地面平面拟合，以获得地面法线向量和相机中心到地面的高度。在进行标定时，选择以稳定速度行驶时的关键帧，这样可以在不同的图像帧之间获得较小的相机姿态变化，有利于标定过程的稳定性，关键帧是指在时间序列中选择的一帧图像，通常表示为时间间隔的起点。从选择的关键帧开始，通过KLT稀疏光流算法提取图像中的角点特征，并进行跟踪。然后通过水平线分割图像，可以筛选位于水平线以下的特征点来选择地面特征，并利用车辆的运动信息进一步预测地面特征在下一个关键帧中的位置，这样可以有效地提取和跟踪地面特征，为后续的相机到地面标定和场景理解提供重要的信息。\n\n![](https://cdn.jsdelivr.net/gh/geiyiren/MyBlogImage1/车载相机与地面的在线标定/3.png)\n\n上图通过车辆运动进行特征预测，这里，Ok是关键帧Ik的相机中心。\n\n![](https://cdn.jsdelivr.net/gh/geiyiren/MyBlogImage1/车载相机与地面的在线标定/4.png)\n\n上图为粗糙的地面特征提取，对于每个特征，通过车辆运动预测其在下一个关键帧中的位置a。因此，与没有任何预测的KLT跟踪器中的特征相比，在b中有更多的、质量更高的匹配特征对。进一步在d中从b中均匀采样/选择特征以进行计算优化。这里，红色线段的端点表示关键帧Ik和Ik+1之间的匹配特征，绿色线是地平线。\n\n## 跨关键帧地面优化\n\n采用基于滑动窗口的因子图优化方法来优化相机姿态、地面法向量和相机中心到地面的高度。通过使用单应性变换矩阵，可以将当前关键帧的特征点投影到上一关键帧的图像中。然后通过最小化重投影误差来优化相机姿态和地面参数，以确保在上一关键帧中的特征点与当前关键帧中的投影点之间的一致性。\n\n具体来说，首先计算从当前关键帧到上一关键帧的相机姿态变换。然后，根据相机姿态变换将当前关键帧的特征点投影到上一关键帧的图像平面上。接下来计算投影点与上一关键帧中的特征点之间的重投影误差，并将其作为优化问题的目标函数。通过最小化这个目标函数，可以同时调整相机姿态、地面法向量和相机中心到地面的高度，从而得到更准确的地面参数。通过这种跨关键帧的地面优化方法，可以更好地优化相机姿态和地面参数，提高相机到地面的标定精度，并为后续的路径规划和场景感知任务提供更准确的地面信息。\n\n# 实验\n\n在各种驾驶场景下使用乘用车实现了本文的算法并进行了大量实验，车辆安装了由四个向下朝向的鱼眼摄像机组成的全景摄像系统（参见下图a中的示例），这些摄像机与车轮编码器数据同步。摄像机的帧率为33Hz，图像分辨率调整为812×540。本文收集了来自不同区域的长序列连续数据，以分析本文算法的效率和鲁棒性（参见表I）。这些数据涵盖了从平坦的铺装地面（FPG）到城市、郊区和农村等不同天气、光照和驾驶条件下的公共道路，FPG数据来自极其平坦的沥青路面，用于验证本文动态标定的基准性能。表I的最后一列表示车辆行驶而不是停车的时间百分比。\n\n![](https://cdn.jsdelivr.net/gh/geiyiren/MyBlogImage1/车载相机与地面的在线标定/5.png)\n\n上图显示本文的方法在具有挑战性的驾驶场景中表现良好，图中的标签与表格I从上到下对应。\n\n![](https://cdn.jsdelivr.net/gh/geiyiren/MyBlogImage1/车载相机与地面的在线标定/6.png)\n\n将本文的方法与现有的最先进方法进行比较，从而定性地检验性能，包括Liu等人\\[23\\]、OECS\\[24\\]和ROECS\\[25\\]在本文的数据集上的性能。首先比较了在FPG数据上的标定性能，并在表II中总结了结果。与对手一样，本文的方法在车辆行驶在FPG上时能够生成连续稳定的相机到地面的标定。因此显示了与地面真实（GT）标定的欧拉角差的平均值，并评估绝对变化量δr、δp和δy。这里，δr、δp和δy分别表示滚转角、俯仰角和偏航角的变化量。表II中的δh列是相机中心到地面的高度位移。在表II中，即使在图像上没有可辨别纹理的混凝土路面上，本文的在线方法也取得了更好的性能。例如，本文的方法在俯仰角、偏航角和高度估计方面分别获得了显著的绝对增益，分别为44.4%、50.0%和71.2%。\n\n![](https://cdn.jsdelivr.net/gh/geiyiren/MyBlogImage1/车载相机与地面的在线标定/7.png)\n\n为了展示本文提出的方法的优越性，在下图中呈现了误差直方图，获得了不同区间的误差差异，作为相对于最先进工作的性能提升的总和。本文的方法在不同水平下具有相对较小的特征转移误差f，并且误差保持在0.83像素以内，这在不同数据序列中保持一致。本文的方法在郊区数据上获得了最低的性能增益44.2%，在城市数据上获得了最高的性能增益67.6%。在从城市到农村地区的公共道路驾驶数据中，与最先进方法相比，本文的方法在误差p方面表现更好。误差p在0.75像素以内变化，并且90.9%的误差在0.67像素以内。在考虑平坦道路条件的情况下，性能提高了12.7%，在郊区数据中获得了最高得分，而在FPG数据中获得了最低得分，为1.59%。\n\n![](https://cdn.jsdelivr.net/gh/geiyiren/MyBlogImage1/车载相机与地面的在线标定/8.png)\n\n上图为表I中数据序列的性能直方图。水平轴的值对应于误差，垂直轴是概率密度。\n\n下图展示了在车辆以高速直行时不同方法生成的鸟瞰图像的视觉结果。本文的方法不依赖于不同摄像头之间的重叠区域或特定物体，获得了较小的特征残差误差，并生成了更好对齐的鸟瞰图像，原因如下：\n\n（1）直行车道标线与车辆行驶方向平行；\n\n（2）摄像头之间的车道标线互相重叠；\n\n（3）道路上的混凝土裂缝在相邻摄像头鸟瞰图像的重叠区域上连接在一起。\n\n![](https://cdn.jsdelivr.net/gh/geiyiren/MyBlogImage1/车载相机与地面的在线标定/9.png)\n\n上图为在行驶过程中城市I数据的示例结果。上图展示了a本文的结果，bROECS\\[25\\]，cOECS\\[24\\]和（d）Liu等人的结果。\n\n# 总结\n\n本文提出了一种在线相机到地面无目标标定方法，用于在行驶过程中生成相机坐标与地面坐标之间的非刚体变换。采用了一种新颖的粗到精的架构来选择地面特征，并通过基于几何的方法进行验证。对三角化的地面特征进行平面拟合，以获得地面法向量和相机到地面的高度，然后通过滑动窗口的因子图优化对其进行优化。通过旋转平均确定相机到地面的变换，并提供停止标准来广播满足标定结果的情况。使用从不同天气和驾驶条件下收集的真实数据对本文的算法进行了广泛测试，结果显示本文的方法是有效的，并且优于最先进的技术。在未来将减少因子图优化的运行时间复杂度，并进行可观测性分析，以识别帮助丢弃不需要用于标定计算的姿态和地面特征的退化场景。\n\n# 文章链接\n[参考文章](https://arxiv.org/pdf/2303.17137.pdf)\n\n[原文链接](https://mp.weixin.qq.com/s/nSMl6mf-cyc54tL-yLdJcw)\n","tags":["文章","360环视","在线标定"],"categories":["相机标定"]},{"title":"单应性矩阵应用之鸟瞰图生成","slug":"单应性矩阵应用之鸟瞰图生成","url":"/2023/11/02/dan-ying-xing-ju-zhen-ying-yong-zhi-niao-kan-tu-sheng-cheng/","tags":["opencv","鸟瞰图","单应性矩阵"],"categories":["opencv"]},{"title":"零基础学习g2o","slug":"零基础学习g2o","url":"/2023/10/17/ling-ji-chu-xue-xi-g2o/","content":"\n# 正篇\n\n## 简介\ng2o（General Graphic Optimization）是一个基于图优化的库，将非线性优化与图论结合起来的理论，我们可以**利用g2o求解任何可以表示为图优化的最小二乘问题**。图优化就是把优化问题表现成图的方式。图由顶点和边组成，其中*顶点表示优化变量*，*边表示误差项*，对任意一个非线性最小二乘问题，我们都可以构建与之对应的图。\n\ng2o的核里带有各种各样的求解器，而它的顶点、边的类型则多种多样。通过自定义顶点和边，事实上，只要一个优化问题能够表达成图，那么就可以用g2o去求解它。常见的，比如bundle adjustment，ICP，数据拟合，都可以用g2o来做。\n\n从代码层面来说，g2o是一个c++编写的项目，用cmake构建。它的github地址在：https://github.com/RainerKuemmerle/g2o \n\ng2o的源代码文件夹的内容：\n- `apps`　　　　 一些应用程序。好用的g2o_viewer就在这里。其他还有一些不常用的命令行工具等。\n- `core`　　　　 核心组件，很重要！基本的顶点、边、图结构的定义，算法的定义，求解器接口的定义在这里。\n- `examples`　  一些例程，可以参照着这里的东西来写。不过注释不太多。\n- `solvers`　　  求解器的实现。主要来自choldmod, csparse。在使用g2o时要先选择其中一种。\n- `stuff`　　　  对用户来讲可有可无的一些工具函数。\n- `types`　　　  各种顶点和边，很重要！我们用户在构建图优化问题时，先要想好自己的顶点和边是否已经提供了定义。如果没有，要自己实现。如果有，就用g2o提供的即可。\n\n就经验而言，`solvers`给人的感觉是大同小异(不同的求解器可能有针对性的求解场景，但是对于一般的优化问题，一般都适用)，而 `types` 的选取(关键就是顶点和边的定义)，则是 g2o 用户主要关心的内容。然后 `core` 下面的内容，我们要争取弄的比较熟悉，才能确保使用中出现错误可以正确地应对。\n\ng2o的结构图如下所示：\n\n![](https://cdn.jsdelivr.net/gh/geiyiren/MyBlogImage1/零基础学习g2o/g2o框架图.png)\n\n先看上半部分。`SparseOptimizer`(稀疏优化器) 是我们最终要维护的东东。它是一个OptimizableGraph(优化图)，从而也是一个HyperGraph(超图)。一个 `SparseOptimizer` 含有很多个顶点 （都继承自 `Base Vertex`）和很多个边（继承自 `BaseUnaryEdge`(一元边), `BaseBinaryEdge`(二元边)或`BaseMultiEdge`(多元边)）。这些 `Base Vertex` 和 `Base Edge`都是抽象的基类，而实际用的顶点和边，都是它们的派生类。我们用 `SparseOptimizer.addVertex` 和 `SparseOptimizer.addEdge` 向一个图中添加顶点和边，最后调用 `SparseOptimizer.optimize` 完成优化。\n\n在优化之前，需要指定我们用的求解器和迭代算法。从图中下半部分可以看到，一个 `SparseOptimizer` 拥有一个 `Optimization Algorithm`继承自`Gauss-Newton`, `Levernberg-Marquardt`, `Powell's dogleg` 三者之一（我们常用的是GN或LM）。同时，这个 `Optimization Algorithm` 拥有一个`Solver`它含有两个部分。一个是 `SparseBlockMatrix` ，用于计算稀疏的雅可比矩阵和海塞矩阵； 一个是 `linearsolver` ，用于计算迭代过程中最关键的一步：\n\n$$H\\Delta x=-b$$\n\n这就需要一个线性方程的求解器。而这个求解器，可以从 PCG, CSparse, Choldmod 三者选一。\n\n**综上所述，在g2o中选择优化方法一共需要三个步骤：**\n\n- 选择一个线性方程求解器，从 PCG, CSparse, Choldmod中选，实际则来自 g2o/solvers 文件夹中定义的东东。\n- 选择一个 BlockSolver 。\n- 选择一个迭代策略，从GN, LM, Doglog中选。\n\n\n\n\n\n\n\n\n\n\n# 扫盲篇\n\n## 最小二乘\n \n> 参考网站：https://blog.csdn.net/qq_41598072/article/details/83984299\n大家可以随意搜索一下，相关的文章很多。长篇大论的不少，刚入门的朋友一看到那些公式可能就看不下去了。比如下面的解释：\n\n![](https://imgconvert.csdnimg.cn/aHR0cHM6Ly9waWMyLnpoaW1nLmNvbS84MC92Mi1jMjdkNWI0NzcwNjM5NDZiNmFiZmQxNWI1YTYzNTExNV9oZC5qcGc?x-oss-process=image/format,png)\n\n毫无疑问，这样的解释是专业的，严谨的。事实上，这是深度学习圣经里的解释。我并没有诋毁大师的意思，只是觉得用一个具体的例子来说明，可能会让读者更加容易理解：\n\n小明是跑运输的，跑1公里需要6块，跑2公里需要5块（那段时间刚好油价跌了），跑3公里需要7块，跑4公里需要10块，请问跑5公里需要多少块？\n\n如果我们有初中数学基础，应该会自然而然地想到用线性方程组来做，对吧。\n\n![](https://imgconvert.csdnimg.cn/aHR0cHM6Ly9waWMxLnpoaW1nLmNvbS84MC92Mi1kMGRkYzFiM2EzNGRiOTE5Yzk0OGViOTAyZWQwMzEyOF9oZC5qcGc?x-oss-process=image/format,png)\n\n这里假定x是公里数，y是运输成本（β1和β2是要求的系数）。我们把上面的一组数据代入得到这么几个方程：\n\n![](https://imgconvert.csdnimg.cn/aHR0cHM6Ly9waWMxLnpoaW1nLmNvbS84MC92Mi0zMWQ5OWY5YmIxZjViMDE0MDcyMTBhYTRiYmIzM2IwY19oZC5qcGc?x-oss-process=image/format,png)\n\n如果存在这样的β1和β2，让所有的数据$（x，y）=（1,6），（2,5），（3,7），（4，10）$ 都能满足的话，那么解答就很简单了，β1+5β2就是5公里的成本，对吧。\n\n但遗憾的是，这样的β1和β2是不存在的，上面的方程组很容易，你可以把前面两个解出来得到一组β1和β2，后面两个也解出来同样得到一组β1和β2。这两组β1和β2是不一样的。\n\n形象地说，就是你找不到一条直线，穿过所有的点，因为他们不在一条直线上。如下图：\n\n![](https://imgconvert.csdnimg.cn/aHR0cHM6Ly9waWMyLnpoaW1nLmNvbS84MC92Mi04NWRlYTEzMTU4OTgyMzgxZDViMjcxMmM2YmY3MjI2MV9oZC5qcGc?x-oss-process=image/format,png)\n\n可是现实生活中，我们就希望能找到一条直线，虽然不能满足所有条件，但能**近似**地表示这个趋势，或者说，能近似地知道5公里的运输成本，这也是有意义的。\n\n现实生活当中，有很多这样的例子，想起以前在某公司上班的时候，CEO说我们研发部做事有个问题：一个研发任务，要求三个月做完，因为周期太短，完成不了，就干脆不做，这显然是不对的，要尽全力，哪怕三个月完成了80%，或者最终4个月完成，总比不作为的好。\n\n其实最小二乘法也是这样，要尽全力让这条直线最接近这些点，那么问题来了，怎么才叫做最接近呢？直觉告诉我们，这条直线在所有数据点中间穿过，让这些点到这条直线的误差之和越小越好。这里我们用方差来算更客观。也就是说，把每个点到直线的误差平方加起来：\n\n![](https://imgconvert.csdnimg.cn/aHR0cHM6Ly9waWMxLnpoaW1nLmNvbS84MC92Mi05MzljOTExODY2N2VlMzgxNzI1NTQ3ZmE2MDUwNDFkY19oZC5qcGc?x-oss-process=image/format,png)\n\n（如果上面的四个方程都能满足，那么S的值显然为0，这是最完美的，但如果做不到完美，我们就让这个S越小越好）\n\n接下来的问题就是，如何让这个S变得最小。这里有一个概念，就是求偏导数。这里我想提一下，在培训的过程中，我发现机器学习的数学基础课程当中，微积分是大家印象最深刻的，而且也最容易理解：比如导数就是求变化率，而偏导数则是当变量超过一个的时候，对其中一个变量求变化率。如果这个概念也忘了，可以参考我在深度学习回答里那个王小二卖猪的例子。这里就不细讲了：\n\n要让S取得最小值（或最大值，但显然这个函数没有最大值，自己琢磨一下），那么S对于β1和β2分别求偏导结果为0，用一个直观的图来表示：\n\n![](https://imgconvert.csdnimg.cn/aHR0cHM6Ly9waWMyLnpoaW1nLmNvbS84MC92Mi05NjgwODUzMTY5YmNhMGRjY2M2OTY3OGM4MzM4NzQ2MV9oZC5qcGc?x-oss-process=image/format,png)\n\n我们看到这条曲线，前半部分是呈下降的趋势，也就是变化率（导数）为负的，后半部分呈上升的趋势，也就是变化率（导数）为正，那么分界点的导数为0，也就是取得最小值的地方。这是一个变量的情况，对于多个变量的情况，要让S取得最小值，那最好是对β1和β2分别求导（对β1求导的时候，把β2当常量所以叫求偏导），值为0：\n\n![](https://imgconvert.csdnimg.cn/aHR0cHM6Ly9waWMyLnpoaW1nLmNvbS84MC92Mi05ZDlmZDA4MGM1YmZiOTAxMTc0NjM5YTVmMjM3Y2M2OV9oZC5qcGc?x-oss-process=image/format,png)\n\n![](https://imgconvert.csdnimg.cn/aHR0cHM6Ly9waWMxLnpoaW1nLmNvbS84MC92Mi00ZTQ1OWRkNDQ1N2Q5ZDM1YTk3ZDU1NWUyMGJiYmU3OF9oZC5qcGc?x-oss-process=image/format,png)\n\n看到这个我们就熟悉了，两个变量，刚好有两个方程式，初中学过，那么很容易得出：\n\n![](https://imgconvert.csdnimg.cn/aHR0cHM6Ly9waWMyLnpoaW1nLmNvbS84MC92Mi1mMDMwYTk0Y2M4YjcwYjgzYjk4MDUxMDg0MTkyMTM5ZF9oZC5qcGc?x-oss-process=image/format,png)\n\n![](https://imgconvert.csdnimg.cn/aHR0cHM6Ly9waWMxLnpoaW1nLmNvbS84MC92Mi0xYmM3ZTQ5OTYyY2EyMTI1NGI3YWU5N2M3OTNlNWYwY19oZC5qcGc?x-oss-process=image/format,png)\n\n其实也就意味着\n\n![](https://imgconvert.csdnimg.cn/aHR0cHM6Ly9waWM0LnpoaW1nLmNvbS84MC92Mi00ZTJhNzVmMWJkMmM0NzZmOTFlNmYzMDMwMzFiNzcyYl9oZC5qcGc?x-oss-process=image/format,png)\n\n这个函数也就是我们要的直线，这条直线虽然不能把那些点串起来，但它能最大程度上接近这些点。也就是说5公里的时候，成本为3.5+1.4x5=10.5块，虽然不完美，但是很接近实际情况。\n\n\n## BA优化\n>参考网站: https://optsolution.github.io/archives/58892.html\n### 简介\nBundle Adjustment中文译为**光束法平差**，大概大家看到更多的翻译可能为束调整、捆集调整或者捆绑调整等等.所谓bundle，来源于bundle of light，其本意就是指的光束，这些光束指的是三维空间中的点投影到像平面上的光束，而重投影误差正是利用这些光束来构建的，因此称为光束法强调光束也正是描述其优化模型是如何建立的。\n\n剩下的就是平差，那什么是平差呢？由于测量仪器的精度不完善和人为因素及外界条件的影响，测量误差总是不可避免的。为了提高成果的质量，处理好这些测量中存在的误差问题，观测值的个数往往要多于确定未知量所必须观测的个数，也就是要进行*多余观测*。有了多余观测，势必在观测结果之间产生矛盾，测量平差的目的就在于消除这些矛盾而求得观测量的最可靠结果并评定测量成果的精度。测量平差采用的原理就是“最小二乘法”。平差也就正好表述了为什么需要BA以及BA这个优化过程到底是怎么进行的。**BA的本质是一个优化模型，其目的是最小化重投影误差**。\n\n![](https://cdn.jsdelivr.net/gh/geiyiren/MyBlogImage1/零基础学习g2o/BA1.jpg)\n\n这些五颜六色的线就是我们讲的光束啦！那现在就该说下什么叫重投影误差了，重投影也就是指的第二次投影，那到底是怎么投影的呢？我们来整理一下吧。\n- 第一次投影指的就是相机在拍照的时候三维空间点投影到图像上\n- 第二次投影指的是利用几何信息构建三角形来确定三维空间点的位置，利用相机矩阵将得到的三维点的坐标投影到图像上，进行第二次投影，也就是重投影.重投影使用的三维点的位置是根据三角化得到的。\n> 第二次投影利用到了三角化的原理，那么什么是三角化呢？参加后文三角化介绍。\n\n现在我们知道什么是重投影了，那重投影误差到底是什么样的误差呢？这个误差是指的真实三维空间点在图像平面上的投影（也就是图像上的像素点）和重投影（其实是用我们的计算值得到的虚拟的像素点）的差值，因为种种原因计算得到的值和实际情况不会完全相符，也就是这个差值不可能恰好为0，此时也就需要将这些差值的和最小化获取最优的相机参数及三维空间点的坐标。\n\nBA是一个图优化模型，那首先肯定要构造一个图模型了（没学过图论也没事，后面还是会回到一般的优化模型）。既然是图模型那自然就有节点和边了，这个图模型的节点由相机$P_i$和三维空间点$X_j$构成，如果点$X_j$投影到相机$P_i$的图像上则将这两个节点连接起来。还是来张图吧。\n\n![](https://cdn.jsdelivr.net/gh/geiyiren/MyBlogImage1/零基础学习g2o/BA2.png)\n\n这样就一目了然了。那么我们现在就可以通过这个图来构造优化模型了。\n\n\n令点$X_j$在相机$P_i$拍摄到的图像归一化坐标系上的坐标为$k(u_{i j}^{T},1)^{T}=K_{i}^{-1}x_{i j}$，其重投影后的图像归一化坐标系下坐标为$k^{\\prime}(v_{i j}^{T},1)^{T}=K_{i}^{-1}P_{i}X_{j}$，其中$K_{i}^{-1}$是为了在计算时能不受相机内参影响,$k$和$k^{\\prime}$是将齐次坐标转换为非齐次坐标的常数项，可以得到该重投影误差为:\n$$e_{i j}=u_{i j}-v_{i j}$$\nBA是要将所有重投影误差的和最小化，那么这里自然就要开始求和了。\n$$\\operatorname*{min}_{R_{i},t_{i},X_{j}}\\sum_{i,j}\\sigma_{i j}||u_{i j}-v_{i j}||_{2}$$\n其中当点$X_j$在相机$P_i$中有投影时$\\sigma_{i j}=1$，否则为$\\sigma_{i j}=0$。到此我们就得到了BA优化模型的数学形式了。\n\n既然是优化模型，那自然就应该用各种优化算法来进行计算了。常用的方法有最速下降法，牛顿方法，高斯牛顿方法，LM方法。具体细节[点我查看](https://optsolution.github.io/archives/58892.html)\n> 具体细节预览[点我查看](https://cdn.jsdelivr.net/gh/geiyiren/MyBlogImage1/零基础学习g2o/BA简述.png)\n\n## 三角化\n在单目SLAM中，仅通过单张图像无法获得像素的深度信息，我们需要通过三角测量(Triangulation)(或三角化)的方法来估计地图点的深度。即通过某个特征点P在不同帧图像中像素点的位置，来计算出该特征点在三维空间中的坐标，也即获得特征点P的深度信息。特征点在某个相机中被观测到，根据相机位姿和观测向量可以得到3D空间中的一条从相机中心出发的观测“射线”，多个相机位姿观测会产生多条观测射线，理想情况下这些观测射线相交于空间中一点，求所有观测射线的交点就是特征点在3D空间的位置，这就是三角化最朴素的思想。\n\n![](https://cdn.jsdelivr.net/gh/geiyiren/MyBlogImage1/零基础学习g2o/三角化.png)\n\n以两视图的三角化为例，考虑$I_1$,$I_2$两帧图像，$R,t$是第二帧相对于第一帧的旋转矩阵和平移向量（对应的变换矩阵是$T_{12}$）。在$I_1$中有特征点$p_1$，对应于$I_2$中的匹配点$p_2$。根据相机的内参数矩阵$K$，我们便可以获得$p_1$在帧归一化图像平面中的点$x_1=K^{-1}p_{1}$；$p_2$在$I_2$帧归一化平面中的点$x_2=K^{-1}p_2$。\n\n根据对极约束，他们满足如下的关系：\n$$s_{1}x_{1}=s_{2}Rx_{2}+t$$\n\n先对公式左右两端左乘反对称矩阵$x^{\\wedge}$，得到：\n\n$$s_{1}x_{1}^{\\wedge}x_{1}=0=s_{2}x_{1}^{\\wedge}R x_{2}+x_{1}^{\\wedge}t$$\n\n根据上述公式的右端，可以计算出$s_2$，进而计算出$s_1$，我们便可得到路标点$P$在这两帧中的深度。然而，在实际的位姿估计中，我们估计的值往往存在误差，上述公式不严格为0。这时候我们可以计算最小二乘解。\n> 多视图三角化[点我查看](https://gutsgwh1997.github.io/2020/03/31/%E5%A4%9A%E8%A7%86%E5%9B%BE%E4%B8%89%E8%A7%92%E5%8C%96/)\n> 具体细节预览[点我查看](https://cdn.jsdelivr.net/gh/geiyiren/MyBlogImage1/零基础学习g2o/多视图三角化.png)\n\n## 对极约束\n对极几何（Epipolar geometry）又叫对极约束，是根据图像二维平面信息来估计单目相机帧间运动或双目相机相对位姿关系的一种算法。直观来讲，当相机在两个不同视角对同一物体进行拍摄时，物体在两幅图像中的成像肯定会有不同，那么，根据这两幅不同的图像，我们如何判断出相机的位姿发生了怎样的变化，这正是对极几何要解决的问题。直观来说就是利用$n$对匹配点对的图像坐标求解相机位姿变换关系。\n\n需要明确的是，在对极几何中，我们的已知条件仅仅是每幅图像中特征点的像素坐标，当然，计算对极约束的前提是我们必须知道两幅图像中特征点之间准确的匹配关系。\n![](https://cdn.jsdelivr.net/gh/geiyiren/MyBlogImage1/零基础学习g2o/对极几何示意图.png)\n![](https://cdn.jsdelivr.net/gh/geiyiren/MyBlogImage1/零基础学习g2o/对极几何推导.png)\n\n\n","tags":["g2o"],"categories":["g2o"]},{"title":"文献检索","slug":"论文检索","url":"/2023/10/09/lun-wen-jian-suo/","content":"\n# 360环视\n## 相机标定优化\n### Online Correction of Camera Poses\n\n- [Online Correction of Camera Poses for the Surround-view System: A Sparse Direct Approach](https://github.com/geiyiren/MyBlogPaper1/blob/main/AVM/%E6%A0%87%E5%AE%9A/Online%20correction%20of%20camera%20poses%20for%20the%20surround%20viewsystem%20a%20sparse%20direct%20approach.pdf)\n\n- 摘要\n环绕视图模块是现代先进驾驶辅助系统不可或缺的组成部分。通过精确地校准环绕视图摄像机的内部信息和外部信息，可以从原始的鱼眼图像中生成一个自上而下的环绕视图。然而，这些相机的姿势有时可能会改变。目前，如何在不重新校准的情况下，在线校正相机的姿态仍是一个有待解决的问题。为了解决这个问题，我们引入了稀疏直接框架，并提出了一种新的级联结构优化方案。该方案实际上由两级优化方案组成，并提出了两个相应的基于光度误差的模型。第一级优化的模型称为地面模型，因为它的光度误差是在地平面上测量的。对于优化的第二层，它是基于所谓的地面照相机模型，即在成像平面上计算光度误差。利用这些模型，姿态校正任务被表述为一个非线性最小二乘问题，以最小化相邻鸟瞰图图像重叠区域的光度误差。通过这两个层次优化的级联结构，可以在速度和精度之间达到适当的平衡。实验表明，该方法可以有效地消除环绕视图系统中摄像机适度姿态变化造成的错位。源代码和测试用例可以在[https://cslinzhang.github.io/CamPoseCorrection/](https://cslinzhang.github.io/CamPoseCorrection/)上找到。\n\n> *The surround-view module is an indispensable component of a modern advanced driving assistance system. By calibrating the ntrinsics and extrinsics of the surround-view cameras accurately, a top-down surround-view can be generated from raw fisheye images. However, poses of these cameras sometimes may change. At present, how to correct poses of cameras in a surround-view system online without re-calibration is still an open issue. To settle this problem, we introduce the sparse direct framework and propose a novel optimization scheme of a cascade structure. This scheme is actually composed of two levels of optimization and two corresponding photometric error based models are proposed. The model for the first-level optimization is called the ground model, as its photometric errors are measured on the ground plane. For the second level of the optimization, it’s based on the so-called ground-camera model, in which photometric errors are computed on the imaging planes. With these models, the pose correction task is formulated as a nonlinear least-squares problem to minimize photometric errors in overlapping regions of adjacent bird’s-eye-view images. With a cascade structure of these two levels of optimization, an appropriate balance between the speed and the ccu\u0002racy can be achieved. Experiments show that our method can effectively eliminate the misalignment caused by cameras’ moderate pose hanges in the surround-view system. Source code and test cases are available online at https://cslinzhang.github.io/CamPoseCorrection/.*\n\n","tags":["文献检索"],"categories":["文献检索"]},{"title":"零基础学习卡尔曼滤波","slug":"零基础学习卡尔曼滤波","url":"/2023/10/08/ling-ji-chu-xue-xi-qia-er-man-lu-bo/","content":"\n# 扫盲篇\n\n## 最小二乘\n$a_1$ dddddddddddddddddddddddddd\n\ndfsadfasdf\n$$a_1$$\n\n<span style=\"white-space: nowrap;\">\n  $$\n  \\begin{bmatrix}\n    1 & 2 & 3 \\\\\n    4 & 5 & 6 \\\\\n    7 & 8 & 9\n  \\end{bmatrix}\n  $$\n</span>\n","tags":["卡尔曼滤"],"categories":["卡尔曼滤波"]},{"title":"常用图像变换","slug":"常用图像变换","url":"/2023/09/20/chang-yong-tu-xiang-bian-huan/","content":"\n# 形态学变换\n\n形态学变换是一组用于图像处理中的数学操作，用于改变图像中物体的形状、大小和结构。这些操作通常用于处理二值图像（黑白图像），用于分割图像中的物体、去除噪声、查找轮廓等，最初是为了分析和处理二值图像中的形状、结构和特征而开发的。\n\n## 腐蚀与膨胀\n\n与卷积操作类似(嗯... 什么是卷积...[点我查看](https://setosa.io/ev/image-kernels/)),假设有图像A和结构元素B,结构元素B在A上面移动,其中B定义其中心为锚点，计算B覆盖下A的最大像素值用来替换锚点的像素，其中B作为结构体可以是任意形状。随着锚点在图像上的移动，结构B就可对图像上的每个像素进行处理。\n\n膨胀操作用于扩大图像中的白色区域，即通过结构元素的移动来扩展白色像素。如果结构元素的中心覆盖了至少一个白色像素，则中心位置的像素被置为白色。膨胀操作通常用于填充空洞、连接断开的对象和扩展物体。腐蚀和膨胀是数学形态学最基本的变换。\n\n图像膨胀主要针对的是阈值化后的图像。图像膨胀类似于“领域被扩张”，将图像中的高亮区域或白色部分进行扩增粗化，其运行结果图比原图的高亮区域更大。其原理是：将核在原始图像中进行遍历，然后将原始图像遍历到的像素点的值与自定义卷积核(全为1的二维矩阵)得值进行与运算，像素点与对应核一 一对应进行与，当卷积核对应的元素值只要有一个为1时，设置卷积核中心值的像素点为1，如果全为0，,则其值设置为0。\n\n图像腐蚀主要针对的是阈值化后的图像。图像腐蚀类似于“领域被蚕食”，将图像中的高亮区域或白色部分进行缩减细化，其运行结果图比原图的高亮区域更小。其原理是：将核在原始图像中进行遍历，然后将原始图像遍历到的像素点的值与自定义卷积核(全为1的二维矩阵)得值进行与运算，像素点与对应核一 一对应进行与，当卷积核对应的元素值均为1时，设置卷积核中心值的像素点为1，否则其值设置为0\n\n一头雾水，直接看图...\n\n| ![](https://cdn.jsdelivr.net/gh/geiyiren/MyBlogImage1/常用图像变换/df2fe5f21358787937bf255254be8820.png) | ![](https://cdn.jsdelivr.net/gh/geiyiren/MyBlogImage1/常用图像变换/7ffd7403a2a42acc16899afdda0b19a0.png) | ![](https://cdn.jsdelivr.net/gh/geiyiren/MyBlogImage1/常用图像变换/6b29fcd3560f6d0db69c76561679ee41.png) |\n|---------------------------------------------------------|---------------------------------------------------------|---------------------------------------------------------|\n| **腐蚀变换**                                            | **原图**                                                | **膨胀变换**                                            |\n\n注：卷积核的大小为5×5。\n\n**腐蚀就是使得“白色”区域变小，膨胀就是使得“白色”区域变大。**\n\n## 开运算与闭运算\n\n开运算是将腐蚀（Erosion）操作和膨胀（Dilation）操作依次应用于图像的操作。首先执行腐蚀操作，然后再执行膨胀操作。开运算通常用于以下情况：\n\n-   去除小的噪声和斑点：通过腐蚀操作可以缩小小的白色区域，然后通过膨胀操作将它们恢复到原始大小，从而去除小的噪声和斑点。\n-   分离连接的物体：开运算可以分离连接在一起的物体，使它们变得更远离彼此。\n\n闭运算是将膨胀（Dilation）操作和腐蚀（Erosion）操作依次应用于图像的操作。首先执行膨胀操作，然后再执行腐蚀操作。闭运算通常用于以下情况：\n\n-   填充物体内的小孔：通过膨胀操作可以填充物体内的小孔，然后通过腐蚀操作来还原物体的大小。\n-   连接断开的物体：闭运算可以连接断开的物体，使它们相互接触。\n\n在图像分割中，开运算可以分离相邻物体，闭运算可用于连接物体。在光学字符识别（OCR）中，开运算可用于去除文本字符之间的干扰，闭运算可用于连接字符的笔画。在医学影像中，这些操作可用于处理X射线图像或CT扫描图像中的结构。\n\n一头雾水，直接看图...\n\n| ![](https://cdn.jsdelivr.net/gh/geiyiren/MyBlogImage1/常用图像变换/28953503336881d61c9b80472ab7a96f.png) | ![原始图像](https://cdn.jsdelivr.net/gh/geiyiren/MyBlogImage1/常用图像变换/7ffd7403a2a42acc16899afdda0b19a0.png) | ![](https://cdn.jsdelivr.net/gh/geiyiren/MyBlogImage1/常用图像变换/60951e8e70e0276c13faa177bc76695e.png) |\n|-------------------------------------------------------------------------------------|---------------------------------------------------------|-------------------------------------------------------------------------------------|\n| **开运算**                                                                          | **原图**                                                | **闭运算**                                                                          |\n\n注：卷积核的大小为5×5。\n\n嗯... 有啥区别.... 因为开运算和闭运算都是腐蚀和膨胀相结合的，无非是顺序不同，因此，对于上述图像的影响不大。\n\n\n| ![](https://cdn.jsdelivr.net/gh/geiyiren/MyBlogImage1/常用图像变换/0d6668004a819e172f8c6ac9ca7d8864.png) | ![](https://cdn.jsdelivr.net/gh/geiyiren/MyBlogImage1/常用图像变换/311d90b895603171b85bc3054f80143e.png) | ![](https://cdn.jsdelivr.net/gh/geiyiren/MyBlogImage1/常用图像变换/8b39caf08ec08e1441b49cd645c20e63.png) |\n|-------------------------------------------------------|---------------------------------------------------------|-------------------------------------------------------|\n| **开运算**                                            | **原图**                                                | **闭运算**                                            |\n\n**开运算就是填充白色空洞，闭运算就是断开黑色连接，开运算和闭运算都基本保持图像原来的尺寸和形状。**\n\n## 形态学梯度\n\n形态学梯度通过计算图像中每个像素点的亮度变化程度来实现，从而可以突出物体的边界。形态学梯度操作通常对二值图像或灰度图像进行处理。\n\n形态学梯度操作通常通过以下公式来计算每个像素的梯度值：\n\nGradient(x,y)=Dilation(x,y)-Erosion(x,y)\n\nDilation(x,y) 表示对图像进行膨胀操作，Erosion(x,y) 表示对图像进行腐蚀操作。这意味着形态学梯度是膨胀图像和腐蚀图像之间的差异。这种操作突出了物体的边缘，因为边缘像素的值在膨胀和腐蚀之间产生最大的变化。形态学梯度的应用如下：\n\n-   边缘检测：形态学梯度可用于检测图像中的边缘，使其成为图像处理中常用的边缘检测工具。在边缘检测中，物体边界通常是感兴趣的区域，形态学梯度可以帮助找到这些边界。\n-   物体分割：形态学梯度可以用于分割图像中的不同物体，因为它可以突出物体之间的边界。这在计算机视觉和图像分析中非常有用。\n-   纹理分析：在纹理分析中，形态学梯度可以用于检测和描述图像中的纹理特征，从而有助于分类和识别任务。\n-   图像增强：形态学梯度操作可以增强图像中物体的轮廓和边缘，使它们更清晰可见，这在图像改进和可视化中很有用。\n-   医学影像处理：在医学图像中，形态学梯度可以用于检测血管、骨骼和组织的边界，从而帮助医生进行诊断。\n\n对图像进行形态学梯度计算时的效果如下：\n\n\n| ![](https://cdn.jsdelivr.net/gh/geiyiren/MyBlogImage1/常用图像变换/7ffd7403a2a42acc16899afdda0b19a0.png) | ![](https://cdn.jsdelivr.net/gh/geiyiren/MyBlogImage1/常用图像变换/fcbca0d7334a7df27f68aad79fcc65fd.png) |\n|---------------------------------------------------------|-----------------------------------------------------------|\n| **原图**                                                | **形态学梯**                                              |\n\n通过上图可以看出，形态学梯度对图像的边缘检测具有明显的效果。\n\n## 顶帽与黑帽\n\n顶帽和黑帽是形态学图像处理中的两种操作，它们分别用于突出图像中的亮区域和暗区域，常用于图像增强和特征提取。顶帽操作是原始图像与开运算的结果之差。开运算通常用于去除图像中的噪声或连接分散的物体，因此顶帽操作可以突出图像中的小亮区域或物体的细节。顶帽操作通常用于以下情况：\n\n-   亮物体检测：当亮物体与背景的亮度差异很小时，顶帽操作可以突出这些亮物体。\n-   纹理分析：用于分析图像中的纹理和细节。\n-   图像增强：可以增强图像中的细节，使其更清晰可见。\n\n黑帽操作是闭运算的结果与原始图像之差。闭运算通常用于填充物体内的小孔或连接物体，因此黑帽操作可以突出图像中的小暗区域或物体的细节。黑帽操作通常用于以下情况：\n\n-   暗物体检测：当暗物体与背景的亮度差异很小时，黑帽操作可以突出这些暗物体。\n-   小孔填充：用于填充物体内的小孔或裂缝，以还原物体的形状。\n-   图像增强：可以增强图像中的细节，特别是暗区域的细节。\n\n应用示例：\n\n-   医学影像：顶帽和黑帽操作可用于医学影像中的病变检测和血管分析。\n-   工业检测：在制造业中，它们可用于检测产品表面上的缺陷或微小的瑕疵。\n-   纹理分析：用于纹理分析和纹理特征提取，例如在图像分类或图像检索中。\n-   数字图像处理：常用于数字图像处理中的各种图像增强和预处理任务。\n\n总之，顶帽和黑帽操作是形态学图像处理中的两种重要工具，可以帮助突出图像中的亮暗区域和细节，用于不同的图像分析和增强任务。选择适当的操作取决于具体的应用场景和目标。\n\n一头雾水，直接看图...\n\n| ![](https://cdn.jsdelivr.net/gh/geiyiren/MyBlogImage1/常用图像变换/4bbcac92cf2200b7e9865fa07d1e73c3.png) | ![](https://cdn.jsdelivr.net/gh/geiyiren/MyBlogImage1/常用图像变换/311d90b895603171b85bc3054f80143e.png) | ![](https://cdn.jsdelivr.net/gh/geiyiren/MyBlogImage1/常用图像变换/4f8310d681cc934306a65da7641bb029.png) |\n|-----------------------------------------------------|---------------------------------------------------------|-----------------------------------------------------|\n| **顶帽**                                            | **原图**                                                | **黑帽**                                            |\n\n结合开运算和闭运算，就可以看出顶帽和黑帽操作与之的关系，但是具体应用起来是什么样子的呢？看下图：\n\n\n| ![](https://cdn.jsdelivr.net/gh/geiyiren/MyBlogImage1/常用图像变换/aa5e50980c5e180aa26224402a463e6e.png) | ![](https://cdn.jsdelivr.net/gh/geiyiren/MyBlogImage1/常用图像变换/4693bd3b37c710f59bbc5155dd0bcba2.png)     | ![](https://cdn.jsdelivr.net/gh/geiyiren/MyBlogImage1/常用图像变换/5e779f81df404e04a55ad2c946aed599.png) |\n|---------------------------------------------------------|-----------------------------------------------------------|-----------------------------------------------------|\n| **原图**                                                | **闭运算**                                                | **黑帽**                                            |\n\n\n| ![](https://cdn.jsdelivr.net/gh/geiyiren/MyBlogImage1/常用图像变换/e1040dba7d87a8279fac9a8ee3ef6b64.png) | **![](https://cdn.jsdelivr.net/gh/geiyiren/MyBlogImage1/常用图像变换/3e16fd13019d0bd17319d5190ca46760.png)** | ![](https://cdn.jsdelivr.net/gh/geiyiren/MyBlogImage1/常用图像变换/d565b8b1a2af708a41f010d0b6f7e810.png) |\n| **原图**                                                | **开运算**                                                | **顶帽**                                            |\n\n**顶帽操作是原始图像与开运算的结果之差。黑帽操作是闭运算的结果与原始图像之差。**\n\n# 几何变换\n\n几何变换是数字图像处理领域中的关键概念，用于改变图像的几何结构和外观，而不涉及像素值的修改。这些变换允许我们对图像进行缩放、旋转、平移、拉伸和扭曲等操作，以满足特定的需求和应用场景。几何变换在图像处理中有广泛的应用，从简单的尺寸调整到复杂的场景校正和特效添加。它们为我们提供了强大的工具，用于改善图像质量、分析图像内容以及实现各种计算机视觉任务。无论是医学影像分析、自动驾驶、视频游戏还是艺术创作，几何变换都是不可或缺的工具，为图像处理和计算机视觉领域的不断发展提供了关键支持。\n\n## 仿射变换\n\n仿射变换是指在向量空间中进行一次线性变换(乘以一个矩阵)并加上一个平移(加上一个向量)，变换为另一个向量空间的过程。在有限维的情况下，每个仿射变换可以由一个矩阵A和一个向量b给出，它可以写作A和一个附加的列b。一个仿射变换对应于一个矩阵和一个向量的乘法，而仿射变换的复合对应于普通的矩阵乘法，只要加入一个额外的行到矩阵的底下，这一行全部是0除了最右边是一个1，而列向量的底下要加上一个1.\n\n仿射变换描述了一种二维仿射变换的功能，它是一种二维坐标之间的线性变换，保持二维图形的“平直性”(即变换后直线还是直线，圆弧还是圆弧)和“平行性”(其实是保持二维图形间的相对位置关系不变，平行线还是平行线，而直线上的点位置顺序不变，另特别注意向量间夹角可能会发生变化)。仿射变换可以通过一系列的原子变换的复合来实现包括：平移(Translation)、缩放(Scale)、翻转(Flip)、旋转(Rotation)和错切(Shear).\n\n事实上，仿射变换代表的是两幅图之间的关系，我们通常使用2x3矩阵来表示仿射变换如下：\n\n![](https://cdn.jsdelivr.net/gh/geiyiren/MyBlogImage1/常用图像变换/0112ba5cf3ed3070df2c9b16a0977592.png)\n\n![](https://cdn.jsdelivr.net/gh/geiyiren/MyBlogImage1/常用图像变换/593c901c84ab56cf201b071ea784d283.png)\n\n考虑到我们要使用矩阵A和B对二维向量X=[x,y]T做变换，所以也能表示为下列形式：\n\n![](https://cdn.jsdelivr.net/gh/geiyiren/MyBlogImage1/常用图像变换/1c55f47f42310736e8d18d997a3a688f.png)\n\n得到如下效果：\n\n![](https://cdn.jsdelivr.net/gh/geiyiren/MyBlogImage1/常用图像变换/2d9e26acd785f952e36ead506de2d417.png)\n\n从上面解释中我们得知仿射变换表示的就是两幅图片的一种联系，关于这种联系的信息大致可以从以下两种场景获得。\n\na. 我们已知X和T而且我们知道他们是有联系的，接下来的工作就是求解矩阵M\n\nb. 我们一致M和X要求得T,我们只需要应用算式T=M.X即可。对于这种联系的信息可以用矩阵M清晰的表达(即给出明确的2x3矩阵)或者也可以用两幅图片点之间几何关系来表达。\n\n因为矩阵M联系着两幅图片，我们以其表示两图中各三点直接的联系为例，如下:\n\n点1,2和3(在图一中形成一个三角)与图二中三个点一一映射，仍然形成三角形，但形状已经大大改变。如果我们能通过这样两组三点求出仿射变换（你能选择自己喜欢的点），接下来我们就能把仿射变换应用到图像中所有的点。\n\n对实际的图像进行仿射变换的效果如下：\n\n| ![](https://cdn.jsdelivr.net/gh/geiyiren/MyBlogImage1/常用图像变换/38c2d8927c01a06858a43fe180df10bf.png) | ![](https://cdn.jsdelivr.net/gh/geiyiren/MyBlogImage1/常用图像变换/a1bdbc0eb00b913a9ec23e1a92074091.png) |\n|---------------------------------------------------------|---------------------------------------------------------|\n| **原图**                                                | **仿射变换**                                            |\n\n**仿射变换是将矩形变换成平行四边形，变换后各边依旧平行。**\n\n## 透视变换\n\n透视变换不能保证物体形状的“平行性”。仿射变换是透视变换的特殊形式。透视变换是将一个平面投影到另一个平面，简单理解就是把一张图片投影到另一张图片，求的是同一张图片到它的投影图片之间的变换。透视变换是将成像投影到一个新的视平面，也称作投影映射。如图所示：\n\n![](https://cdn.jsdelivr.net/gh/geiyiren/MyBlogImage1/常用图像变换/ce8be3b8d534d31b2192bcbc583e3a81.png)\n\n透视变换原理如下：\n\n![](https://cdn.jsdelivr.net/gh/geiyiren/MyBlogImage1/常用图像变换/645bf3d7e15e69e8a183a1be8755b91f.png)\n\n上述公式中， (*u*,*v*) 代表原始图像坐标， (*x*,*y*) 为经过透视变换的图片坐标，其中变换矩阵为3×3 形式。进而可以得到：\n\n![](https://cdn.jsdelivr.net/gh/geiyiren/MyBlogImage1/常用图像变换/57a9929d24923ac6eb7581731ccfe3e6.png)\n\n在原图上取4点坐标与新图对应，相当于列出方程组，解出变换矩阵。通过变换矩阵，在输入原图像坐标的情况下，可以直接求解新图平面坐标。\n\n![](https://cdn.jsdelivr.net/gh/geiyiren/MyBlogImage1/常用图像变换/7c71e1a5dbcf76e3543a33c99c3171cc.png)\n\n其中， (*x*,*y*)是原图坐标，<span style=\"display: inline-block; vertical-align: middle;\"><img src=\"https://cdn.jsdelivr.net/gh/geiyiren/MyBlogImage1/常用图像变换/c002438d0c0f30cdbb142c65c99ef72b.png\" alt=\"\" style=\"max-height: 1.5em;\"></span>是变换后的坐标；<span style=\"display: inline-block; vertical-align: middle;\"><img src=\"https://cdn.jsdelivr.net/gh/geiyiren/MyBlogImage1/常用图像变换/c03622f9b4a0db4e9018790e5490f206.png\" alt=\"\" style=\"max-height: 1.5em;\"></span> 为旋转量，<span style=\"display: inline-block; vertical-align: middle;\"><img src=\"https://cdn.jsdelivr.net/gh/geiyiren/MyBlogImage1/常用图像变换/a057b24fb85fb51287d74dba2baef71c.png\" alt=\"\" style=\"max-height: 1.5em;\"></span>  为平移量。因为透视变换是非线性的，所以不能齐次性表示；透视变换矩阵为3×3。透视变换的方程组有8个未知数，所以要求解就需要找到4组映射点，四个点就刚好确定了一个三维空间。\n\n利用透视变换常常进行图像的“摆正”，示例如下：\n\n| ![](https://cdn.jsdelivr.net/gh/geiyiren/MyBlogImage1/常用图像变换/ecfb0ef920f80807ce2f9227c6aeff55.png) | ![](https://cdn.jsdelivr.net/gh/geiyiren/MyBlogImage1/常用图像变换/5a59ba2712377bcb27bd960e2a078dba.png) |\n|---------------------------------------------------------|-----------------------------------------------------------------------------------------|\n| **原图**                                                | **透视变换**                                                                            |\n\n**透视变换用于将一个二维平面上的图像从一种视角或投影方式转换为另一种视角或投影方式的方法。它的主要目的是消除或校正由于观察角度或位置变化引起的投影畸变，以便更准确地分析或呈现图像中的对象。**\n\n# 去畸变\n\n这里重点介绍鱼眼相机为例展开介绍。首先，鱼眼镜头为什么可以获得比普通镜头更大的视野范围呢，他们两者之间的差别在哪？\n\n其实，我们平常接触的大多数镜头都可以近似看做针孔相机模型，该模型下，光线沿直线传播，像与物之间是相似的，或者更严格地用数学语言来说，像与物之间是经过了透视变换（Perspective Transform）。在透视变换下，直线经过变换仍是直线，曲线经过变换仍是曲线，两直线交点经过变换仍是两直线相交的点等。正因为投影变换保持了很多几何性质不变，所以我们看照片是能够与原场景联系起来的，照片与原场景之间存在某些相似的特性。那么鱼眼镜头为什么可以获得比普通镜头更大的视野范围呢，他们两者之间的差别在哪？\n\n从某种意义上来说，相机镜头所起的作用，就是做了一个数学变换，将物空间变换为像空间，成像平面就是在像空间内切了一刀，截取了一个平面，成为拍下的照片。\n\n但基于针孔相机模型的镜头存在一个缺陷——光线始终沿直线传播使得镜头难以捕捉位于边缘的物体。如下图所示，对于同样长度的红色箭头，越靠近边缘的经过镜头成像后就变得越长，而实际上我们底片的尺寸是有限的，所以极端接近边缘的物体普通的镜头就无法成像记录了。\n\n![](https://cdn.jsdelivr.net/gh/geiyiren/MyBlogImage1/常用图像变换/784946d7aeaf0b77e4b5e91eb85e0e78.png)\n\n于是人们想到的水下的鱼。由于水的折射率比空气大，光线从空气进入水中，折射角比入射角更小，并且入射角越大，这个变小的程度也越大。由于这个特性，使得在水中向上看时，能一眼看到整个水面上的这个半球形空间，整个空间的影像都背扭曲、压缩到了一个半顶角约为48°的锥形内。\n\n![](https://cdn.jsdelivr.net/gh/geiyiren/MyBlogImage1/常用图像变换/ab3ff1d293450f796c8a04a36468a708.png)\n\n在这个锥形空间内部，是来自水面上的空间的光线，在这个锥形外部，是来自水面下景色的反射。也就是说，在水下向上看，在一个圈之外，只能看到水底的景色；所有水面上的景色，都被压缩在一个圈内，如下图所示。鱼眼镜头也是人们根据这种特性发明的，另外，鱼眼镜头的前镜片直径很短，且呈抛物状像前部凸出，与鱼的眼睛十分相似，“鱼眼镜头”因此而得名。\n\n![](https://cdn.jsdelivr.net/gh/geiyiren/MyBlogImage1/常用图像变换/6a0cdceaaeabedb67171931925741dac.jpeg)\n\n鱼眼镜头一般是由十几个不同的透镜组合而成的，如下图所示，在成像的过程中，入射光线经过不同程度的折射，投影到尺寸有限的成像平面上，使得鱼眼镜头与普通镜头相比起来拥有了更大的视野范围。\n\n![](https://cdn.jsdelivr.net/gh/geiyiren/MyBlogImage1/常用图像变换/8f225713814103dc0d3d5d279921a18e.png)\n\n在研究鱼眼相机成像时，可以将上面的镜头组简化为一个球面，如下图所示，*O1-XcYcZc*为相机坐标系，O2-xy为成像平面。现实世界有一点P,入射角θ，如果按照普通相机的针孔相机模型，入射光线PO1经过镜头之后不改变路线,P、O1、<span style=\"display: inline-block; vertical-align: middle;\"><img src=\"https://cdn.jsdelivr.net/gh/geiyiren/MyBlogImage1/常用图像变换/561fc8fc43f1ead10dd35a66513d00a5.png\" alt=\"\" style=\"max-height: 1.5em;\"></span>三点共线，<span style=\"display: inline-block; vertical-align: middle;\"><img src=\"https://cdn.jsdelivr.net/gh/geiyiren/MyBlogImage1/常用图像变换/561fc8fc43f1ead10dd35a66513d00a5.png\" alt=\"\" style=\"max-height: 1.5em;\"></span>为P的像点，但是对于鱼眼相机，入射光线PO1经过镜头后会发生折射，因此P的像点为*p*，极坐标表示为（r，φ）。\n\n![](https://cdn.jsdelivr.net/gh/geiyiren/MyBlogImage1/常用图像变换/7d8730b23f213a652c7831c05825b3b7.png)\n\n根据投影函数的不同，鱼眼相机的设计模型大致能被分为五种：透视投影（即针孔相机模型）、等积投影、等距投影、体视投影、正交投影。而实际的镜头因为各种原因并不会精确的符合投影模型，为了方便鱼眼相机的标定，一般取r关于θ泰勒展开式的前5项来近似鱼眼镜头的实际投影函数：\n\n![](https://cdn.jsdelivr.net/gh/geiyiren/MyBlogImage1/常用图像变换/fa31e394765b87121758996872f7340e.png)\n\n![](https://cdn.jsdelivr.net/gh/geiyiren/MyBlogImage1/常用图像变换/ea2695d35ac1024134b00751cfad39a0.png)\n\n假设相机坐标系下有一点P(x,y,z)，点P(x,y,z)如果按照针孔相机模型投影，则不存在畸变，像点为P0(a,b)。不妨假设f=1（最终可以求得rd 和r的比值与f无关）,可求得P0 点坐标y以及入射角θ：\n\n![](https://cdn.jsdelivr.net/gh/geiyiren/MyBlogImage1/常用图像变换/b7807a8872366727b6299499d28345f5.png)\n\n由于畸变的存在，像点到图像中心的距离r被压缩成rd,实际的像点位置为p'(x',y),有\\|Op'\\|=rd,\\|OP0\\|=r。结合等距投影函数有：\n\n![](https://cdn.jsdelivr.net/gh/geiyiren/MyBlogImage1/常用图像变换/f3a9b01ac3248215c5904b2b87d9c74f.png)\n\n因为f=1，θd 的一次项系数k0 可以为1，最终可以得到OpenCV中使用的鱼眼相机模型：\n\n![](https://cdn.jsdelivr.net/gh/geiyiren/MyBlogImage1/常用图像变换/a821cb9a522abf758657aeab932fd8dc.png)\n\n由相似三角形原理：\n\n![](https://cdn.jsdelivr.net/gh/geiyiren/MyBlogImage1/常用图像变换/4543df1de58c719a6be4c04ca947624b.png)\n\n所以就求得了畸变后点p' 的坐标为：\n\n![](https://cdn.jsdelivr.net/gh/geiyiren/MyBlogImage1/常用图像变换/eb3e8f28d45e99d9ba53eefb2d2a8d4b.png)\n\n最后利用相机内参将像平面的点转换到像素坐标系就得到了最终图像上的点：\n\n![](https://cdn.jsdelivr.net/gh/geiyiren/MyBlogImage1/常用图像变换/d10563806f7a6f97c687a2b74f4e4543.png)\n\n鱼眼相机拍摄的图像去畸变后的效果如下所示：\n\n| ![](https://cdn.jsdelivr.net/gh/geiyiren/MyBlogImage1/常用图像变换/1f0d3bb10e87bd6e364a92c8e5406a41.png) | ![](https://cdn.jsdelivr.net/gh/geiyiren/MyBlogImage1/常用图像变换/06680c23f161c764dc5e05cee7011e22.png)![](https://cdn.jsdelivr.net/gh/geiyiren/MyBlogImage1/常用图像变换/06680c23f161c764dc5e05cee7011e22.png) |\n|----------------------------------------------------|----------------------------------------------------------------------------------------------------------------------|\n| **原图**                                           | **去畸变图像**                                                                                                       |\n\n**可以看出去畸变图像的视野相比与原始图像视野范围有所减小，但物体更贴近实际尺寸。**\n\n# 实验\n\n- code\n```cpp\n#include <opencv2/opencv.hpp>\n#include <opencv2/highgui/highgui.hpp>\n#include <opencv2/imgproc/imgproc.hpp>\n#include <vector>\n#include <iostream>\n#include <cstdlib> \n#include <string>  \n\n/**\n * @description: 腐蚀变换\n * @return {*}\n * @author: wangshuaiyang\n */\nint MyErode(cv::Mat input_image)\n{\n    cv::Mat src_img = input_image.clone();\n    cv::Mat my_struct = cv::getStructuringElement(cv::MORPH_RECT, cv::Size(5, 5)); // ;\n    cv::Mat dst_img;\n    cv::morphologyEx(src_img, dst_img, cv::MORPH_ERODE, my_struct);\n    cv::imshow(\"腐蚀变换\", dst_img);\n    cv::imwrite(\"腐蚀变换.png\", dst_img);\n    cv::waitKey(0);\n    return 0;\n}\n\n/**\n * @description: 膨胀变换\n * @return {*}\n * @author: wangshuaiyang\n */\nint MyDilate(cv::Mat input_image)\n{\n    cv::Mat src_img = input_image.clone();\n    cv::Mat my_struct = cv::getStructuringElement(cv::MORPH_RECT, cv::Size(5, 5)); // 十字形结构元素;\n    cv::Mat dst_img;\n    cv::morphologyEx(src_img, dst_img, cv::MORPH_DILATE, my_struct);\n    cv::imshow(\"膨胀变换\", dst_img);\n    cv::imwrite(\"膨胀变换.png\", dst_img);\n    cv::waitKey(0);\n    return 0;\n}\n\n/**\n * @description: 开运算\n * @return {*}\n * @author: wangshuaiyang\n */\nint MyOpen(cv::Mat input_image)\n{\n    cv::Mat src_img = input_image.clone();\n    cv::Mat my_struct = cv::getStructuringElement(cv::MORPH_RECT, cv::Size(5, 5)); // 十字形结构元素;\n    cv::Mat dst_img;\n    cv::morphologyEx(src_img, dst_img, cv::MORPH_OPEN, my_struct);\n    cv::imshow(\"开运算\", dst_img);\n    cv::imwrite(\"开运算.png\", dst_img);\n    cv::waitKey(0);\n    return 0;\n}\n\n/**\n * @description: 闭运算\n * @return {*}\n * @author: wangshuaiyang\n */\nint MyClose(cv::Mat input_image)\n{\n    cv::Mat src_img = input_image.clone();\n    cv::Mat my_struct = cv::getStructuringElement(cv::MORPH_RECT, cv::Size(5, 5)); // 十字形结构元素;\n    cv::Mat dst_img;\n    cv::morphologyEx(src_img, dst_img, cv::MORPH_CLOSE, my_struct);\n    cv::imshow(\"闭运算\", dst_img);\n    cv::imwrite(\"闭运算.png\", dst_img);\n    cv::waitKey(0);\n    return 0;\n}\n\n/**\n * @description: 顶帽\n * @return {*}\n * @author: wangshuaiyang\n */\nint MyTopHat(cv::Mat input_image)\n{\n    cv::Mat src_img = input_image.clone();\n    cv::Mat my_struct = cv::getStructuringElement(cv::MORPH_RECT, cv::Size(5, 5)); // 十字形结构元素;\n    cv::Mat dst_img;\n    cv::morphologyEx(src_img, dst_img, cv::MORPH_TOPHAT, my_struct);\n    cv::imshow(\"顶帽\", dst_img);\n    cv::imwrite(\"顶帽.png\", dst_img);\n    cv::waitKey(0);\n    return 0;\n}\n\n/**\n * @description: 黑帽\n * @return {*}\n * @author: wangshuaiyang\n */\nint MyBlackHat(cv::Mat input_image)\n{\n    cv::Mat src_img = input_image.clone();\n    cv::Mat my_struct = cv::getStructuringElement(cv::MORPH_RECT, cv::Size(5, 5)); // 十字形结构元素;\n    cv::Mat dst_img;\n    cv::morphologyEx(src_img, dst_img, cv::MORPH_BLACKHAT, my_struct);\n    cv::imshow(\"黑帽\", dst_img);\n    cv::imwrite(\"黑帽.png\", dst_img);\n    cv::waitKey(0);\n    return 0;\n}\n\n/**\n * @description: 形态学梯度\n * @return {*}\n * @author: wangshuaiyang\n */\nint MyGradient(cv::Mat input_image)\n{\n    cv::Mat src_img = input_image.clone();\n    cv::Mat my_struct = cv::getStructuringElement(cv::MORPH_RECT, cv::Size(5, 5)); // 十字形结构元素;\n    cv::Mat dst_img;\n    cv::morphologyEx(src_img, dst_img, cv::MORPH_GRADIENT, my_struct);\n    cv::imshow(\"形态学梯度\", dst_img);\n    cv::imwrite(\"形态学梯度.png\", dst_img);\n    cv::waitKey(0);\n    return 0;\n}\n\n/**\n * @description: 仿射变换\n * @return {*}\n * @author: wangshuaiyang\n */\nint MyAffine(cv::Mat input_image)\n{\n    cv::Mat src_img = input_image.clone();\n\n    float scale_x = 0.7;     // 水平缩放因子\n    float scale_y = 0.3;     // 垂直缩放因子\n    float theta = CV_PI / 5; // 旋转角度\n    float tx = 100;           // 水平平移量\n    float ty = 30;           // 垂直平移量\n    float shear_x = 0.8;     // X轴错切\n    float shear_y = 0.2;     // Y轴错切\n\n    cv::Mat warpMatrix = cv::Mat::zeros(2, 3, CV_32FC1);\n    warpMatrix.at<float>(0, 0) = scale_x * cos(theta);\n    warpMatrix.at<float>(0, 1) = -shear_y * scale_y * sin(theta);\n    warpMatrix.at<float>(0, 2) = tx;\n    warpMatrix.at<float>(1, 0) = shear_x * scale_x * sin(theta);\n    warpMatrix.at<float>(1, 1) = scale_y * cos(theta);\n    warpMatrix.at<float>(1, 2) = ty;\n\n    cv::Mat dst_img;\n    cv::warpAffine(src_img, dst_img, warpMatrix, src_img.size());\n    cv::imshow(\"仿射变换\", dst_img);\n    cv::imwrite(\"仿射变换.png\", dst_img);\n    cv::waitKey(0);\n    return 0;\n}\n\n// 鼠标操作 自己准备结构体\nstruct ImageData\n{\n    cv::Mat img;                // 目标图像 用于点击 确定坐标\n    std::vector<cv::Point2f> points; // 存放原图的坐标 通过鼠标的点击进行存放\n};\n//鼠标操作的回调函数:用于选择四个角的点（使用方法：从左上角开始顺时针选择四个点，选完之后回车操作）\nvoid mouseHundle(int event,int x,int y,int flag,void *arg)\n{\n    // 强制转换\n    struct ImageData *d = (struct ImageData *)arg;\n    // 如果按下的是鼠标左键\n    if (event == cv::EVENT_LBUTTONDOWN)\n    {\n        // 用圆形来标记下鼠标按下左键标记的位置\n        cv::circle(d->img, cv::Point(x, y), 3, cv::Scalar(255), 3, CV_AA); // 在图上标记,圆心为点击的位置\n        cv::imshow(\"Image\", d->img);                                       // 原窗口上进行显示标记点\n        printf(\"选择点%d: %d,%d...\\n\", (int)d->points.size() + 1, x, y);\n        // 透视变换 需要使用四个点的坐标\n        if (d->points.size() < 4)\n        {\n            d->points.push_back(cv::Point2f(x, y)); // 把点击下来的坐标进行存储\n        }\n        else\n        {\n            cv::setMouseCallback(\"Image\", nullptr, nullptr); // 取消鼠标回调\n            cv::destroyWindow(\"Image\");\n        }\n    }\n}\n\n/**\n * @description: 透视变换\n * @return {*}\n * @author: wangshuaiyang\n */\nint MyPerspectiveTF(cv::Mat input_image)\n{\n    cv::Mat src_img = input_image.clone();\n    cv::Mat dst_img;\n\n    ImageData data;\n    data.img = src_img.clone();\n    cv::namedWindow(\"Image\");\n    cv::setMouseCallback(\"Image\", mouseHundle, &data);\n    cv::imshow(\"Image\", src_img);\n    printf(\"请在图像上点击四个点，然后按任意键继续...\\n\");\n    cv::waitKey(0);\n\n    cv::Size dst_size = cv::Size(190, 260); // 输出图像的尺寸\n\n    std::vector<cv::Point2f> outputPoints; // 输出图像上的对应点\n    outputPoints.emplace_back(cv::Point2f(0, 0));\n    outputPoints.emplace_back(cv::Point2f(dst_size.width, 0));\n    outputPoints.emplace_back(cv::Point2f(dst_size.width, dst_size.height));\n    outputPoints.emplace_back(cv::Point2f(0, dst_size.height));\n\n    if (outputPoints.size() != 4 || data.points.size() != 4)\n    {\n        std::cerr << \"请选择4个点即可\" << std::endl;\n        return 0;\n    }\n    cv::Mat perspectiveMatrix = cv::getPerspectiveTransform(data.points, outputPoints);\n    cv::warpPerspective(src_img, dst_img, perspectiveMatrix, dst_size);\n\n    cv::imshow(\"透视变换\", dst_img);\n    cv::imwrite(\"透视变换.png\", dst_img);\n    cv::waitKey(0);\n\n    return 0;\n}\n\nint main(int argc, char *argv[])\n{\n    // 判断参数输入是否正确\n    if (argc <= 2)\n    {\n        std::cerr << \"参数错误,请使用如下命令格式: \" << argv[0] << \"[图像路径] [图像变换类型(1,2,3,...)] \" << std::endl;\n        return 1;\n    }\n\n    int mode = std::atoi(argv[2]);\n\n    if (mode == 0)\n    {\n        printf(\"说明：\\n[0] 说明\\n[1] 图像腐蚀变换\\n[2] 图像膨胀变换\\n[3] 开运算\\n[4] 闭运算\\n[5] 顶帽\\n[6] 黑帽\\n[7] 形态学梯度\\n[8] 仿射变换\\n[9] 透视变换\\n\");\n        return 0;\n    }\n\n    // 获得图像\n    cv::Mat img = cv::imread(argv[1], cv::IMREAD_GRAYSCALE);\n    cv::imshow(\"原始图像\", img);\n    cv::imwrite(\"原始图像.png\", img);\n    cv::waitKey(0);\n\n    int ret = 0;\n    switch (mode)\n    {\n    case 1:\n        printf(\"图像腐蚀变换...\\n\");\n        ret = MyErode(img);\n        break;\n    case 2:\n        printf(\"图像膨胀变换...\\n\");\n        ret = MyDilate(img);\n        break;\n    case 3:\n        printf(\"开运算...\\n\");\n        ret = MyOpen(img);\n        break;\n    case 4:\n        printf(\"闭运算...\\n\");\n        ret = MyClose(img);\n        break;\n    case 5:\n        printf(\"顶帽...\\n\");\n        ret = MyTopHat(img);\n        break;\n    case 6:\n        printf(\"黑帽...\\n\");\n        ret = MyBlackHat(img);\n        break;\n    case 7:\n        printf(\"形态学梯度...\\n\");\n        ret = MyGradient(img);\n        break;\n    case 8:\n        printf(\"仿射变换...\\n\");\n        ret = MyAffine(img);\n        break;\n    case 9:\n        printf(\"透视变换...\\n\");\n        ret = MyPerspectiveTF(img);\n        break;\n    }\n\n    return 0;\n}\n```\n\n- 编译命令\n```bash\ng++ image_transform.cpp -o image_transform -lopencv_core -lopencv_highgui -lopencv_imgproc -lopencv_imgcodecs -lopencv_calib3d\n```\n\n- 运行命令\n```bash\n./image_transform 图像路径 图像变换类型(1,2,3,...)\n```\n\n# 参考文献\n\n1.  <https://blog.csdn.net/qq_16137569/article/details/112398976>\n2.  数字图像处理（第四版）\n","tags":["opencv","图像变换"],"categories":["opencv"]},{"title":"OpenGL_ES常用问答","slug":"OpenGL_ES常用问答","url":"/2023/06/21/opengl-es-chang-yong-wen-da/","content":"\n# glUseProgram什么时候使用?\n\nglUseProgram是OpenGL中的一个函数，用于指定当前使用的着色器程序对象。着色器程序对象是由顶点着色器和片段着色器组成的，用于描述渲染管线中的图形处理和光栅化阶段。\n\nglUseProgram函数的调用时机通常是在绘制场景之前。当你创建并编译好顶点着色器和片段着色器，并将它们链接为一个着色器程序对象后，你需要使用glUseProgram来告诉OpenGL在绘制时要使用这个着色器程序。\n\n具体的步骤通常是这样的：\n\n> 1. 创建顶点着色器和片段着色器，并编译它们。\n> 2. 创建一个着色器程序对象，并将顶点着色器和片段着色器附加到该对象上。\n> 3. 链接着色器程序对象。\n> 4. 在每次绘制场景之前，调用glUseProgram函数，将着色器程序对象作为参数传递进去，以指定当前使用的着色器程序。\n> 5. 执行绘制操作，OpenGL将使用当前指定的着色器程序进行渲染。\n\n通过glUseProgram函数，你可以在渲染过程中灵活地切换不同的着色器程序，以实现不同的渲染效果或实现特定的图形处理算法。\n\n# glActiveTexture什么时候使用?\n\nglActiveTexture是OpenGL中的一个函数，用于指定当前活动的纹理单元。纹理单元是用于存储和处理纹理数据的硬件单元。\n\nglActiveTexture函数的调用时机通常是在设置纹理之前。在渲染过程中，你可能会使用多个纹理，例如一张用于漫反射贴图，一张用于法线贴图等。glActiveTexture函数允许你指定当前要操作的纹理单元，以便后续的纹理相关函数能够作用于指定的单元。\n\n具体的步骤通常是这样的：\n\n1. 在绑定纹理之前，调用glActiveTexture函数，传递一个纹理单元的索引作为参数。常用的索引值为GL_TEXTURE0、GL_TEXTURE1等，表示不同的纹理单元。\n2. 绑定纹理对象到指定的纹理单元。使用glBindTexture函数将纹理对象与当前活动的纹理单元关联起来。例如，使用glBindTexture(GL_TEXTURE_2D, textureID)将纹理对象绑定到当前活动的纹理单元上。\n3. 设置纹理参数和上传纹理数据等操作。在glActiveTexture函数和glBindTexture函数之后，你可以执行一系列与纹理相关的操作，如设置纹理过滤方式、纹理环绕方式、上传纹理数据等。\n\n通过glActiveTexture函数，你可以在渲染过程中使用多个纹理单元，并对每个纹理单元进行独立的设置和绑定。这样可以实现更复杂的纹理映射效果，如多重纹理、立方体贴图等。\n\n\n# 怎么从缓冲区读取像素数据？\n\n```cpp\n // 读取颜色缓冲区的像素数据\n        std::vector<unsigned char> pixelData(10 * 10 * 4); // RGBA格式，每个像素4个字节\n        glReadPixels(0, 0, 10, 10, GL_RGBA, GL_UNSIGNED_BYTE, pixelData.data());\n        // 检查像素数据\n        for (int i = 0; i < 10; ++i)\n        {\n            for (int j = 0; j < 10; ++j)\n            {\n                int pixelIndex = (i * 10 + j) * 4; // 每个像素4个字节\n                unsigned char red = pixelData[pixelIndex];\n                unsigned char green = pixelData[pixelIndex + 1];\n                unsigned char blue = pixelData[pixelIndex + 2];\n                unsigned char alpha = pixelData[pixelIndex + 3];\n                // 打印像素值\n                LOGI(1, \"像素(%d, %d): R=%d, G=%d, B=%d, A=%d\\n\", i, j, red, green, blue, alpha);\n            }\n        }\n```\n\n# 怎么获取opengl es的错误代码？\n\n```cpp\n EGLint status2 = eglGetError();\n        if (status2 != EGL_SUCCESS)\n        {\n            return -1;\n            LOGI(1, \"eglSwapBuffers failed!!!, status= %d\\n\", status2); // 帧缓冲不完整，eglSwapBuffers 执行失败}\n        }\n```\n\n# VAO绑定怎么使用？\n\n```cpp\nglBindVertexArray(VAO);\n```\n绑定顶点数组对象,执行VAO绑定之后其后的所有VBO配置都是这个VAO对象的一部分。具体来说，glBindVertexArray的作用是将VAO与当前上下文相关的顶点状态绑定在一起。顶点状态包括顶点属性指针、顶点缓冲对象等。当我们需要绘制时，只需绑定相应的VAO，OpenGL会自动应用之前设置的顶点状态。\n\n# glDrawElements函数有什么作用？\n\nglDrawElements函数用于绘制索引化的图元，它并不会将绘制结果保存在任何地方。它的作用是根据索引数据来指定绘制顶点的顺序，并将这些顶点渲染到当前帧缓冲对象中。\n绘制结果的保存通常发生在帧缓冲对象（Framebuffer Object, FBO）中。帧缓冲对象是一个特殊的OpenGL对象，它可以作为渲染目标来保存绘制结果。可以将帧缓冲对象与纹理或渲染缓冲对象关联，以便将绘制结果保存在纹理或渲染缓冲对象中。\n在使用glDrawElements之前，需要先创建并绑定顶点数组对象（VAO），并将索引数据存储在索引缓冲对象（Index Buffer Object, IBO）中。然后，通过glBindVertexArray绑定VAO，使用glBindBuffer将IBO绑定到GL_ELEMENT_ARRAY_BUFFER目标，以告诉OpenGL使用IBO中的索引来绘制顶点。\n\n# 怎么设置纹理采样方式和纹理拉伸方式？\n\n```cpp\n// ## 设置纹理拉伸方式\nglTexParameterf(GL_TEXTURE_2D, GL_TEXTURE_WRAP_S, GL_CLAMP_TO_EDGE); // 设置纹理 S 横轴）的拉伸方式为截取\nglTexParameterf(GL_TEXTURE_2D, GL_TEXTURE_WRAP_T, GL_CLAMP_TO_EDGE); // 设置纹理 T 纵轴）的拉伸方式为截取\n// ## 设置纹理采样方式\nglTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_LINEAR); // 将纹理缩小时(GL_TEXTURE_MIN_FILTER)，会进行线性插值(GL_LINEAR)来计算新的纹理像素值。\nglTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_LINEAR); // 将纹理放大时(GL_TEXTURE_MAG_FILTER)，会进行线性插值(GL_LINEAR)来计算新的纹理像素值。\n```\n在OpenGL中，纹理参数是与当前绑定的纹理对象相关联的。当你调用glTexParameterf函数设置纹理参数时，它会作用于当前绑定的纹理对象。\n要确定glTexParameterf设置的是哪个纹理的参数，需要在调用该函数之前通过glBindTexture函数将相应的纹理对象绑定到当前纹理目标。\n\n\n# Surfaceview和GLSurfaceview有什么区别\n\nSurfaceView和GLSurfaceView是Android中用于图形渲染的两个重要视图类，它们之间有以下区别：\n\n1. 功能和用途：SurfaceView是用于显示普通2D图形和视频的视图，而GLSurfaceView则是专门用于显示OpenGL ES图形的视图。GLSurfaceView提供了与OpenGL ES渲染相关的功能和接口，可以更方便地进行OpenGL ES的初始化、渲染和交互操作。\n\n2. 渲染机制：SurfaceView使用双缓冲机制进行绘制，即在后台线程中渲染图形，并将渲染结果通过SurfaceHolder进行显示。这种机制使得SurfaceView能够在主UI线程之外进行绘制，适用于需要频繁更新的图形或视频场景。GLSurfaceView也采用了双缓冲机制，但它使用了专门的渲染线程，并提供了OpenGL ES渲染上下文的管理和控制。\n\n3. 对性能的要求：由于SurfaceView在单独的线程中进行渲染，因此它更适合于需要高性能渲染的场景，如视频播放、游戏等。GLSurfaceView在底层使用了OpenGL ES，因此可以更高效地进行图形渲染，并提供了更多与OpenGL ES相关的功能和特性。\n\n4. 交互处理：SurfaceView的UI事件处理是在主UI线程中进行的，而GLSurfaceView可以通过设置Renderer来处理与OpenGL ES相关的交互事件，如触摸事件、按键事件等。\n5. 使用SurfaceView时候需要单独开启线程进行循环渲染，而GLSurfaceView在每帧渲染之前会自动调用onDrawFrame函数，因此我们可以将渲染程序写在onDrawFrame中，无线单独开启线程。\n6. 使用SurfaceView时候需要绑定窗口并设置窗口属性，而GLSurfaceView默认绑定当前窗口，无需额外绑定。\n\n综上所述，SurfaceView适用于普通的2D图形和视频显示，而GLSurfaceView则专注于OpenGL ES图形渲染，并提供更高性能和更多的OpenGL ES功能。选择使用哪个类取决于你的具体需求和场景。","tags":["OpenGL ES"],"categories":["OpenGL ES"]},{"title":"C++对象优化","slug":"c++对象优化","url":"/2023/05/29/c-dui-xiang-you-hua/","content":"\n# 对象使用过程中背后调用了哪些方法\n\n## 代码\n\n```cpp\n#include <iostream>\nusing namespace std;\nclass Test\n{\npublic:\n\tTest(int a=10):ma(a)\n\t{\n\t\tcout<<\"Test(int)\"<<endl;\n\t}\n\n\t~Test()\n\t{\n\t\tcout<<\"~Test()\"<<endl;\n\t}\n\n\tTest (const Test &t):ma(t.ma)\n\t{\n\t\tcout<<\"Test (const Test &t)\"<<endl;\n\t}\n\n\tTest& operator=(const Test &t)\n\t{\n\t\tcout<<\"operator=\"<<endl;\n\t\tma = t.ma;\n\t\treturn *this;\n\t}\nprivate:\n\tint ma;\n};\n\nint main()\n{\n\tcout<<\"--- 1 ---\"<<endl;\n\tTest t1;\n\n\tcout<<\"--- 2 ---\"<<endl;\n\tTest t2(t1);\n\n\tcout<<\"--- 3 ---\"<<endl;\n\tTest t3 = t1;\n\n\tcout<<\"--- 4 ---\"<<endl;\n\tTest t4 = Test(20);\n\n\tcout<<\"--- 5 ---\"<<endl;\n\tt4 = t2;\n\n\tcout<<\"--- 6 ---\"<<endl;\n\tt4 = Test(30);\n\n\tcout<<\"--- 7 ---\"<<endl;\n\tt4 = (Test)30;\n\n\tcout<<\"--- 8 ---\"<<endl;\n\tt4 = 30;\n\n\tcout<<\"--- 9 ---\"<<endl;\n\t//Test *p = &Test(40;)\n\n\tcout<<\"--- 10 ---\"<<endl;\n\tconst Test &ref = Test(50);\n\n}\n```\n\n## 运行结果\n\n```bash\n--- 1 ---\nTest(int)\n--- 2 ---\nTest (const Test &t)\n--- 3 ---\nTest (const Test &t)\n--- 4 ---\nTest(int)\n--- 5 ---\noperator=\n--- 6 ---\nTest(int)\noperator=\n~Test()\n--- 7 ---\nTest(int)\noperator=\n~Test()\n--- 8 ---\nTest(int)\noperator=\n~Test()\n--- 9 ---\n--- 10 ---\nTest(int)\n~Test()\n~Test()\n~Test()\n~Test()\n~Test()\n```\n\n## 解析\n- 1\t\n正常使用构造函数生成t1，传入参数有默认值\n- 2\t\n常见的拷贝构造\n- 3\t\n拷贝构造\n- 4\t\nC++编译器对于对象构造的优化，用临时对象生成新对象的时候，临时对象就不产生了，直接构造新对象，因此这里等价于直接调用常规构造函数，不调用拷贝构造\t\t\nTest(20)显式生成临时对象，生存周期为所在语句\t\t\n因此这里的Test t4 = Test(20);等价于Test t4(20);\t\t\n- 5\t\n调用了赋值运算符重载函数\n- 6\t\t\n使用临时对象为已经存在的对象赋值，这时临时对象需要生成，要不无法赋值，显式生成临时对象\n- 7\t\t\n把30强制转换为Test，然后将int 转换为 Test(int)，这时就要看这个类有没有输入为int的构造函数，进而调用。这时临时对象需要生成，要不无法赋值，显式生成临时对象\n- 8\t\n把30强制转换为Test，然后将int 转换为 Test(int)，这时就要看这个类有没有输入为int的构造函数，进而调用。这时临时对象需要生成，要不无法赋值，隐式生成临时对象\n- 9\t\n这里的临时对象需要生成，且出了语句临时对象就会调用析构函数，因此这里说明使用指针指向临时对象是不安全的，因此这里直接运行是报错的，无法获取右值的地址\n- 10\t\n这里的临时对象需要生成，且出了语句临时对象不会调用析构函数\n\n\n```cpp\n#include <iostream>\nusing namespace std;\nclass Test\n{\npublic:\n\tTest(int a=5, int b = 5) : ma(a),mb(b)\n\t{\n\t\tcout<<\"Test(int, int)\"<<endl;\n\t}\n\n\t~Test()\n\t{\n\t\tcout<<\"~Test()\"<<endl;\n\t}\n\n\tTest(const Test &src) : ma(src.ma), mb(src.mb)\n\t{\n\t\tcout<<\"Test(const Test &)\"<<endl;\n\t}\n\n\tTest operator = (const Test &src)\n\t{\n\t\tma = src.ma;\n\t\tmb = src.mb;\n\t\tcout<<\"operator = \"<<endl;\n\t}\nprivate:\n\tint ma;\n\tint mb;\n};\n\nTest t1(10,10);\n\nint main()\n{\n\tcout<<\"--- 3 ---\"<<endl;\n\tTest t2(20,20);\n\n\tcout<<\"--- 4 ---\"<<endl;\n\tTest t3 = t2;\n\n\tcout<<\"--- 5 ---\"<<endl;\n\tstatic Test t4 = Test(30,30);\n\n\tcout<<\"--- 6 ---\"<<endl;\n\tt2 = Test(40,40);\n\n\tcout<<\"--- 7 ---\"<<endl;\n\tt2 = (Test)(50,50);\n\n\tcout<<\"--- 8 ---\"<<endl;\n\tt2 = 60;\n\n\tcout<<\"--- 9 ---\"<<endl;\n\tTest *p1 = new Test(70,70);\n\n\tcout<<\"--- 10 ---\"<<endl;\n\tTest *p2 = new Test[2];\n\n\tcout<<\"--- 11 ---\"<<endl;\n\t// Test *p3 = &Test(80,80);\n\n\tcout<<\"--- 12 ---\"<<endl;\n\tconst Test &p4 = Test(90,90);\n\n\tdelete p1;\n\tdelete [] p2;\n}\n\nTest t5(100,100);\n```\n\n## 运行结果\n```bash\nTest(int, int)\nTest(int, int)\n--- 3 ---\nTest(int, int)\n--- 4 ---\nTest(const Test &)\n--- 5 ---\nTest(int, int)\n--- 6 ---\nTest(int, int)\noperator = \n~Test()\n~Test()\n--- 7 ---\nTest(int, int)\noperator = \n~Test()\n~Test()\n--- 8 ---\nTest(int, int)\noperator = \n~Test()\n~Test()\n--- 9 ---\nTest(int, int)\n--- 10 ---\nTest(int, int)\nTest(int, int)\n--- 11 ---\n--- 12 ---\nTest(int, int)\n~Test()\n~Test()\n~Test()\n~Test()\n~Test()\n~Test()\n~Test()\n~Test()\n~Test()\n```\n\n## 解析\n- 5\n使用临时构造同类型新对象的时候，临时对象被优化，类似于上文的第4项\n- 7\n逗号表达式的值为最后一个参数的值，即:t2 = (Test)(50);这里将50进行了强制类型转换。编译器就会去找有没有带一个整型输入的构造函数去实现。\n- 11\n不能使用指针指向临时对象，临时对象使用后析构。\n- 12\n使用引用变量指向临时对象，相当于给临时对象起了一个别名，引用对象销毁时，临时对象才会析构。\n\n# 函数调用过程中对象背后调用了哪些方法\n\n## 代码\n\n```cpp\n#include <iostream>\nusing namespace std;\n\nclass Test\n{\npublic:\n\tTest(int data =10):ma(data){\n\t\tcout<<\"Test(int)\"<<endl;\n\t}\n\t~Test(){\n\t\tcout<<\"~Test\"<<endl;\n\t}\n\tTest(const Test &t):ma(t.ma){\n\t\tcout<<\"Test(const Test &)\"<<endl;\n\t}\n\tvoid operator=(const Test&t)\n\t{\n\t\tcout<<\"operator=\"<<endl;\n\t\tma=t.ma;\n\t}\n\n\tint getData() const {return ma;}\nprivate:\n\tint ma;\n};\n\nTest GetObject(Test t)\n{\n\tint val=t.getData();\n\tTest tmp(val);\n\treturn tmp;\n}\n\nint main()\n{\n\n\tTest t1;\n\tTest t2;\n\tt2=GetObject(t1);\n\n\treturn 0;\n}\n```\n\n## 程序运行结果\n```bash\nTest(int)\nTest(int)\n=== 1 ===\nTest(const Test &)\nTest(int)\noperator=\n~Test\n~Test\n~Test\n~Test\n```\n\n## 分析\n- Test(int)\n调用默认构造函数\n- Test(int)\n调用默认构造函数\n- Test(const Test &)\n执行`GetObject(t1)`时需要将实参t1传递给`GetObject(Test t)`函数的形参`t`,这里是不能是直接的赋值，应该是初始化，即:要默认调用构造函数(拷贝构造函数)，因此这里实际是调用了`Test(const Test &)`函数。\n- Test(int)\n这里是`GetObject(Test t)`函数内部调用了默认构造函数\n- operator=\n由于`GetObject(Test t)`函数内部的`tmp`变量在函数结束后就会被释放没有办法再把参数传递出去，因此这里其实也在调用构造函数，需要构造一个临时变量，使用函数重载进行值传递\n- ~Test\n依次执行临时对象的析构\n- ~Test\n依次执行临时对象的析构\n- ~Test\n依次执行临时对象的析构\n- ~Test\n依次执行临时对象的析构","tags":["C++","对象优化","c++课程"],"categories":["C++"]},{"title":"鱼眼相机外参标定","slug":"鱼眼相机外参标定","url":"/2023/05/29/yu-yan-xiang-ji-wai-can-biao-ding/","content":"\n# 参考网站\n\n待整理\n\n[AVM环视系统——鱼眼相机去畸变算法](https://zhuanlan.zhihu.com/p/603296375)\n\n```cpp\n// 外参求解\nstd::vector<cv::Point3f> object_points;\nif (!(cv::solvePnP(object_points, image_points_undist_new, cam_K[cam_index], cv::noArray(), cam_R[cam_index], cam_T[cam_index],\n                   false, cv::SOLVEPNP_ITERATIVE)))\n{\n    printf(\"ERROR: solvePnP cam_index[%d]\\n\", cam_index);\n}\n\nfloat projection_error = ComputeProjectionError(object_points, image_points_undist_new, cam_K[cam_index], cam_R[cam_index], cam_T[cam_index]);\n\nstd::cout << \"projection_error1: \" << projection_error << std::endl;\n// 定义迭代终止条件：最大迭代次数为 100，收敛阈值为 0.001\ncv::TermCriteria termCrit(cv::TermCriteria::MAX_ITER | cv::TermCriteria::EPS, 200, 0.001);\n// 使用 L-M（Levenberg-Marquardt） 算法进行迭代优化，不断减小重投影误差\ncv::Mat RR = cam_R[cam_index].clone();\ncv::Mat TT = cam_R[cam_index].clone();\ncv::solvePnPRefineLM(object_points, image_points_undist_new, cam_K[cam_index], cv::noArray(), RR, TT, termCrit);\n// 使用虚拟视觉伺服 (Virtual Visual Servoing)方法进行迭代优化，不断减小重投影误差\n// cv::solvePnPRefineVVS(object_points, image_points_undist_new, cam_K[cam_index], cv::noArray(), RR, TT, termCrit);\ncam_R[cam_index] = RR.clone();\ncam_R[cam_index] = TT.clone();\n```\n\n```\n\n/**\n * @description: 输入畸变图，输出去畸变图\n * @param {Mat} &img_dist\n * @param {Mat} &img_undist\n * @return {*}\n * @author: wangshuaiyang\n */\nint TAvmCal::DistToUndistImage(cv::Mat img_dist, cv::Mat &img_undist, int cam_index)\n{\n    int ret = 0;\n\n#if 1\n    // 新的相机内参矩阵和图像尺寸（可选）\n    float scale = 2.5;\n    cv::Mat new_cam_K = cam_K[cam_index].clone();\n    new_cam_K.at<float>(0, 0) = new_cam_K.at<float>(0, 0);     // fx\n    new_cam_K.at<float>(1, 1) = new_cam_K.at<float>(0, 0);     // fy\n    new_cam_K.at<float>(0, 2) = new_cam_K.at<float>(0, 0) * 5; // cx\n    new_cam_K.at<float>(1, 2) = new_cam_K.at<float>(0, 0) * 2; // cy\n\n    cv::Size new_size = cv::Size(img_dist.size().width * scale, img_dist.size().height * scale);\n    cv::fisheye::undistortImage(img_dist, img_undist, cam_K[cam_index], cam_D[cam_index], new_cam_K, new_size);\n    cv::resize(img_undist, img_undist, img_dist.size());\n\n#else\n    cv::Mat mapx;\n    cv::Mat mapy;\n\n    // 计算矫正图\n    float point_u_tmp[2];\n    float point_d_tmp[2];\n    float scale = 2.5;\n    int offset_x = 1000;\n    int offset_y = 300;\n    int w = img_dist.cols * scale;\n    int h = img_dist.rows * scale;\n    mapx.create(h, w, CV_32FC1);\n    mapy.create(h, w, CV_32FC1);\n    for (int col = 0; col < w; col += 1)\n    {\n        for (int row = 0; row < h; row += 1)\n        {\n            // 归一化\n            std::vector<cv::Point2d> unDist_points(1);\n            std::vector<cv::Point2d> dist_points(1);\n            point_u_tmp[0] = col - offset_x;\n            point_u_tmp[1] = row - offset_y;\n            unDist_points[0].x = (point_u_tmp[0] - cam_K[cam_index].at<float>(0, 2)) / cam_K[cam_index].at<float>(0, 0);\n            unDist_points[0].y = (point_u_tmp[1] - cam_K[cam_index].at<float>(1, 2)) / cam_K[cam_index].at<float>(1, 1);\n\n            cv::fisheye::distortPoints(unDist_points, dist_points, cam_K[cam_index], cam_D[cam_index]);\n\n            mapx.at<float>(row, col) = dist_points[0].x;\n            mapy.at<float>(row, col) = dist_points[0].y;\n        }\n    }\n\n    cv::remap(img_dist, img_undist, mapx, mapy, cv::INTER_LINEAR);\n\n    cv::resize(img_undist, img_undist, img_dist.size());\n#endif\n\n#if  SHOW_DETECT_PROCESS\n    cv::imshow(\"image_remap_fish\", img_undist);\n    cv::waitKey(0);\n#endif\n    return 0;\n}\n\n/**\n * @description: 计算重投影误差(使用均方误差，RMS)\n * @return {*}\n * @author: wangshuaiyang\n */\nfloat TAvmCal::ComputeProjectionError(const std::vector<cv::Point3f> &objectPoints,\n                                      const std::vector<cv::Point2f> &imagePoints,\n                                      const cv::Mat &cameraMatrix,\n                                      const cv::Mat &rvec,\n                                      const cv::Mat &tvec)\n{\n    // 使用估计的相机位姿将世界坐标系中的三维点投影到图像平面上\n    std::vector<cv::Point2f> projectedPoints;\n    cv::projectPoints(objectPoints, rvec, tvec, cameraMatrix, cv::noArray(), projectedPoints);\n\n    // 计算重投影误差\n    float RMS_Error = 0.0;\n    for (size_t i = 0; i < imagePoints.size(); ++i)\n    {\n        float dx = projectedPoints[i].x - imagePoints[i].x;\n        float dy = projectedPoints[i].y - imagePoints[i].y;\n        RMS_Error += (dx * dx + dy * dy);\n    }\n    RMS_Error /= (float)imagePoints.size();\n    RMS_Error = std::sqrt(RMS_Error);\n\n    // 返回总的重投影误差\n    return RMS_Error;\n}\n```","tags":["C++","鱼眼相机外参标定"],"categories":["鱼眼相机"]},{"title":"单例模式","slug":"单例模式","url":"/2023/05/19/dan-li-mo-shi/","content":"\n# 使用场景\n- 当存在一个或多个变量仅初始化一次，却被多个文件多次使用的情况下考虑单例模式\n- 可实现一次初始化，多文件多次使用\n- 例如 ：相机的内参和外参一般只初始化一次，然后直接使用。\n# 使用方法\n# 声明与定义\n### ParametersInit.h\n```cpp\n#ifndef __PARAMETERS_INIT_H__\n#define __PARAMETERS_INIT_H__\n\n// for thread-safe singleton\n#include <pthread.h>\n#include <iostream>\n\nclass ParametersInit\n{\nprivate:\n    static ParametersInit *m_instance;\n    static pthread_once_t _once;\n    int m_test;\npublic:\n    ParametersInit(/* args */);\n    ~ParametersInit();\n    //使用pthread_once保证init()只调用一次\n    static ParametersInit *GetInstance();\n    static void init();\n    void camParametersInit(int in_test);\n    int getTest();\n};\n\n#endif\n\n```\n### ParametersInit.cpp\n```cpp\n#include \"../inc/ParametersInit.h\"\n\n// 静态成员函数必须初始化后使用\npthread_once_t ParametersInit::_once = 0;\nParametersInit *ParametersInit::m_instance=NULL;\n\nParametersInit::ParametersInit(/* args */)\n{\n}\n\nParametersInit::~ParametersInit()\n{\n}\nvoid ParametersInit::init()\n{\n    while (!m_instance)\n    {\n        m_instance = new ParametersInit();\n    }\n}\n\nParametersInit *ParametersInit::GetInstance()\n{\n    pthread_once(&_once, ParametersInit::init);\n    return m_instance;\n}\nvoid ParametersInit::camParametersInit(int in_test)\n{\n    m_test = in_test;\n}\nint ParametersInit::getTest()\n{\n    return m_test;\n}\n```\n\n## 使用\n### init.cpp\n```cpp\n#include \"ParametersInit.h\"\n\nParametersInit *m_Instance = ParametersInit::GetInstance();\nm_Instance->camParametersInit(100);\n```\n\n### use1.cpp\n```cpp\n#include \"ParametersInit.h\"\n\nParametersInit *m_Instance = ParametersInit::GetInstance();\n// 这里可以直接使用init.cpp初始化的参数ParametersInit::m_test\nint m_test = m_Instance->getTest();//m_test=100\n```\n\n>参考网站: https://blog.csdn.net/CoderAldrich/article/details/83114881","tags":["设计模式","单例模式"],"categories":["设计模式"]},{"title":"C++多线程常用案例","slug":"C++多线程常用案例","url":"/2023/05/10/c-duo-xian-cheng-chang-yong-an-li/","content":"# 案例1\n\n## 案例说明\n\n使用C++11 std库中的线程和条件变量实现notify_one的一个简单例子。在这个例子中，我们有一个线程向一个队列中添加元素，另一个线程从队列中删除元素。线程通过条件变量进行同步。\n\n## 代码\n\n```cpp\n#include <iostream>\n#include <thread>\n#include <queue>\n#include <mutex>\n#include <condition_variable>\n\nstd::queue<int> queue;\nstd::mutex mtx;\nstd::condition_variable cv;\n\nvoid producer(int value) {\n    for (int i = 0; i < value; ++i) {\n        std::this_thread::sleep_for(std::chrono::seconds(1)); // 模拟生产\n        std::lock_guard<std::mutex> lock(mtx);\n        queue.push(i);\n        std::cout << \"Produced: \" << i << std::endl;\n        cv.notify_one(); // 通知消费者\n    }\n}\n\nvoid consumer() {\n    while(true) {\n        std::unique_lock<std::mutex> lock(mtx);\n        cv.wait(lock, []{ return !queue.empty(); }); // 等待直到队列不为空\n        int value = queue.front();\n        queue.pop();\n        std::cout << \"Consumed: \" << value << std::endl;\n    }\n}\n\nint main() {\n    std::thread t1(producer, 10);\n    std::thread t2(consumer);\n\n    t1.join();\n    t2.join();\n\n    return 0;\n}\n```\n\n在这个例子中，生产者线程在每次添加一个元素到队列后都会调用notify_one()来通知消费者线程。消费者线程在wait()函数中等待，直到收到通知并且队列不为空才会继续执行。\n\n需要注意的是，虽然在上述代码中我们的消费者线程是一个无限循环，但在实际的程序中，你需要有一种机制来结束这个线程。","tags":["C++","多线程"],"categories":["C++"]},{"title":"智能指针的使用","slug":"智能指针的使用","url":"/2023/05/10/zhi-neng-zhi-zhen-de-shi-yong/","content":"\n# 介绍\n\n在 C++ 中，智能指针是一种对象，它处理内存管理的问题，使程序员更加专注于业务逻辑而不是内存管理。C++ 标准库中提供了几种类型的智能指针，包括：\n\n- `std::unique_ptr`: 它代表独占所有权的概念。一个 `std::unique_ptr` 对象在任何时间都拥有它所指向的对象。当 `std::unique_ptr` 被销毁（例如，当离开其作用域时），它所指向的对象也会被销毁（即调用其析构函数）。\n\n- `std::shared_ptr`: 它代表共享所有权的概念。多个 `std::shared_ptr` 对象可以拥有同一个对象。当最后一个拥有该对象的 `std::shared_ptr` 被销毁时，它所指向的对象也会被销毁。\n\n- `std::weak_ptr`: 它是为了配合 `std::shared_ptr` 而存在的，它提供了一种方式访问 `std::shared_ptr` 所管理的对象，但是不增加引用计数。这对于解决 `std::shared_ptr` 循环引用的问题（即，两个 `std::shared_ptr` 相互引用，导致它们都不会被销毁）是很有用的。\n\n智能指针的使用可以极大地简化内存管理，避免内存泄漏和其他与生命周期管理相关的错误。然而，它们并不能解决所有的内存管理问题，仍然需要程序员小心谨慎地设计他们的代码。\n\n# 示例\n\n## `std::unique_ptr`示例\n\n```cpp\n#include <memory>\n\nstruct Foo {\n    Foo() { std::cout << \"Foo::Foo\\n\"; }\n    ~Foo() { std::cout << \"Foo::~Foo\\n\"; }\n    void bar() { std::cout << \"Foo::bar\\n\"; }\n};\n\nvoid f(const Foo &) {\n    std::cout << \"f(const Foo&)\\n\";\n}\n\nint main() {\n    std::unique_ptr<Foo> p1(new Foo);  // p1 独占 Foo\n\n    p1->bar();  // 输出 \"Foo::bar\"\n\n    {\n        std::unique_ptr<Foo> p2(std::move(p1));  // 现在 p2 独占 Foo\n        f(*p2);\n        p1 = std::move(p2);  // 现在 p1 独占 Foo\n    }\n\n    p1->bar();  // 输出 \"Foo::bar\"\n\n    // Foo 的析构器在这里被调用，因为 p1 被销毁\n}\n\n```\n\n## `std::shared_ptr`示例\n\n```cpp\n#include <memory>\n\nstruct Foo {\n    Foo() { std::cout << \"Foo::Foo\\n\"; }\n    ~Foo() { std::cout << \"Foo::~Foo\\n\"; }\n    void bar() { std::cout << \"Foo::bar\\n\"; }\n};\n\nint main() {\n    std::shared_ptr<Foo> p1 = std::make_shared<Foo>();\n    // 这里，我们不再需要使用 new。std::make_shared 是一个更安全，更高效的方式来分配共享对象。\n    \n    p1->bar();  // 输出 \"Foo::bar\"\n\n    {\n        std::shared_ptr<Foo> p2 = p1;\n        p2->bar();  // 输出 \"Foo::bar\"\n        // Foo 的实例仍未被删除，因为 p1 和 p2 都还在作用域内\n    }\n    \n    p1->bar();  // 输出 \"Foo::bar\"\n    \n    // Foo 的析构器在这里被调用，因为 p1 离开了作用域\n}\n\n```\n\n## `std::weak_ptr`示例\n\n```cpp\n#include <memory>\n\nstruct Foo {\n    Foo() { std::cout << \"Foo::Foo\\n\"; }\n    ~Foo() { std::cout << \"Foo::~Foo\\n\"; }\n};\n\nint main() {\n    std::weak_ptr<Foo> weak;\n    {\n        std::shared_ptr<Foo> shared = std::make_shared<Foo>();\n        weak = shared;\n        // 在 shared 存在的时候，我们可以使用 weak 来获取一个新的 shared_ptr 实例\n        auto p = weak.lock();\n        if (p) {\n            std::cout << \"Object has not been deleted\\n\";\n        }\n    }\n\n    // 这里，shared 被销毁，因此 Foo 被删除\n\n    // 因为 Foo 已经被删除，所以我们不能再从 weak 中获取一个 shared_ptr\n    auto p = weak.lock();\n    if (!p) {\n        std::cout << \"Object has been deleted\\n\";\n    }\n}\n\n```\n\n# 常用方法\n\n## reset\n\n智能指针的 reset 方法是用于释放智能指针当前拥有的对象，并可能接管新的对象。\n\n以下是 std::unique_ptr 和 std::shared_ptr 的 reset 方法的使用：\n\n- `std::unique_ptr` 的 `reset` 方法\n\n```cpp\n#include <memory>\n\nstruct Foo {\n    Foo(int val) : value(val) { std::cout << \"Foo \" << value << \" constructed.\\n\"; }\n    ~Foo() { std::cout << \"Foo \" << value << \" destructed.\\n\"; }\n    int value;\n};\n\nint main() {\n    std::unique_ptr<Foo> p(new Foo(1));  // p 现在指向一个新的 Foo 对象\n\n    p.reset(new Foo(2));  // p 释放旧的 Foo 对象并指向一个新的 Foo 对象\n    // 在这一步，\"Foo 1 destructed.\" 被打印到控制台\n}\n\n```\n\n- `std::shared_ptr` 的 `reset` 方法\n\n```cpp\n#include <memory>\n\nstruct Foo {\n    Foo(int val) : value(val) { std::cout << \"Foo \" << value << \" constructed.\\n\"; }\n    ~Foo() { std::cout << \"Foo \" << value << \" destructed.\\n\"; }\n    int value;\n};\n\nint main() {\n    std::shared_ptr<Foo> p1 = std::make_shared<Foo>(1);  // p1 现在指向一个新的 Foo 对象\n\n    std::shared_ptr<Foo> p2 = p1;  // p2 也指向同一个 Foo 对象\n\n    p1.reset(new Foo(2));  // p1 释放旧的 Foo 对象并指向一个新的 Foo 对象\n    // 但是，\"Foo 1 destructed.\" 并未被打印到控制台，因为 p2 仍然拥有它\n\n    p2.reset();  // p2 释放它的 Foo 对象\n    // 在这一步，\"Foo 1 destructed.\" 被打印到控制台\n}\n\n```","tags":["C++","智能指针"],"categories":["C++"]},{"title":"类的封装与函数绑定用法解析","slug":"类的封装与函数绑定用法解析","url":"/2023/05/10/lei-de-feng-zhuang-yu-han-shu-bang-ding-yong-fa-jie-xi/","content":"\n# 类的封装\n## 位置\n\nsrc/adas_proc/adas_app/adas_app.cpp ---> 629行\n\n## 定义\n\n```cpp\nusing AdasProcWrapper = ac::ObjWrapper<ac::AdasProcInterface, HAC_CreateAdasProc, HAC_DestroyAdasProc>;\nAdasProcWrapper                        adas_proc_;\n```\n\n- `AdasProcWrapper` 是一个类型别名（using 声明），用于定义 `adas_proc_`对象。它是由 `ac::ObjWrapper` 模板类实例化而来。  \n- `ac::ObjWrapper` 是一个模板类，接受三个模板参数：`ac::AdasProcInterface、HAC_CreateAdasProc 和 HAC_DestroyAdasProc`。\n\nObjWrapper模板类的定义如下:\n\n```cpp\n/**\n * @brief 一个简单的wrapper\n */\nusing ObjCreateType  = HAC_Handle(*)(const char *);\nusing ObjDestroyType = void(*)(HAC_Handle);\ntemplate<typename T, ObjCreateType Create, ObjDestroyType Destroy>\nclass ObjWrapper final\n{\npublic:\n    explicit ObjWrapper(const char *config)\n    {\n        obj_ = reinterpret_cast<T *>(Create(config));\n        if (obj_ == nullptr)\n        {\n            throw StringException(StringFormatWithPrefix(\"error: Create obj failed.\"));\n        }\n    }\n    ObjWrapper()\n    {\n\n    }\n    ~ObjWrapper()\n    {\n        Destroy(reinterpret_cast<HAC_Handle>(obj_));\n    }\n\n    T *operator->()\n    {\n        if (obj_ == nullptr)\n        {\n            throw StringException(StringFormatWithPrefix(\"error: obj is nullptr.\"));\n        }\n        return obj_;\n    }\n    T *Get()\n    {\n        return obj_;\n    }\n    void Reset(const char *config)\n    {\n        auto obj = reinterpret_cast<T *>(Create(config));\n        if (obj == nullptr)\n        {\n            throw StringException(StringFormatWithPrefix(\"error: Create obj failed.\"));\n        }\n        Destroy(reinterpret_cast<HAC_Handle>(obj_));\n        obj_ = obj;\n    }\n    ObjWrapper(const ObjWrapper &) = delete;\n    ObjWrapper& operator=(const ObjWrapper &) = delete;\nprivate:\n    T *obj_ = nullptr;\n};\n```\n由模板类的定义可知，该模板类有三个模板参数：\n- `typename T`：这是一个类型参数，用于指定被包装的对象的类型。\n- `ObjCreateType Create`：这是一个函数指针类型，用于指定创建对象的函数。\n- `ObjDestroyType Destroy`：这是一个函数指针类型，用于指定销毁对象的函数。\n\n因此，`AdasProcWrapper` 类型的 `adas_proc_` 对象是一个使用 `ac::ObjWrapper` 封装的 ADAS 处理实例。这个封装提供了一种方便的方式来创建和销毁 ADAS 处理实例，并提供了 ADAS 处理接口的访问。`adas_proc_`为封装类`ac::ObjWrapper`实例化后的对象。\n\n## 封装类的使用1\n\n```cpp\nadas_proc_.Reset(json_config_str.c_str());\n```\n\n封装类对象adas_proc_调用了模板类`ac::ObjWrapper`中的`Reset`函数，该函数调用了模板类创建时传入的参数2：`HAC_CreateAdasProc`,该参数是一个函数指针类型，用于指定创建对象的函数。该函数的定义如下所示：\n\n```cpp\n/**\n * @brief 创造对象\n * @param config json字符串，参考，assets目录下的配置文件,会从中读取各种配置信息，\n *               包括摄像头信息，模型文件路径,以及其他配置信息等等\n * @note 当句柄不为NULL时候，最后一定要调用HAC_DestroyAdasProc进行销毁，\n *       如果为NULL，调用或者不调用HAC_DestroyAdasProc都可以。\n * @return HAC_Handle 句柄,需要判断返回值是否是NULL\n */\nextern \"C\" HQ_FLAG_DLL_API HAC_Handle HAC_CreateAdasProc(const char *config)\n{\n    return reinterpret_cast<HAC_Handle>(new ac::AdasProcImpl(config));\n}\n```\n\n## 封装类的使用2\n\n```cpp\nadas_proc_->SetAdasInfoEvent(std::bind(&Impl::OnAdasInfo,\n            this, std::placeholders::_1, std::placeholders::_2, std::placeholders::_3));\n```\n\n其中，`SetAdasInfoEvent`函数的定义如下：\n```cpp\nvoid AdasProcImpl::SetAdasInfoEvent(const AdasInfoEvent &event)\n{\n    on_adas_info_ = event;\n}\n```\n\n其中，`OnAdasInfo`函数的定义如下：\n```cpp\nint OnAdasInfo(const uint8_t *buffer, uint32_t size, int64_t tickcount)\n{ \n    **************\n}\n```\n\n这里就有点绕了，模板类中并没有SetAdasInfoEvent函数，这里怎么能使用呢？其实这个函数的定义在`ac::AdasProcInterface`类中，由于在模板类中重载了`->`运算符，因此`adas_proc_->SetAdasInfoEvent`中的`->`是被重载后的运算符，`adas_proc_->`等同于`adas_proc_.obj_`,故`adas_proc_->SetAdasInfoEvent`等同于`adas_proc_.obj_.SetAdasInfoEvent`。\n\n这里封装类重载了`->`运算符，因此看起来封装后的类可以直接访问模板参数1指向类`ac::AdasProcInterface`的成员函数。\n\n到此为止，可以基本了解封装类的定义和使用示例。\n\n\n# 函数的绑定\n\n紧接上文，在调用`SetAdasInfoEvent`函数时使用了`std::bind`进行了函数的绑定。`std::bind` 是 C++ 标准库中的一个函数模板，它允许你创建一个函数对象，将参数绑定到可调用对象上。它位于 `<functional>` 头文件中，用于泛化函数调用。\n\nstd::bind 函数可以将一个可调用对象和一些参数绑定在一起，生成一个新的函数对象。这个新的函数对象可以延迟执行或者在需要时进行调用，而且可以自定义绑定的参数。\n\n因此,这里是将`Impl::OnAdasInfo`与其参数进行绑定后生成一个新的可调用对象，同时将其作为函数`SetAdasInfoEvent`的参数传递给`on_adas_info_`,也就是说`on_adas_info_=std::bind(&Impl::OnAdasInfo, this, std::placeholders::_1, std::placeholders::_2, std::placeholders::_3)`。这样`on_adas_info_`就可以在使用时传递参数并执行`OnAdasInfo`函数。\n\n`on_adas_info_`的调用场景如下：\n```cpp\nvoid AdasProcImpl::OnAlarmInfo(const uint8_t *buffer, uint32_t size, int64_t tickcount)\n{\n    // 设置输出信息到buffer中\n    // 把决策模块会掉出来的内容添加到out_buffer_中，然后回调到外面\n    if (on_adas_info_ != nullptr)\n    {\n        decltype(out_buffer_)  tmp;\n        {\n            \n            std::lock_guard<std::mutex> lck(buf_mutex_);\n            // 把buffer中内容放入out_buffer中\n            const auto out_buffer_length = out_buffer_.size();\n            out_buffer_.resize(out_buffer_length + size);\n            std::memcpy(out_buffer_.data() + out_buffer_length, buffer, size);\n            tmp = out_buffer_;\n            out_buffer_.resize(0);\n        }\n\n        on_adas_info_(tmp.data(), tmp.size(), tickcount);\n    }\n}\n```\n\n到此为止，可以基本了解函数绑定的定义和使用示例。","tags":["C++","类的封装","函数绑定"],"categories":["C++"]},{"title":"C++接口定义","slug":"C++接口定义","url":"/2023/05/10/c-jie-kou-ding-yi/","content":"\n# 为什么要定义接口类?\n在软件开发这个行业中，一个较大的软件项目，一般由几个小组共同开发完成，为了将小组之间的影响降低到最低，定义好接口软件成为双方关注的焦点，对于要求在短时间开发完成的接口更是如此。那么如何才能定义好的接口呢? 第一，接口名字和实际的功能相符合；第二、接口要对数据进行封装，不允许客户直接操作接口之下的数据，尤其是使用new和delete在堆上操作内存数据。因为客户很容易由于操作不当造成错误，误以为是设计的接口有问题。\n\n# 两种常见的接口定义方法？\nc++中实现对接口与实现进行分离有两种方法，一种是将对象的实现细目隐藏于指针背后，简单的说就是将其分成两个类，一个类只提供接口，另一个负责实现该接口，这种设计手法常称为Pimpl Idiom(pointer to implementation)。\n另一种方法就是将接口定义为抽象类，接口全被定义为纯虚函数的形式（纯虚函数没有具体的实现方法），派生类的成员函数负责实现这些接口。这种设计手法称为对象接口（Object Interface）。千万不要忘记把抽象接口类的析构函数定义为virtual函数，可能会造成内存泄漏。\n\n# \"对象接口\"方式\n\n## 示例1\n### 如何定义?\n\n首先给接口类下了定义：接口类应该是只提供方法声明，而自身不提供方法定义的抽象类。接口类自身不能实例化，接口类的方法定义/实现只能由接口类的子类来完成。\n\n而对于C++，其接口类一般具有以下特征：\n\n- 1.最好不要有成员变量，但可以有静态常量（static const或enum）\n- 2.要有纯虚接口方法\n- 3.要有虚析构函数，并提供默认实现\n- 4.不要声明构造函数\n\n如下就是一个最简单的例子：\n\n```cpp\nclass Testable\n{\npublic:\n    static const int START = 1;  // #1\n    static const int STOP = 2;\n \n    virtual void test() = 0;  // #2： 接口方法\n \n    virtual ~Testable() {};   // #3： 从C++11开始可以： virtual ~Testable() = default;\n}\n\n```\n\n`#1.`\n如果成员变量，尤其是可变的成员变量，定义在接口中，等于是把实现细节暴露出来了，不符合接口定义的要求，所以一般不在接口中定义可变的成员变量。\n而常量可以定义在接口中，因为有时接口需要返回状态，而这些状态可以定义成常量放在接口中。\n\n`#2.`\n由于不能让接口类自身能够实例化，并且需要子类必须实现接口暴露的方法，所以接口方法都要声明成纯虚函数。\n声明成纯虚函数意味着接口类自身不需要提供方法的定义，方法的定义需要由接口类的子类提供，并且接口类自身也因此变成了抽象类而不能被实例化。\n\n`#3.`\na). 在使用接口类的指针访问接口类的子类的实例时，当对接口类的指针做delete时，如果接口类的析构函数不是虚析构函数的话，将只会调用接口类的析构函数，接口类的子类的析构函数将不会被调用，内存泄露将会产生，所以接口类的析构函数必须定义成虚析构函数。\nb). 如果接口类的析构函数不提供默认实现，即如果接口类的析构函数是纯虚析构函数的话，接口类的子类将被迫必须提供析构函数的实现，这样对接口类的子类不友好。\nc). 在C++11中也可以用：  virtual ~Testable() = default; 替代 virtual ~Testable() {};\n\n`#4.`\n不要显式定义任何的构造函数，但也不要在接口中加入如下代码来禁止生成构造函数：\n\n```cpp\n\tTestable() = delete;\n\tTestable(const Testable&) = delete;\n```\n\n因为C++的调用机制要求子类的构造函数调用时一定会先调用父类的构造函数，如果禁止生成构造函数，代码编译时会报错。如果程序员不显式的提供构造函数，编译器也会隐式的加上构造函数的，虽然这些构造函数对于接口类来说实际没有什么意义。\n\nC++中如何定义标识接口（marker interface）类?\n标识接口是没有任何方法和属性的接口。这种接口在java中出现的较多，比如：java.io.Serializable、java.rmi.Remote、java.util.EventListener、java.util.RandomAccess\n\n实现代码如下：\n```cpp\nclass Testable {\npublic:\n    virtual ~Testable() = 0 {}; // #5\n};\n```\n`#5.`\n只要对纯虚析构函数提供一个默认实现就可以了。这种对纯虚函数提供实现的写法看似很奇怪，但C++的确是支持的。\n\n### 如何正确的使用接口类\n\n提供接口与实现\n首先，声明一个接口：\n\n- `circle.h`\n\n```cpp\n// circle.h\n// 圆的接口类\nclass Circle {\npublic:\n\tvirtual ~Circle() {};\n \n\t// 接口方法：面积\n\tvirtual double area() = 0;\n};\n```\n\n通过继承的方式实现这个接口：\n\n- `circle_impl.h`\n\n```cpp\n// circle_impl.h\n#include \"circle.h\"\n \n// 圆的具体实现类\nclass CircleImpl : public Circle {\n \nprivate:\n\tdouble radius;\npublic:\n\tCircleImpl(double radius);\n\tdouble area() override;\n};\n```\n\n- `circle_impl.cpp`\n\n```cpp\n// circle_impl.cpp\n#include <cmath>\n#include \"circle_impl.h\"\n \ninline double pi() {\n\treturn std::atan(1) * 4;\n};\n \nCircleImpl::CircleImpl(double _radius) : radius(_radius) {\n};\n \ndouble CircleImpl::area() {\n\treturn pi() * radius * radius;\n};\n```\n\n最后，通过管理类创建接口派生类的实例，或者销毁接口派生类的实例：\n\n- `circle_manager.h`\n\n```cpp\n// circle_manager.h\n#include \"circle.h\"\n \n// 圆的创建工厂类\nclass CircleManager {\npublic:\n    static Circle* create(double radius);     // 创建circle实例\n    static void destroy(Circle* circlePtr);   // 销毁circle实例\n};\n```\n\n- `circle_manager.cpp`\n\n```cpp\n// circle_manager.cpp\n#include \"circle_manager.h\"\n#include \"circle_impl.h\"\n \nCircle* CircleManager::create(double radius) {\n    Circle* circlePtr = new CircleImpl(radius);\n \n    return circlePtr;\n};\n \nvoid CircleManager::destroy(Circle* circlePtr) {\n    delete circlePtr;\n}; \n```\n\n- 代码目录结构\n\n```bash\nproj-+\n     |-inc-+\n     |     |-circle.h\n     |     |-circle_manager.h\n     |\n     |-src-+\n           |-circle_impl.h\n           |-circle_impl.cpp\n           |-circle_manager.cpp\n```\n\n其中inc目录用于存放Circle接口类和Circle管理类的声明，src目录中存放Circle实现类CircleImpl的声明和定义、Circle管理类CircleManager的定义。\n\n然后，可以将以上代码编译成静态库circle.lib，并和inc目录中的头文件一起提供给外部调用：\n\n> - `如何使用静态库？`\n> 外部使用者编译时，需要做如下配置：\n> \n> *  1 把inc目录添加到“附加包含目录”中。\n> \n> *  2 “附加依赖项”中添加circle.lib。\n> \n> *  3 把circle.lib所在目录的路径添加到“附加库目录”中。\n\n外部使用者的代码如下：\n\n- `main.cpp`\n\n```cpp\n// main.cpp\n#include <iostream>\n#include \"circle_manager.h\"\n#include \"circle.h\"\n \nint main() \n{\n    Circle* circlePtr = CircleManager::create(3);\n    cout << circlePtr->area() <<endl;\n    CircleManager::destroy(circlePtr);\n    \n    system(\"pause\");\n \n    return 0;\n}\n```\n\n以上代码只提供给外部circle的接口，circle的实现完全被隐藏了起来，外部将无从知晓，外部使用者只能通过circle管理类生成circle的派生类的实例。外部使用者得到circle派生类的实例后，除了能调用接口暴露的方法area()外，其它什么也做不了，这样就完全达到了使用接口的最终目标。\n\n`如何编译成动态库？`\n首先，添加一个新的头文件：\n\n```cpp\n// dll_export.h \n// if windows .dll \n#ifdef _WINDLL \n \n#ifdef DLL_API_EXPORTS \n#define DLL_API __declspec(dllexport) \n#else \n#define DLL_API __declspec(dllimport) \n#endif \n \n// else if Linux or macOS .so \n#else \n#define DLL_API \n#endif\n```\n\n添加此头文件后，代码可以在windows、Linux下都可编译生成动态库，只需在编译时设置不同参数就行了。\n\n```bash\nwindows： /D \"DLL_API_EXPORTS\" /D \"_WINDLL\"\nLinux： 不用配置额外参数\ncircle.h和circle_manager.h也要做相应改动：\n```\n\n编译完成后将生成”circle.lib“和”circle.dll“文件：\n\n```bash\nproj-+\n     |-inc-+\n     |     |-circle.h\n     |     |-circle_manager.h\n     |\n     |-src-+\n     |     |-circle_impl.h\n     |     |-circle_impl.cpp\n     |     |-circle_manager.cpp\n     |\n     |-bin-+\n           |-circle.lib\n           |-circlr.dll\n```\n\n`如何使用动态库？`\n外部使用者编译时，需要做如下配置：\n\n- 1 代码中添加#pragma comment(lib,\"circle.lib\")， 这里是circle.lib，不是circle.dll。\n\n- 2 把inc目录添加到“附加包含目录”中。\n\n- 3 附加依赖项”中添加circle.lib，这里也是circle.lib，不是circle.dll。\n\n- 4 把bin目录所在路径添加到”附加库目录“中。\n\n### 总结\n这里有几点需要说明一下：\n\n1、为什么CircleManager类即在提供创建实例的方法又要提供销毁实例的方法？\n\n由于编译器的实现方式不同，dll的堆空间可能跟调用方的堆空间不同，它可能是由dll自己单独管理的，所以从dll中创建的实例，最好还是在dll中销毁。\n\n2、对动态库的调用本文是通过隐式调用的方式完成的，对动态库的调用也可以使用显式调用的方式，但由于windows和Linux在使用显式调用时的API是不同的，不好提供统一的代码，所以本文没有举例，以后有机会再单独行文介绍。\n\n## 示例2\n\n- `Animal.h`\n\n```cpp\n#include <string>\nusing namespace std;\n \nclass Animal\n{\npublic:\n    Animal(){};\n    virtual ~Animal(){};\n \n    virtual string& getName() const = 0;\n    virtual void setName(string& name) = 0;\n    virtual int getAge() const = 0;\n    virtual void setAge(int age) = 0;\n};\n \nAnimal* creat(string& name, int age);\n```\n\n- `RealAnimal.h`\n\n```cpp\n#include \"Animal.h\"\n \nclass RealAnimal: public Animal \n{\npublic:\n    RealAnimal(string& name, int age);\n    virtual ~RealAnimal();\n \n    string& getName() const;\n    void setName(string& name);\n    int getAge() const;\n    void setAge(int age);\n \nprivate:\n    friend Animal* creat(string& name, int age);\n \nprivate:\n    string& mName;\n    int mAge;\n};\n```\n\n- `RealAnimal.cpp`\n```cpp\n#include \"RealAnimal.h\"\n \nRealAnimal::RealAnimal(string& name, int age):\n    mName(name),\n    mAge(age)\n{\n \n}\n \nRealAnimal::~RealAnimal()\n{\n \n}\n \nstring& RealAnimal::getName() const \n{\n    return mName;\n}\n \nvoid RealAnimal::setName(string& name)\n{\n    mName = name;\n}\n \nint RealAnimal::getAge() const\n{\n    return mAge;\n}\n \nvoid RealAnimal::setAge(int age)\n{\n    mAge = age;\n}\n \nAnimal* creat(string& name, int age) \n{\n    return new RealAnimal(name, age);\n}\n```\n\n如前面所说，Animal* creat(string& name, int age)确实只是实例化一个RealAnimal对象，返回的却是Animal接口对象，所以必须将类Animal 的析构函数声明为虚函数，不然会造成内存泄漏。\n\n\n## 总结\n\n对象接口的形式就是定义一个接口类，类内函数为纯虚函数(继承者必须实现)，放在一个接口头文件中，对外开放；然后定义一个实现上述接口的类，这个类继承了接口类，必须对类内的函数进行实现。这个外部只能看到接口头文件中内容，可以使用接口中定义的方法，但是无法修改和访问方法实现的细节。\n\n# \"指针实现\"方式\n\n## 示例1\n\n- `personImpl.h`\n\n```cpp\n#include <string>\n#include <iostream>\nusing namespace std;\n \nclass PersonImpl \n{\npublic:\n    PersonImpl(string& name, int age);\n    virtual ~PersonImpl();\n \n    string& getName() const;\n    void setName(string& name);\n    int getAge() const;\n    void setAge(int age);\n \nprivate:\n    string& mName;\n    int mAge;\n};\n```\n\n- `personImpl.cpp`\n\n```cpp\n#include \"personImpl.h\"\n \nPersonImpl::PersonImpl(string& name, int age):mName(name),mAge(age)\n{\n \n}\n \nPersonImpl::~PersonImpl() \n{\n \n}\n \nstring& PersonImpl::getName() const \n{\n    return mName;\n}\n \nvoid PersonImpl::setName(string& name) \n{\n    mName = name;\n}\n \nint PersonImpl::getAge() const \n{\n    return mAge;\n}\n \nvoid PersonImpl::setAge(int age) \n{\n    mAge = age;\n}\n```\n\n\n- `person.h`\n\n```cpp\n#include<string>\nclass PersonImpl;\nusing namespace std;\n \nclass Person \n{\npublic:\n    Person(string& name, int age);\n    virtual ~Person();\n \n    string& getName() const;\n    void setName(string& name);\n    int getAge() const;\n    void setAge(int age);\n \n    PersonImpl * getImp();\n \nprivate:\n    PersonImpl *mPersonImpl;\n};\n```\n\n- `person.cpp`\n\n```cpp\n#include \"person.h\"\n#include \"personImpl.h\"\n \nPerson::Person(string& name, int age):mPersonImpl(new PersonImpl(name, age))\n{\n    std::cout << \"construct Person\" << std::endl;\n}\n \nPerson::~Person() \n{\n    delete mPersonImpl;\n    std::cout << \"deconstruct Person\" << std::endl;\n}\n \nstring& Person::getName() const \n{\n    return mPersonImpl->getName();\n}\n \nvoid Person::setName(string& name) \n{\n    mPersonImpl->setName(name);\n}\n \nint Person::getAge() const \n{\n    return mPersonImpl->getAge();\n}\n \nvoid Person::setAge(int age) \n{\n    mPersonImpl->setAge(age);\n}\n \nPersonImpl* Person:: getImp()\n{\n    return mPersonImpl;\n}\n```\n\n\n- `main.cpp`\n\n```cpp\n#include <stdio.h>\n#include <iostream>\n#include<string>\n#include \"person.h\"\n#include \"personImpl.h\"\n \n \nint main()\n{    \n    string str= \"abcdefg\";\n    Person person(str,30);\n \n    PersonImpl *personImp = person.getImp();\n \n    string name = personImp->getName();\n    int age =personImp->getAge();\n    cout<<name.c_str()<<endl;\n    cout<<age<<endl;\n \n    system(\"pause\");\n    return 0;\n}\n\n\n```\n## 示例2\n\n- `adas_app.h`\n```cpp\nclass AdasApp\n{\npublic:\n    // json字符串\n    AdasApp(const std::string &config);\n    virtual ~AdasApp();\nprivate:\n    class Impl;\n    std::unique_ptr<Impl> impl_/* = nullptr*/;\n};\n```\n\n- `adas_app.cpp`\n```cpp\nclass AdasApp::Impl final\n{\npublic:\n\n    /**\n     * @brief 解析得到前向目标\n     */\n    std::vector<ac::ObstacleInfo> DecodeObjects(const uint8_t *buffer, uint32_t size)\n    {\n        ...具体实现...\n    }\n\n    /**\n     * @brief 解析得到车道线\n     */\n    std::vector<ac::CurveInfo> DecodeCurves(const uint8_t *buffer, uint32_t size)\n    {\n        ...具体实现...\n    }\n\n    Impl(const std::string &config)\n    {\n        ...具体实现...\n        DecodeObjects();\n        DecodeCurves();\n    }\n      ~Impl()\n    {\n        ...具体实现...\n    }\n\n    AdasApp(const std::string &config)\n    : impl_(new Impl(config))\n    {\n\n    }\n\n    ~AdasApp()\n    {\n\n    }\n```\n\n- `main.cpp`\n\n```cpp\nint main()\n{\n   AdasApp obj(ac::LoadTextFile(config)); \n}\n```\n\n这个例子使用了智能指针实现adad的实现类`class Impl;` `std::unique_ptr<Impl> impl_/* = nullptr*/;`在adas_app.h中看不到真正的实现，但实际声明了一个智能指针`impl_`，在adas_app.cpp中将该指针指针指向了一个new对象`impl_(new Impl(config)`，并将其new对象的构造函数`Impl{}`进行了真正的实现。\n\n---\n\n> 版权声明：本文为CSDN博主「netyeaxi」的原创文章，遵循CC4.0BY-SA版权协议，转载请附上原文出处链接及本声明。\n> 原文链接：https://blog.csdn.net/netyeaxi/article/details/80887646\n> 原文链接：https://blog.csdn.net/netyeaxi/article/details/80724557\n> 原文链接：https://blog.csdn.net/qq_20853741/article/details/121244189","tags":["C++","接口定义"],"categories":["C++"]},{"title":"安卓OpenGL渲染画面闪烁原因分析","slug":"安卓OpenGL渲染画面闪烁原因分析","url":"/2023/03/16/an-zhuo-opengl-xuan-ran-hua-mian-shan-shuo-yuan-yin-fen-xi/","content":"1.硬件接触不良  \n2.opengl双缓存未开启  \n3.opengl双缓存开启但离屏数据为更新  \n4.相机数据被覆盖  \n4.1相机数据格式不对  \n4.2申请内存与访问内存越界问题","tags":["android","opengl","画面闪烁"],"categories":["待整理android"]},{"title":"git使用指南","slug":"git使用指南","url":"/2023/02/28/git-shi-yong-zhi-nan/","content":"# 常用命令\n## `git config` 设置用户名称和邮件地址  \n- 设置用户名称\n```bash\ngit config --global user.name \"goto456\"\n```\n- 设置邮件地址\n```bash\ngit config --global user.email \"goto456@126.com\" \n```\n- 列出当前Git所有的配置信息\n```bash\ngit config --list \n```\n## `git init` 初始化本地仓库\n获取一个 Git 仓库有两种方法：  \n1.本地初始化一个仓库  \n2.从远程克隆一个仓库到本地  \n对于第1种方式，如果想对本地现有的一个项目用 Git 来管理，可以直接进入该项目的目录下执行如下命令，就可以将其初始化成一个 Git 仓库了。  \n```bash\ngit init\n```\n## `git clone` 克隆远程仓库到本地\n- 通过ssh方式克隆\n```bash\ngit clone git@github.com:goto456/leetcode.git\n```\n- 通过https方式克隆\n```bash\ngit clone https://github.com/goto456/leetcode.git \n```\n> https方式：不管是谁，只要拿到该项目的 url 可以随便 clone，但是在 push 到远程的时候需要验证用户名和密码；  \n> ssh方式：需要现将你电脑的SSH key（SSH公钥）添加到GitHub（或者其他代码托管网站）上，这样在 clone 项目和 push 项目到远程时都不需要输入用户名和密码。\n\n# 参考文档\n\n[参考文档](https://github.com/geiyiren/MyBlogFile1/blob/pdf/git%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8D%97/git%E6%95%99%E7%A8%8B.pdf)","tags":["git","gitlab"],"categories":["git"]},{"title":"C++的lambda表达式使用方法","slug":"C++的lambda表达式使用方法","url":"/2023/02/14/c-de-lambda-biao-da-shi-shi-yong-fang-fa/","tags":["C++","函数参数传递","lambda表达式"],"categories":["C++"]},{"title":"自定义鱼眼图像去畸变","slug":"自定义鱼眼图像去畸变","url":"/2023/02/14/zi-ding-yi-yu-yan-tu-xiang-qu-ji-bian/","content":"\n# 畸变图像$\\rightarrowtail$ 去畸变图像\n```cpp\nvoid cv::fisheye::undistortImage(\n    InputArray distorted,            // 输入的畸变图像\n    OutputArray undistorted,         // 输出的去畸变图像\n    InputArray K,                    // 相机内参矩阵(3x3)\n    InputArray D,                    // 相机畸变系数\n    InputArray Knew = cv::noArray(), // 新的相机内参矩阵(3x3)\n    const Size& new_size = Size()    // 新的去畸变图像尺寸\n);\n\n```\n- `new_size`一般设置为空，默认输出去畸变图像和畸变图像的尺寸相同。\n- `Knew `为新的相机内参矩阵，影响者去畸变之后图像的范围，参数有：`fx`、`fy`、`cx`、`cy`。\n    + `fx`为水平方向的焦距，值越大，水平方向显示图像范围越大。\n    + `fy`为垂直方向的焦距，值越大，垂直方向显示图像范围越大。\n    + `cx`主点坐标的x值，值越大，显示图像范围整体越偏左\n    + `cy`主点坐标的y值，值越大，显示图像范围整体越偏下\n> `cx`、`cy`一般和原应相机的参数一样，这样去畸变后的图像和畸变图像的中心可以对齐；`fx`、`fy`需要根据去畸变图像的视野需求进行调整，一般在原相机的参数的基础上进行缩放。\n- 效果展示\n![原始畸变图像](https://cdn.jsdelivr.net/gh/geiyiren/MyBlogImage1/自定义鱼眼图像去畸变/0.0-0.0.png)\n<style>\n  th, td {\n    text-align: center; /* 设置表头和单元格中的文本居中 */\n  }\n</style>\n<table>\n<colgroup>\n    <col style=\"width: 20%;\">\n    <col style=\"width: 20%;\">\n    <col style=\"width: 60%;\">\n</colgroup>\n<tr>\n    <th>fx缩小倍数</th>\n    <th>fy缩小倍数</th>\n    <th>去畸变图像</th>\n</tr>\n<tr>\n    <td>1.0</td>\n    <td>1.0</td>\n    <td><img src=\"https://cdn.jsdelivr.net/gh/geiyiren/MyBlogImage1/自定义鱼眼图像去畸变/1.0-1.0.png\"\"></td>\n</tr>\n<tr>\n    <td>1.3</td>\n    <td>1.0</td>\n    <td><img src=\"https://cdn.jsdelivr.net/gh/geiyiren/MyBlogImage1/自定义鱼眼图像去畸变/1.3-1.0.png\"\"></td>\n</tr>\n<tr>\n    <td>1.5</td>\n    <td>1.0</td>\n    <td><img src=\"https://cdn.jsdelivr.net/gh/geiyiren/MyBlogImage1/自定义鱼眼图像去畸变/1.5-1.0.png\"\"></td>\n</tr>\n<tr>\n    <td>3.0</td>\n    <td>1.0</td>\n    <td><img src=\"https://cdn.jsdelivr.net/gh/geiyiren/MyBlogImage1/自定义鱼眼图像去畸变/3.0-1.0.png\"\"></td>\n</tr>\n<tr>\n    <td>5.0</td>\n    <td>1.0</td>\n    <td><img src=\"https://cdn.jsdelivr.net/gh/geiyiren/MyBlogImage1/自定义鱼眼图像去畸变/5.0-1.0.png\"\"></td>\n</tr>\n<tr>\n    <td>5.0</td>\n    <td>1.5</td>\n    <td><img src=\"https://cdn.jsdelivr.net/gh/geiyiren/MyBlogImage1/自定义鱼眼图像去畸变/5.0-1.5.png\"\"></td>\n</tr>\n<tr>\n    <td>5.0</td>\n    <td>3.0</td>\n    <td><img src=\"https://cdn.jsdelivr.net/gh/geiyiren/MyBlogImage1/自定义鱼眼图像去畸变/5.0-3.0.png\"\"></td>\n</tr>\n</table>\n\n# 畸变点$\\rightarrowtail$ 去畸变点\n```cpp\nvoid cv::fisheye::undistortPoints(\n    InputArray distorted,          // 输入的畸变坐标点\n    OutputArray undistorted,      // 输出的去畸变坐标点\n    InputArray K,                  // 相机内参矩阵(3x3)\n    InputArray D,                  // 畸变参数向量\n    InputArray R = cv::noArray(),  // 旋转矩阵(3x3)，通常是单位矩阵\n    InputArray P = cv::noArray()   // 投影矩阵(3x3)或新相机内参矩阵Knew(3x3)\n);\n\n```\n> 这个函数可以直接向畸变图像上的点转换为去畸变图像上的点，也可以利用`R`,`P`矩阵将畸变图像上的点转换为世界坐标系中。\n\n**注意**：这里转换为去畸变图像上的点时，不支持图像缩放，仅支持新的内参矩阵，因此图像在去畸变时，一般不改变图像的大小，保证点去畸变时可以与之对应。\n\n# 去畸变点$\\rightarrowtail$ 畸变点\n没有直接的函数将畸变点转换为去畸变点，但是可以利用map映射函数获得映射点来进行转换。\n```cpp\nvoid cv::fisheye::initUndistortRectifyMap(\n    InputArray K,              // 相机内参矩阵 (3x3)\n    InputArray D,              // 畸变参数向量\n    InputArray R,              // 旋转矩阵 (3x3)\n    InputArray P,              // 新相机矩阵 (3x3)\n    const Size& size,          // 输出映射的图像尺寸\n    int m1type,                // 映射矩阵的数据类型 (例如：CV_32FC1)\n    OutputArray map1,          // 输出的第一个映射\n    OutputArray map2           // 输出的第二个映射\n);\n\n```\n这里`map1`、`map2`为映射矩阵，类型为`cv::Mat`,尺寸为`size`，也就是说这个`Mat`的尺寸就是去畸变图像的尺寸，每个位置存储的值为对应畸变图像上点的`x`值或者`y`值。这样我们就可以访问这个`Mat`中每个像素值，进而得到去畸变点对应的畸变点坐标。\n> 众所周知，map映射时存储的映射关系一般为相反的\n\n- 使用方法\n```cpp\n// 初始化映射表\ncv::Mat map_x, map_y;\nstd::vector<cv::Point2f> image_points_dist, image_points_undist_new;\ncv::fisheye::initUndistortRectifyMap(cam_K[cam_index], cam_D[cam_index], cv::Mat::eye(3, 3, CV_32FC1), cam_K_new[cam_index], cv::Size(CAMERA_WIDTH, CAMERA_HEIGHT), CV_32FC1, map_x, map_y);\n\nfor (auto point : image_points_undist)\n{\n    cv::Point2f point_undist = cv::Point2f(point.x,\n                                           point.y);\n    image_points_dist.emplace_back(cv::Point2f(map_x.at<float>(point_undist), map_y.at<float>(point_undist)));\n}\n```\n\n**注意**: 这里的输出映射的图像尺寸需要为畸变图像的原始尺寸`cv::Size(CAMERA_WIDTH, CAMERA_HEIGHT)`,旋转矩阵应该为单位矩阵，新相机矩阵与去畸变时的设置保持一直即可。\n\n# 代码: `undist.cpp`\n\n```cpp\n#include <opencv2/opencv.hpp>\n#include <opencv2/highgui/highgui.hpp>\n#include <opencv2/imgproc/imgproc.hpp>\n\n\n#define UNDIST_SCALE (2.5)\n\n/**\n * @description: 输入畸变图，输出去畸变图\n * @param {Mat} &img_dist\n * @param {Mat} &img_undist\n * @return {*}\n * @author: wangshuaiyang\n */\nint DistToUndistImage(cv::Mat img_dist, cv::Mat &img_undist)\n{\n    int ret = 0;\n\n    cv::Mat cam_K = (cv::Mat_<float>(3, 3) << 319.307046915, 0, 640,\n                0, 319.715597621, 360,\n                0, 0, 1);\n    cv::Mat cam_D = (cv::Mat_<float>(4, 1) << 0.07218855, 0.02228145, -0.015075182, 0.002351672);\n\n    // 新的相机内参矩阵和图像尺寸（可选）\n    cv::Mat cam_K_new = cam_K.clone();\n    cam_K_new.at<float>(0, 0) = cam_K_new.at<float>(0, 0)/5.0;     // fx\n    cam_K_new.at<float>(1, 1) = cam_K_new.at<float>(1, 1)/1.5;     // fy\n    cam_K_new.at<float>(0, 2) = cam_K_new.at<float>(0, 2); // cx\n    cam_K_new.at<float>(1, 2) = cam_K_new.at<float>(1, 2); // cy\n\n    cv::fisheye::undistortImage(img_dist, img_undist, cam_K, cam_D, cam_K_new);\n\n    cv::resize(img_undist, img_undist, img_dist.size());\n\n    cv::imshow(\"image_remap_fish\", img_undist);\n    cv::waitKey(0);\n\n    return ret;\n}\nint  main()\n{\n    cv::Mat img = cv::imread(\"picture_back.png\", cv::IMREAD_COLOR);\n    cv::Mat undist_img;\n    int ret = DistToUndistImage(img, undist_img);\n    return 0;\n}\n```\n\n- 编译\n- \n```bash\ng++ undist.cpp -o undist -lopencv_core -lopencv_highgui -lopencv_imgproc -lopencv_imgcodecs -lopencv_calib3d\n```","tags":["opencv","c++"],"categories":["opencv"]},{"title":"编码规范","slug":"编码规范","url":"/2023/02/14/bian-ma-gui-fan/","content":"# C++编码规范\n\n// 文件: 单词小写, 单词之间使用下划线\n\n```cpp\n#include \"a.h\"\n\n// 命名空间: 小写字母\nnamespace mynamespace {\n\t// 常量: k开头, 每个单词首字母大写\n\tconst int kDaysInAWeek = 7;\n\n\t// 类型定义\n\ttypedef hash_map<TUrlTableProperties *, string> TPropertiesMap;\n\tusing PropertiesMap = hash_map<TUrlTableProperties *, string>;\n\n\t// 全局变量、局部变量: 单词小写, 单词之间使用下划线\n\tint my_name;\n\n\t// 类: T开头, 每个单词首字母大写\n\tclass TMyClass {\n\tpublic:\n\t\t// 结构体: T开头, 每个单词首字母大写\n\t\tstruct TMyStruct {\n\t\t\t// 普通变量: 单词小写, 单词之间使用下划线\n\t\t\tint my_name;\n\t\t};\n\n\t\t// 函数: 每个单词首字母大写, 函数名首字母大写\n\t\tMyExcitingFunction();\n\tprivate:\n\t\t// 类成员变量: 单词小写, 单词之间使用下划线, 最后以下划线结束\n\t\tint my_name_;\n\n\t};\n}\n```\n\n## 变量\n\n\n[C++编码规范](https://github.com/geiyiren/MyBlogFile1/blob/pdf/%E7%BC%96%E7%A0%81%E8%A7%84%E8%8C%83/C%2B%2B%E7%BC%96%E7%A0%81%E8%A7%84%E8%8C%83.pdf)\n\n\n> C++编码规范.pdf的升级版本\n\n[C++编码规范.pdf的升级版本](https://github.com/geiyiren/MyBlogFile1/blob/pdf/%E7%BC%96%E7%A0%81%E8%A7%84%E8%8C%83/C%2B%2B%E7%BC%96%E7%A0%81%E8%A7%84%E8%8C%83C1.pdf)\n\n# C编码规范\n\n[C编码规范](https://github.com/geiyiren/MyBlogFile1/blob/pdf/%E7%BC%96%E7%A0%81%E8%A7%84%E8%8C%83/%E5%B5%8C%E5%85%A5%E5%BC%8FC%E7%BC%96%E7%A0%81%E8%A7%84%E8%8C%83.pdf)\n\n# c\n\n[C#编码规范](https://github.com/geiyiren/MyBlogFile1/blob/pdf/%E7%BC%96%E7%A0%81%E8%A7%84%E8%8C%83/Java%E7%BC%96%E7%A0%81%E8%A7%84%E8%8C%83.pdf)\n\n# C#编码规范\n\n[C#编码规范](https://github.com/geiyiren/MyBlogFile1/blob/pdf/%E7%BC%96%E7%A0%81%E8%A7%84%E8%8C%83/C%E4%BA%95%E7%BC%96%E7%A0%81%E8%A7%84%E8%8C%83C1.pdf)\n\n# google编程风格指南\n\n[google编程风格指南](https://github.com/geiyiren/MyBlogFile1/blob/pdf/%E7%BC%96%E7%A0%81%E8%A7%84%E8%8C%83/google%E7%BC%96%E7%A8%8B%E9%A3%8E%E6%A0%BC%E6%8C%87%E5%8D%97.pdf)\n\n# 移动机器人开发代码规范说明书\n\n[移动机器人开发代码规范说明书](https://github.com/geiyiren/MyBlogFile1/blob/pdf/%E7%BC%96%E7%A0%81%E8%A7%84%E8%8C%83/%E7%A7%BB%E5%8A%A8%E6%9C%BA%E5%99%A8%E4%BA%BA%E5%BC%80%E5%8F%91%E4%BB%A3%E7%A0%81%E8%A7%84%E8%8C%83%E8%AF%B4%E6%98%8E%E4%B9%A6.pdf)","tags":["C++","java","C","C#"],"categories":["编码规范"]},{"title":"Activity和SurfaceView的生命周期","slug":"Activity和SurfaceView的生命周期","url":"/2023/02/10/activity-he-surfaceview-de-sheng-ming-zhou-qi/","content":"当用户浏览、退出和返回到您的应用时，您应用中的 Activity 实例会在其生命周期的不同状态间转换。Activity 类会提供许多回调，这些回调会让 Activity 知晓某个状态已经更改：系统正在创建、停止或恢复某个 Activity，或者正在销毁该 Activity 所在的进程。\n\n在生命周期回调方法中，您可以声明用户离开和再次进入 Activity 时 Activity 的行为方式。例如，如果您正构建流媒体视频播放器，当用户切换至另一应用时，您可能要暂停视频或终止网络连接。当用户返回时，您可以重新连接网络并允许用户从同一位置继续播放视频。换言之，每个回调都支持您执行适合给定状态变更的特定作业。在合适的时间执行正确的作业，并妥善处理转换，这将提升应用的稳健性和性能。例如，良好的生命周期回调实现有助于防止应用出现以下问题：\n- 当用户在使用应用时接听来电，或切换至另一应用时崩溃。\n- 当用户未主动使用它时，消耗宝贵的系统资源。\n- 当用户离开应用并在稍后返回时，丢失用户的进度。\n- 当屏幕在横向和纵向之间旋转时，崩溃或丢失用户的进度。\n\n# Activity 生命周期概念\n为了在 Activity 生命周期的各个阶段之间导航转换，Activity 类提供六个核心回调：onCreate()、onStart()、onResume()、onPause()、onStop() 和 onDestroy()。当 Activity 进入新状态时，系统会调用其中每个回调。\n\n下图是对此范例的直观展现。\n\n![](https://cdn.jsdelivr.net/gh/geiyiren/MyBlogImage1/Activity和SurfaceView的生命周期/activity_surfaceView.png)  \n\n当用户开始离开 Activity 时，系统会调用方法来销毁该 Activity。在某些情况下，此销毁只是部分销毁；Activity 仍然驻留在内存中（例如当用户切换至另一应用时），并且仍然可以返回到前台。如果用户返回到该 Activity，Activity 会从用户离开时的位置继续运行。除了少数例外，应用在后台运行时会受到限制，无法启动 Activity。\n\n系统终止给定进程及其中 Activity 的可能性取决于当时 Activity 的状态。Activity 状态和从内存中弹出 会更详细地介绍状态与弹出漏洞之间的关系。\n\n根据 Activity 的复杂程度，您可能不需要实现所有生命周期方法。但是，请务必了解每个方法，并实现能够确保应用按用户预期方式运行的方法，这非常重要。\n\n> 具体细节参考：https://developer.android.google.cn/guide/components/activities/activity-lifecycle?hl=zh-cn#java\n\n# Activity和SurfaceView的生命周期\n- 程序打开  \nActivity 调用顺序:`onCreate()`->`onStart()`->`onResume()`  \nSurfaceView 调用顺序: `surfaceCreated()`->`surfaceChanged()`  \n\n- 程序关闭（按 BACK 键）  \nActivity 调用顺序:`onPause()`->`onStop()`->`onDestory()`  \nSurfaceView 调用顺序: `surfaceDestroyed()`  \n\n- 程序切到后台（按 HOME 键）  \nActivity 调用顺序:`onPause()`->`onStop()`  \nSurfaceView 调用顺序: `surfaceDestroyed()`  \n\n- 程序切到前台  \nActivity 调用顺序: `onRestart()`->`onStart()`->`onResume()`  \nSurfaceView 调用顺序: `surfaceChanged()`->`surfaceCreated()`  \n\n- 屏幕锁定（挂断键或锁定屏幕）  \nActivity 调用顺序: `onPause()`    \nSurfaceView 什么方法都不调用  \n\n- 屏幕解锁   \nActivity 调用顺序:`onResume()`  \nSurfaceView 什么方法都不调用  \n\n> 总结SurfaceView在页面可见或者不可见时触发  \n\n示例图如下所示:  \n\n![](https://cdn.jsdelivr.net/gh/geiyiren/MyBlogImage1/Activity和SurfaceView的生命周期/activity_lifecycle.png)","tags":["android","activity","surfaceView"],"categories":["android"]},{"title":"ubuntu安装opencv与opencv_contrib","slug":"ubuntu安装opencv与opencv_contrib","url":"/2023/01/31/ubuntu-an-zhuang-opencv-yu-opencv-contrib/","content":"# 安装\n## 依赖包安装\n```bash\nsudo apt-get install build-essential  \n```\n```bash\nsudo apt-get install cmake git libgtk2.0-dev pkg-config libavcodec-dev libavformat-dev libswscale-dev  \n```\n```bash\nsudo apt-get install python-dev python-numpy libtbb2 libtbb-dev libjpeg-dev libpng-dev libtiff-dev libjasper-dev libdc1394-22-dev  \n```\n```bash\nsudo apt-get install build-essential qt5-default ccache libv4l-dev libavresample-dev  libgphoto2-dev libopenblas-base libopenblas-dev doxygen  openjdk-8-jdk pylint libvtk6-dev\n```\n```bash\nsudo apt-get install pkg-config\n```\n\n## 下载源文件\n[opencv](https://github.com/opencv/opencv)  \n[opencv_contrib](https://github.com/opencv/opencv_contrib)\n\n## 解压\n```bash\nunzip opencv-x.x.x.zip\n```\n```bash\nunzip opencv_contrib-x.x.x.zip\n```\n\n## 将opencv_contrib移动到opencv目录下，同时在该目录下新建一个文件夹build\n```bash\ncp -r opencv_contrib-x.x.x opencv-x.x.x  \n```\n```bash\ncd opencv-x.x.x\nmkdir build                             \n```\n\n## 现在进入到opencv-x.x.x目录下，查看文件结构\n```bash\nls\n```\n\n```bash\n3rdparty\ncmake\ndata\nLICENSE\nplatforms\napps\nCMakeLists.txt\ndoc\nmodules\nREADME.md\nbuild\nCONTRIBUTING.md\ninclude\npencv_contrib-x.x.x\nsamples\n```\n## 进入build目录，并且执行cmake生成makefile文件\n```bash\ncd build  \n```\n```bash\ncmake -D CMAKE_BUILD_TYPE=Release -D CMAKE_INSTALL_PREFIX=/usr/local -D OPENCV_EXTRA_MODULES_PATH=/home/files/opencv-x.x.x/opencv_contrib-x.x.x/modules/ .. \n```\n> 注意：OPENCV_EXTRA_MODULES_PATH就是你 opencv_contrib-3.3.1下面的modules目录，请按照自己的实际目录修改地址。\n接下来就是漫长的等待了...   \n生成完毕提示：\n```bash\n--   Install path:                  /usr/local\n-- \n--   cvconfig.h is in:              /home/files/opencv-x.x.x/build\n-- -----------------------------------------------------------------\n-- \n-- Configuring done\n-- Generating done\n-- Build files have been written to: /home/files/opencv-x.x.x/build\n```\n## 在cmake成功之后，就可以在build文件下make了\n```bash\nmake -j8\n```\n```bash\nsudo make install\n```\n接下来就是更漫长的等待 ... 具体时间因人而异\n## 链接库共享\n编译安装完毕之后，为了让你的链接库被系统共享，让编译器发现，需要执行管理命令ldconfig：\n```bash\nsudo ldconfig -v  \n```\n# bug解决\n## 解决编译opencv时，卡在IPPICV\n### 手动下载缺少文件\n[ippicv_2020_lnx_intel64_20191018_general.tgz](https://github.com/geiyiren/MyBlog/blob/main/source/_posts/ubuntu%E5%AE%89%E8%A3%85opencv%E4%B8%8Eopencv_contrib/.cache/ippicv/7421de0095c7a39162ae13a6098782f9-ippicv_2020_lnx_intel64_20191018_general.tgz)\n### 修改配置文件\n```bash\nsudo gedit opencv-x.x.x/3rdparty/ippicv.cmake\n```\n找到`\"https://raw.githubusercontent.com/opencv/opencv_3rdparty/${IPPICV_COMMIT}/ippicv/\"`\n\n将其改为ippicv_2020_lnx_intel64_20191018_general.tgz保存的目录。比如：`\"file:///home/downloads/\"`,格式为`\"file://路径\"`\n最后重新执行编译命令即可：\n```bash\nmake -j8\n```\n\n## 终极方法：解决编译opencv时，卡在IPPICV、boostdesc、vgg等文件下载问题\n卡在这里的原因是因为在cmake编译的时候没有下载成功，这里使用手动下载与替换进行补救\n## 手动下载缺少文件\n[百度网盘:ubuntu安装opencv与opencv_contrib](https://pan.baidu.com/s/1OrfTdsNczKlNvJPg_gD0VA?pwd=1633)\n## 替换本地文件\n在`opencv源文件目录`下找到隐藏文件夹`.cache`，然后分别替换其中的文件。注意下载的文件中每个对应文件的开头字符串为临时校验码，需要以自己本次安装时生成的校验码为准。例如`7421de0095c7a39162ae13a6098782f9-ippicv_2020_lnx_intel64_20191018_general.tgz`中`7421de0095c7a39162ae13a6098782f9`为安装校验码，这个在替换文件时候需要改为本次安装自动生成的校验码。\n## .cache文件目录\n```bash\n.cache\n├── data\n│   └── 7505c44ca4eb54b4ab1e4777cb96ac05-face_landmark_model.dat\n├── ippicv\n│   └── 7421de0095c7a39162ae13a6098782f9-ippicv_2020_lnx_intel64_20191018_general.tgz\n└── xfeatures2d\n    ├── boostdesc\n    │   ├── 0ae0675534aa318d9668f2a179c2a052-boostdesc_lbgm.i\n    │   ├── 0ea90e7a8f3f7876d450e4149c97c74f-boostdesc_bgm.i\n    │   ├── 202e1b3e9fec871b04da31f7f016679f-boostdesc_binboost_064.i\n    │   ├── 232c966b13651bd0e46a1497b0852191-boostdesc_bgm_bi.i\n    │   ├── 324426a24fa56ad9c5b8e3e0b3e5303e-boostdesc_bgm_hd.i\n    │   ├── 98ea99d399965c03d555cef3ea502a0b-boostdesc_binboost_128.i\n    │   └── e6dcfa9f647779eb1ce446a8d759b6ea-boostdesc_binboost_256.i\n    └── vgg\n        ├── 151805e03568c9f490a5e3a872777b75-vgg_generated_120.i\n        ├── 7126a5d9a8884ebca5aea5d63d677225-vgg_generated_64.i\n        ├── 7cd47228edec52b6d82f46511af325c5-vgg_generated_80.i\n        └── e8d0dcd54d1bcfdc29203d011a797179-vgg_generated_48.i\n\n```\n# 参考链接\n[一次性解决opencv源码安装文件下载问题：ippicv_2017u3_lnx, face_landmark_model.dat, tiny-dnn](https://blog.csdn.net/qq_39936818/article/details/104951448)\n[ubuntu安装opencv问题解决——缺少boostdesc_bgm.i文件](https://blog.csdn.net/weixin_45846977/article/details/112396739)\n","tags":["ubuntu","opencv","opencv_contrib"],"categories":["待整理opencv"]},{"title":"写博客常用模板","slug":"写博客常用模板","url":"/2023/01/31/xie-bo-ke-chang-yong-mo-ban/","content":"\n# 插入思维导图\n\n基于百度脑图的开源库 kityminder 很不错，实现了markdown文档中使用思维导图的方法。使用 Hexo 的 pullquote 将思维导图的内容包裹起来，mindmap 是思维导图渲染的标志，尺寸有三种规格：mindmap-sm、mindmap-md 和 mindmap-lg。  \n思维导图的内容和层级关系通过无序列表表示，支持基本的文字和超链接。举个例子，撰写文章时在需要的位置添加如下内容:  \n```markdown\n{% pullquote mindmap mindmap-md %}\n- [在 Hexo 中使用思维导图](https://hunterx.xyz/use-mindmap-in-hexo.html)\n  - 前言\n  - 操作指南\n    - 准备需要的文件\n    - 为主题添加 CSS/JS 文件\n  - 使用方法\n{% endpullquote %}\n```\n效果如下：  \n{% pullquote mindmap mindmap-md %}\n- [在 Hexo 中使用思维导图](https://hunterx.xyz/use-mindmap-in-hexo.html)\n  - 前言\n  - 操作指南\n    - 准备需要的文件\n    - 为主题添加 CSS/JS 文件\n  - 使用方法\n{% endpullquote %}\n\n# 插入图像\n\n```markdown\n![](https://cdn.jsdelivr.net/gh/用户名/仓库名称/仓库下的图像路径)\n```\n- 例如：\n\n```markdown\n![](https://cdn.jsdelivr.net/gh/geiyiren/MyBlogImage1/车辆动态辅助轨迹线生成方法8.png)  \n```\n\n# 插入pdf\n\n```markdown\n<object data=\"仓库路径\"\n type=\"application/pdf\" width=\"100%\" height=\"100%\" >\n<iframe src=\"仓库下pdf路径\" width=\"100%\" height=\"1000px\" frameborder=\"0\" scrolling=\"no\"></iframe>\n</object>\n```\n\n- 例如：\n\n```markdown\n<object data=\"https://github.com/geiyiren/MyBlogFile1/blob/pdf/git%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8D%97/\"\n type=\"application/pdf\" width=\"100%\" height=\"100%\" >\n<iframe src=\"git%E6%95%99%E7%A8%8B.pdf\" width=\"100%\" height=\"1000px\" frameborder=\"0\" scrolling=\"no\"></iframe>\n</object>\n```\n\n上述方法适用用私人github仓库中的pdf文件；如果插入其他链接直达的pdf文档，可以使用：\n\n```markdown\n{% pdf PDF直达链接 %}\n```","tags":["思维导图"],"categories":["模板"]},{"title":"malloc申请内存访问时容易出现的访问越界问题","slug":"malloc申请内存访问时容易出现的访问越界问题","url":"/2022/12/15/malloc-shen-qing-nei-cun-fang-wen-shi-rong-yi-chu-xian-de-fang-wen-yue-jie-wen-ti/","content":"# malloc相关\n## malloc申请内存访问bug\n- 在访问malloc申请的内存时，如果访问越界时不会提示错误，而是继续操作错误的内存块，这一类的错误较为隐秘。\n- 例如：在构建图像变换的map映射表时，申请存放map映射关系的内存块的大小并不是输出图像对应的大小，而是输出图像大小的2倍，因此此时存储的是像素位置(x,y)的映射关系。  \n```cpp\n//构建4路YUV鱼眼图像去畸变映射关系\nvoid dist2undist()\n{\n    float point_u_tmp[2], point_d_tmp[2];\n    float sf = 1.5;\n    int img_out_height = 720 * img_out_h_scale;\n    int img_out_width = 1280 * img_out_w_scale;\n    LOGI(1, \"dist2undist begin !,img_out size(%d,%d)\", img_out_height, img_out_width);\n\n    for (int index = 0; index < NUM_CAMERAS; index++)\n    {\n        // 这里就是bug所在\n        undist_map[index] = (float *)malloc(undistView_width * undistView_height * 3 / 2 * 2 * sizeof(float));\n\n        if (undist_map[index] == NULL)\n        {\n            LOGI(1, \"undist_map malloc failed!\");\n        }\n        for (int i = 0; i < img_out_height; i += 1)\n        {\n            for (int j = 0; j < img_out_width; j += 1)\n            {\n                point_u_tmp[0] = j / img_out_w_scale;\n                point_u_tmp[1] = i / img_out_h_scale;\n                LDC_UndistToDistExt(&ldc[0], point_u_tmp, point_d_tmp, sf);\n\n                undist_map[index][(i * img_out_width + j) * 2] = point_d_tmp[0] * img_in_w_scale;\n                undist_map[index][(i * img_out_width + j) * 2 + 1] = point_d_tmp[1] * img_in_h_scale;\n                if (!int(j % 2))\n                {\n                    undist_map[index][(i / 2 * img_out_width + j + img_out_width * img_out_height) * 2] = int(point_d_tmp[0] * img_in_w_scale / 2) * 2;\n                    undist_map[index][(i / 2 * img_out_width + j + img_out_width * img_out_height) * 2 + 1] = int(point_d_tmp[1] * img_in_h_scale / 2) + 720 * img_in_h_scale;\n                    undist_map[index][(i / 2 * img_out_width + j + img_out_width * img_out_height + 1) * 2] = int(point_d_tmp[0] * img_in_w_scale / 2) * 2 + 1;\n                    undist_map[index][(i / 2 * img_out_width + j + img_out_width * img_out_height + 1) * 2 + 1] = int(point_d_tmp[1] * img_in_h_scale / 2) + 720 * img_in_h_scale;\n                }\n            }\n        }\n    }\n}\n```\n如果 #18 行中申请内存为:\n```cpp\nundist_map[index] = (float *)malloc(undistView_width * undistView_height * 3 / 2 * sizeof(float));\n```\n那么，后面构建map映射关系时并不会出现越界访问提示，甚至后面如果不再申请内存块的情况下，继续越界访问undist_map中的内容也不会报错；但是，如果后面继续申请内存块来使用的时候，后续的内存块可能就会和undist_map内存冲突。  \n***\n<font color=Red>**总结**</font>  \n使用malloc申请内存并访问时，注意访问是否越界，且访问越界不报错。\n","tags":["C++","malloc","内存访问"],"categories":["C++","linux"]},{"title":"android弹窗界面设置方法","slug":"android弹窗界面设置方法","url":"/2022/12/14/android-dan-chuang-jie-mian-she-zhi-fang-fa/","content":"# 功能描述\n点击主界面的一个按钮，然后跳转另一个设置界面，进行参数设置，包括：参数输入、开关按钮、保存、退出等功能。界面的布局采用表格布局，平均分布各个行列。示例代码如下所示。\n# MainActivity.java示例\n```java\n// 主界面按钮定义\nprivate ImageButton mImage_set_btn;\n\n@Override\nprotected void onCreate(Bundle savedInstanceState) {\n\tsuper.onCreate(savedInstanceState);\n\n\t// 主界面按钮事件\n\t// R.id.image_set_btn为主界面按钮ID\n\tmImage_set_btn = (ImageButton) findViewById(R.id.image_set_btn);\n\tmImage_set_btn.setOnClickListener(new View.OnClickListener() {\n\t@Override\n\tpublic void onClick(View view) {\n\t\tfinal LayoutInflater layoutInflater = (LayoutInflater)getBaseContext().getSystemService(LAYOUT_INFLATER_SERVICE);\n\t\t//R.id.avm_parm_view为跳转界面ID（android:id=\"@+id/avm_parm_view\"）\n\t\tView popupView = layoutInflater.inflate(R.layout.layout_avm_parm, (ViewGroup)findViewById(R.id.avm_parm_view));\n\t\tmPopupWindow_register = new PopupWindow(popupView, WindowManager.LayoutParams.MATCH_PARENT, WindowManager.LayoutParams.MATCH_PARENT, true);\n\t\tmPopupWindow_register.setTouchable(true);\n\t\tmPopupWindow_register.setOutsideTouchable(true);\n\t\tmPopupWindow_register.setBackgroundDrawable(new BitmapDrawable(getResources(), (Bitmap) null));\n\t\tmPopupWindow_register.showAsDropDown(view);\n\n\t\t//------ 获取输入控件的输入内容 ------\n\t\t//车长\n\t\teditText_car_length = (EditText) mPopupWindow_register.getContentView().findViewById(R.id.EditText_car_length);\n\t\t//车宽\n\t\teditText_car_width = (EditText) mPopupWindow_register.getContentView().findViewById(R.id.EditText_car_width);\n\t\t//前悬\n\t\teditText_suspension_front = (EditText) mPopupWindow_register.getContentView().findViewById(R.id.EditText_suspension_front);\n\t\t//后悬\n\t\teditText_suspension_back = (EditText) mPopupWindow_register.getContentView().findViewById(R.id.EditText_suspension_back);\n\t\t//保存按钮\n\t\tdelok_btn = popupView.findViewById(R.id.avm_parameter_save);\n\t\t//返回按钮\n\t\tdelcancel_btn = popupView.findViewById(R.id.avm_parameter_return);\n\t\t//车道线开关\n\t\tmTrajectory_Switch=popupView.findViewById(R.id.TrajectoryLine_Switch);\n\t\t//BSD开关\n\t\tmBSD_Switch=popupView.findViewById(R.id.BSD_Switch);\n\t\t//亮度均衡开关\n\t\tmBE_Switch=popupView.findViewById(R.id.BE_Switch);\n\t\t// 获取默认开关参数\n\t\tcarParameter carParm_history = new carParameter();\n\t\ttry {\n\t\t\tcarParm_history=avmSetParm.readJson();\n\t\t} catch (Exception e) {\n\t\t\te.printStackTrace();\n\t\t}\n\t\t//------ 设置输入控件的显示历史数据 ------\n\t\teditText_car_length.setText(String.valueOf(carParm_history.car_length));\n\t\teditText_car_width.setText(String.valueOf(carParm_history.car_width));\n\t\teditText_suspension_front.setText(String.valueOf(carParm_history.suspension_front));\n\t\teditText_suspension_back.setText(String.valueOf(carParm_history.suspension_back));\n\t\tswitch (carParm_history.on_TrajectoryLine){\n\t\t\tcase 0:\n\t\t\t\tmTrajectory_Switch.setChecked(false);\n\t\t\t\tbreak;\n\t\t\tcase 1:\n\t\t\t\tmTrajectory_Switch.setChecked(true);\n\t\t\t\tbreak;\n\t\t}\n\t\tswitch (carParm_history.on_BSD){\n\t\t\tcase 0:\n\t\t\t\tmBSD_Switch.setChecked(false);\n\t\t\t\tbreak;\n\t\t\tcase 1:\n\t\t\t\tmBSD_Switch.setChecked(true);\n\t\t\t\tbreak;\n\t\t}\n\t\tswitch (carParm_history.on_Bright){\n\t\t\tcase 0:\n\t\t\t\tmBE_Switch.setChecked(false);\n\t\t\t\tbreak;\n\t\t\tcase 1:\n\t\t\t\tmBE_Switch.setChecked(true);\n\t\t\t\tbreak;\n\t\t}\n\n\t\t//------ 设置保存按钮触发事件 ------\n\t\tdelok_btn.setOnClickListener(new View.OnClickListener() {\n\t\t\tpublic void onClick(View v) {\n\t\t\t\tString car_length = editText_car_length.getEditableText().toString();\n\t\t\t\tString car_width = editText_car_width.getEditableText().toString();\n\t\t\t\tString suspension_front = editText_suspension_front.getEditableText().toString();\n\t\t\t\tString suspension_back = editText_suspension_back.getEditableText().toString();\n\n\n\t\t\t\tcarParameter carParm = new carParameter();\n\n\t\t\t\tLog.d(\"filename_avm_set_json\",\"filename_avm_set_json\"+avmSetParm.jsonFileName);\n\t\t\t\tcarParm.car_length=Integer.parseInt(car_length);\n\t\t\t\tcarParm.car_width=Integer.parseInt(car_width);\n\t\t\t\tcarParm.suspension_front=Integer.parseInt(suspension_front);\n\t\t\t\tcarParm.suspension_back=Integer.parseInt(suspension_back);\n\t\t\t\tcarParm.on_BSD=mView.mBSDViewID;\n\t\t\t\tcarParm.on_Bright=mView.mBrightID;\n\t\t\t\tcarParm.on_TrajectoryLine=mView.mTrajectoryLineViewID;\n\t\t\t\tLog.d(TAG, \"car_length\"+carParm.car_length);\n\t\t\t\tLog.d(TAG, \"car_width\"+carParm.car_width);\n\t\t\t\tLog.d(TAG, \"suspension_front\"+carParm.suspension_front);\n\t\t\t\tLog.d(TAG, \"suspension_back\"+carParm.suspension_back);\n\t\t\t\tLog.d(TAG, \"on_BSD\"+carParm.on_BSD);\n\t\t\t\tLog.d(TAG, \"on_Bright\"+carParm.on_Bright);\n\t\t\t\tLog.d(TAG, \"on_TrajectoryLine\"+carParm.on_TrajectoryLine);\n\t\t\t\ttry {\n\t\t\t\t\tavmSetParm.writeJson(carParm);\n\t\t\t\t} catch (Exception e) {\n\t\t\t\t\te.printStackTrace();\n\t\t\t\t}\n\t\t\t\tmPopupWindow_register.dismiss();\n\t\t\t}\n\t\t});\n\n\t\t//------ 设置按钮触发事件 ------\n\t\t//车道线\n\t\tmTrajectory_Switch.setOnCheckedChangeListener(new CompoundButton.OnCheckedChangeListener() {\n\t\t\t@Override\n\t\t\tpublic void onCheckedChanged(CompoundButton buttonView, boolean isChecked) {\n\t\t\t\tif (buttonView.isChecked()){\n\t\t\t\t\tmView.mTrajectoryLineViewID=1;\n\t\t\t\t}else {\n\t\t\t\t\tmView.mTrajectoryLineViewID=0;\n\t\t\t\t}\n\t\t\t\tmView.avmTrajectoryLineView();\n\t\t\t}\n\t\t});\n\n\t\t//BSD\n\t\tmBSD_Switch.setOnCheckedChangeListener(new CompoundButton.OnCheckedChangeListener() {\n\t\t\t@Override\n\t\t\tpublic void onCheckedChanged(CompoundButton buttonView, boolean isChecked) {\n\t\t\t\tif (buttonView.isChecked()){\n\t\t\t\t\tmView.mBSDViewID=1;\n\t\t\t\t\tavmStartBSD();\n\t\t\t\t}else {\n\t\t\t\t\tmView.mBSDViewID=0;\n\t\t\t\t\tavmStopBSD();\n\t\t\t\t}\n\t\t\t\tmView.avmBSDView();\n\t\t\t}\n\t\t});\n\t\t//亮度均衡\n\t\tmBE_Switch.setOnCheckedChangeListener(new CompoundButton.OnCheckedChangeListener() {\n\t\t\t@Override\n\t\t\tpublic void onCheckedChanged(CompoundButton buttonView, boolean isChecked) {\n\t\t\t\tif (buttonView.isChecked()){\n\t\t\t\t\tmView.mBrightID=1;\n\t\t\t\t}else {\n\t\t\t\t\tmView.mBrightID=0;\n\t\t\t\t}\n\t\t\t\tmView.avmBrightView();\n\t\t\t}\n\t\t});\n\t\t//返回\n\t\tdelcancel_btn.setOnClickListener(new View.OnClickListener() {\n\t\t\tpublic void onClick(View v) {\n\t\t\t\tmPopupWindow_register.dismiss();\n\t\t\t}\n\t\t});\n\t}\n});\n\n}\n```\n# 主界面xml文件\n```xml\n<?xml version=\"1.0\" encoding=\"utf-8\"?>\n<FrameLayout xmlns:android=\"http://schemas.android.com/apk/res/android\"\n    xmlns:tools=\"http://schemas.android.com/tools\"\n    android:layout_width=\"match_parent\"\n    android:layout_height=\"match_parent\"\n    tools:context=\".MainActivity\">\n    <androidx.drawerlayout.widget.DrawerLayout\n        android:id=\"@+id/drawer_layout\"\n        android:layout_width=\"match_parent\"\n        android:layout_height=\"match_parent\">\n\n    <LinearLayout\n        android:id=\"@+id/layout_root\"\n        android:layout_width=\"match_parent\"\n        android:layout_height=\"match_parent\"\n        android:background=\"@android:color/black\"\n        android:orientation=\"vertical\">\n\n        <TextView\n            android:id=\"@+id/tv_no_camera\"\n            android:layout_width=\"match_parent\"\n            android:layout_height=\"match_parent\"\n            android:layout_gravity=\"center\"\n            android:gravity=\"center\"\n            android:text=\"@string/no_camera_info\"\n            android:textColor=\"#FFFF0000\"\n            android:textSize=\"36sp\"\n            android:visibility=\"gone\" />\n\n        </LinearLayout>\n        <include layout=\"@layout/settings_layout\"></include>\n\n    </androidx.drawerlayout.widget.DrawerLayout>\n    <SurfaceView\n        android:id=\"@+id/surface_view\"\n        android:layout_width=\"fill_parent\"\n        android:layout_height=\"fill_parent\"\n        android:layout_marginLeft=\"1dp\"\n        android:layout_marginRight=\"1dp\"\n        android:layout_marginTop=\"1dp\" />\n\n    <ImageButton\n        android:id=\"@+id/image_set_btn\"\n        android:layout_width=\"55dp\"\n        android:layout_height=\"55dp\"\n        android:layout_gravity=\"bottom|left\"\n        android:layout_marginLeft=\"420dp\"\n        android:background=\"@drawable/btn_bg_round\"\n        android:src=\"@drawable/icon_set\" />\n\n    <ImageButton\n        android:id=\"@+id/image_3d_360_btn\"\n        android:layout_width=\"55dp\"\n        android:layout_height=\"55dp\"\n        android:layout_gravity=\"bottom|left\"\n        android:layout_marginLeft=\"60dp\"\n        android:background=\"@drawable/btn_bg_round\"\n        android:src=\"@drawable/icon_3d_360_normal\"/>\n\n    <ImageButton\n        android:id=\"@+id/image_front_btn\"\n        android:layout_width=\"55dp\"\n        android:layout_height=\"55dp\"\n        android:layout_gravity=\"bottom|left\"\n        android:layout_marginLeft=\"120dp\"\n        android:background=\"@drawable/btn_bg_round\"\n        android:src=\"@drawable/icon_3d_front_normal\"/>\n\n    <ImageButton\n        android:id=\"@+id/image_back_btn\"\n        android:layout_width=\"55dp\"\n        android:layout_height=\"55dp\"\n        android:layout_gravity=\"bottom|left\"\n        android:layout_marginLeft=\"180dp\"\n        android:background=\"@drawable/btn_bg_round\"\n        android:src=\"@drawable/icon_3d_back_normal\"/>\n    <!--       android:visibility=\"gone\" /> -->\n\n    <ImageButton\n        android:id=\"@+id/image_left_btn\"\n        android:layout_width=\"55dp\"\n        android:layout_height=\"55dp\"\n        android:layout_gravity=\"bottom|left\"\n        android:layout_marginLeft=\"240dp\"\n        android:background=\"@drawable/btn_bg_round\"\n        android:src=\"@drawable/icon_3d_left_normal\"/>\n\n    <ImageButton\n        android:id=\"@+id/image_right_btn\"\n        android:layout_width=\"55dp\"\n        android:layout_height=\"55dp\"\n        android:layout_gravity=\"bottom|left\"\n        android:layout_marginLeft=\"300dp\"\n        android:background=\"@drawable/btn_bg_round\"\n        android:src=\"@drawable/icon_3d_right_normal\"/>\n\n    <ImageButton\n        android:id=\"@+id/image_narrow_btn\"\n        android:layout_width=\"55dp\"\n        android:layout_height=\"55dp\"\n        android:layout_gravity=\"bottom|left\"\n        android:layout_marginLeft=\"360dp\"\n        android:background=\"@drawable/btn_bg_round\"\n        android:src=\"@drawable/icon_narrow_normal\"/>\n\n    <ImageButton\n        android:id=\"@+id/image_3d_normal_btn\"\n        android:layout_width=\"55dp\"\n        android:layout_height=\"55dp\"\n        android:layout_gravity=\"bottom|left\"\n        android:background=\"@drawable/btn_bg_round\"\n        android:src=\"@drawable/icon_3d_normal\"/>\n</FrameLayout>\n```\n# 跳转界面xml文件\n```xml\n<?xml version=\"1.0\" encoding=\"utf-8\"?>\n<LinearLayout xmlns:android=\"http://schemas.android.com/apk/res/android\"\n    xmlns:tools=\"http://schemas.android.com/tools\"\n    android:id=\"@+id/avm_parm_view\"\n    android:layout_width=\"match_parent\"\n    android:layout_height=\"match_parent\"\n    android:orientation=\"vertical\"\n    tools:visibility=\"visible\">>\n\n    <!-- 表格1 -->\n    <TableLayout\n        android:layout_width=\"match_parent\"\n        android:layout_height=\"match_parent\"\n        android:background=\"#2B2B2B\"\n        android:stretchColumns=\"1,3\" >\n\n        <TableRow>\n            <TextView\n                android:id=\"@+id/Text_car_width\"\n                android:layout_width=\"wrap_content\"\n                android:layout_height=\"wrap_content\"\n                android:text=\"  车辆宽度:  \"\n                android:textColor=\"@color/color_ffffff\"\n                android:textSize=\"18sp\" />\n            <EditText\n                android:id=\"@+id/EditText_car_width\"\n                android:layout_width=\"wrap_content\"\n                android:layout_height=\"wrap_content\"\n                android:layout_column=\"0\"\n                android:background=\"#CCCFD1\"\n                android:hint=\"毫米/mm\"\n                android:gravity=\"center\"\n                android:inputType=\"number\"\n                android:selectAllOnFocus=\"true\"\n                android:textSize=\"18sp\" />\n            <TextView\n                android:id=\"@+id/Text_suspension_front\"\n                android:layout_width=\"wrap_content\"\n                android:layout_height=\"wrap_content\"\n                android:text=\"  车前悬挂:  \"\n                android:textColor=\"@color/color_ffffff\"\n                android:textSize=\"18sp\" />\n            <EditText\n                android:id=\"@+id/EditText_suspension_front\"\n                android:layout_width=\"wrap_content\"\n                android:layout_height=\"wrap_content\"\n                android:layout_column=\"0\"\n                android:background=\"#CCCFD1\"\n                android:hint=\"毫米/mm\"\n                android:gravity=\"center\"\n                android:inputType=\"number\"\n                android:selectAllOnFocus=\"true\"\n                android:textSize=\"18sp\" />\n\n        </TableRow>\n\n        <!-- 分割线 -->\n        <View\n            android:layout_width=\"match_parent\"\n            android:layout_height=\"10dp\"\n            android:background=\"#000000\" />\n\n        <TableRow>\n            <TextView\n                android:id=\"@+id/Text_car_length\"\n                android:layout_width=\"wrap_content\"\n                android:layout_height=\"wrap_content\"\n                android:text=\"  车辆长度:  \"\n                android:textColor=\"@color/color_ffffff\"\n                android:textSize=\"18sp\" />\n            <EditText\n                android:id=\"@+id/EditText_car_length\"\n                android:layout_width=\"wrap_content\"\n                android:layout_height=\"wrap_content\"\n                android:layout_column=\"0\"\n                android:background=\"#CCCFD1\"\n                android:hint=\"毫米/mm\"\n                android:gravity=\"center\"\n                android:inputType=\"number\"\n                android:selectAllOnFocus=\"true\"\n                android:textSize=\"18sp\" />\n\n            <TextView\n                android:id=\"@+id/Text_suspension_back\"\n                android:layout_width=\"wrap_content\"\n                android:layout_height=\"wrap_content\"\n                android:text=\"  车后悬挂:  \"\n                android:textColor=\"@color/color_ffffff\"\n                android:textSize=\"18sp\" />\n            <EditText\n                android:id=\"@+id/EditText_suspension_back\"\n                android:layout_width=\"wrap_content\"\n                android:layout_height=\"wrap_content\"\n                android:layout_column=\"0\"\n                android:background=\"#CCCFD1\"\n                android:hint=\"毫米/mm\"\n                android:gravity=\"center\"\n                android:inputType=\"number\"\n                android:selectAllOnFocus=\"true\"\n                android:textSize=\"18sp\" />\n        </TableRow>\n        <!-- 分割线 -->\n        <View\n            android:layout_width=\"match_parent\"\n            android:layout_height=\"10dp\"\n            android:background=\"#000000\" />\n\n        <TableRow>\n            <TextView\n                android:id=\"@+id/Text_BE_Switch\"\n                android:layout_width=\"wrap_content\"\n                android:layout_height=\"wrap_content\"\n                android:text=\"  亮度均衡:  \"\n                android:textColor=\"@color/color_ffffff\"\n                android:textSize=\"18sp\" />\n            <Switch\n                android:id=\"@+id/BE_Switch\"\n                android:layout_width=\"wrap_content\"\n                android:layout_height=\"wrap_content\"/>\n\n            <TextView\n                android:id=\"@+id/Text_BSD_Switch\"\n                android:layout_width=\"wrap_content\"\n                android:layout_height=\"wrap_content\"\n                android:text=\"  BSD开关:  \"\n                android:textColor=\"@color/color_ffffff\"\n                android:textSize=\"18sp\" />\n\n            <Switch\n                android:id=\"@+id/BSD_Switch\"\n                android:layout_width=\"wrap_content\"\n                android:layout_height=\"wrap_content\"/>\n        </TableRow>\n        <!-- 分割线 -->\n        <View\n            android:layout_width=\"match_parent\"\n            android:layout_height=\"10dp\"\n            android:background=\"#000000\" />\n        <TableRow>\n            <TextView\n                android:id=\"@+id/Text_TrajectoryLine_Switch\"\n                android:layout_width=\"wrap_content\"\n                android:layout_height=\"wrap_content\"\n                android:text=\"  动态辅助线:  \"\n                android:textColor=\"@color/color_ffffff\"\n                android:textSize=\"18sp\" />\n\n            <Switch\n                android:id=\"@+id/TrajectoryLine_Switch\"\n                android:layout_width=\"wrap_content\"\n                android:layout_height=\"wrap_content\"/>\n        </TableRow>\n        <Button\n            android:id=\"@+id/avm_parameter_save\"\n            android:layout_width=\"wrap_content\"\n            android:layout_height=\"wrap_content\"\n            android:text=\"保存\" />\n        <Button\n            android:id=\"@+id/avm_parameter_return\"\n            android:layout_width=\"wrap_content\"\n            android:layout_height=\"wrap_content\"\n            android:text=\"返回\" />\n    </TableLayout>\n\n\n\n</LinearLayout>\n```","tags":["android","安卓弹窗"],"categories":["android"]},{"title":"JNI中成员变量和方法的相互访问","slug":"JNI中成员变量和方法的相互访问","url":"/2022/12/14/jni-zhong-cheng-yuan-bian-liang-he-fang-fa-de-xiang-hu-fang-wen/","content":"# 什么是JNI\n说明：JNI 是 Java Native Interface 的缩写，它提供了若干的API实现了Java和其他语言的通信（主要是C&C++，但是它并不妨碍你使用其他编程语言，只要调用约定受支持就可以了）。从Java1.1开始，JNI 标准成为 java 平台的一部分，它允许 Java 代码和其他语言写的代码进行交互。总的来说，JNI 就是一个允许Java语言和其他编程语言（主要是C/C++）通信的接口。\n\n原因：C/C++ 是系统级的编程语言，可以用来开发任何和系统相关的程序和类库，效率也很高。而 Java 本身编写底层的应用比较难以实现，使用 JNI 可以调用现有的本地库，极大地灵活了 Java 的开发。\n\n- 缺点：\n\n    - 1、使用java与本地已编译的代码交互，通常会丧失平台可移植性。\n\n    - 2、程序不再是绝对安全的，本地代码的不当使用可能导致整个程序崩溃。\n\n注：对于上面所说的java使用了JNI 接口会丧失平台的可移植性解释如下\n\nJNI 提供出来一个功能接口，但是这个功能是使用本地语言进行实现的，通常是C或者C++。\n\n以 linux 系统和 window 系统的 printf 函数为例，虽然这两个系统都提供了这个打印函数，并且名字也一样，但是在实现上可能会有各自的不同点。同时在 window 下的动态库为 dll 文件，linux 下的动态库为 so 文件。\n\n所以我原本在 linux 下可以正常使用的一套 JNI 功能，一旦需要转移到 windows 上执行的时候就需要重新编译实现接口的动态库。虽然 java 是跨平台的，但是使用 jni 调用的本地方法却是与平台相依赖的，会在进行编译的过程中会出现这样或者那样的兼容性问题，一般不能直接拿来即用。\n\n- 实现JNI的基本步骤\n    - 编写带有 native 声明的方法的java类。\n    - 使用 javah + 类名生成扩展名为.h的头文件。\n    - 使用 C/C++ 实现本地方法。\n    - 将 C/C++ 编写的文件生成动态链接库。\n    - 在 java 类中引用该动态链接库并完成调用。\n    - 注：可以先写 java 的调用，也可以先写 C/C++ 的实现，只要两边约定好接口的名称，参数，返回值等信息即可。\n# 涉及数据类型对照表\n## 基本类型\n![](https://cdn.jsdelivr.net/gh/geiyiren/MyBlogImage1/JNI中成员变量和方法的相互访问/1.png) \n\n## 引用类型\n![](https://cdn.jsdelivr.net/gh/geiyiren/MyBlogImage1/JNI中成员变量和方法的相互访问/2.png) \n# `java`访问`C++`的变量\n```cpp\nJNIEXPORT jint JNICALL\nJava_com_fibocom_multicamera_AvmSurfaceViewNative_nativeGetViewInfo(JNIEnv *env,\n                                                                                    jclass type,\n                                                                                    jint cmd,\n                                                                                    jobject output)\n{\n    jclass objectClass = env->GetObjectClass(output);\n\n    // 通过GetFieldID方法得到这个对象的dist属性\n    jfieldID m3DBtnOn = env->GetFieldID(objectClass, \"m3DBtnOn\", \"I\");\n    jfieldID viewID = env->GetFieldID(objectClass, \"viewID\", \"I\");\n    jfieldID wheelViewID = env->GetFieldID(objectClass, \"wheelViewID\", \"I\");\n    jfieldID trajectoryLineViewID = env->GetFieldID(objectClass, \"trajectoryLineViewID\", \"I\");\n    jfieldID bsdViewID = env->GetFieldID(objectClass, \"bsdViewID\", \"I\");\n    jfieldID brightID = env->GetFieldID(objectClass, \"brightID\", \"I\");\n    //\n    jfieldID dist_l = env->GetFieldID(objectClass, \"dist_l\", \"F\");\n    jfieldID dist_r = env->GetFieldID(objectClass, \"dist_r\", \"F\");\n    jfieldID upon = env->GetFieldID(objectClass, \"upon\", \"F\");\n    jfieldID angle = env->GetFieldID(objectClass, \"angle\", \"F\");\n    jfieldID viewPointX = env->GetFieldID(objectClass, \"viewPointX\", \"F\");\n    jfieldID viewPointY = env->GetFieldID(objectClass, \"viewPointY\", \"F\");\n\n    ParametersInit *m_Instance = ParametersInit::GetInstance();\n    avmmanager::TAvmViewTag m_view_info;\n    m_Instance->getViewInfo(m_view_info);\n\n    env->SetIntField(output, m3DBtnOn, m_view_info.m3DBtnOn);\n    env->SetIntField(output, viewID, m_view_info.viewID);\n    env->SetIntField(output, wheelViewID, m_view_info.wheelViewID);\n    env->SetIntField(output, trajectoryLineViewID, m_view_info.trajectoryLineViewID);\n    env->SetIntField(output, bsdViewID, m_view_info.bsdViewID);\n    env->SetIntField(output, brightID, m_view_info.brightID);\n    //\n    env->SetFloatField(output, dist_l, m_view_info.dist_l);\n    env->SetFloatField(output, dist_r, m_view_info.dist_r);\n    env->SetFloatField(output, upon, m_view_info.upon);\n    env->SetFloatField(output, angle, m_view_info.angle);\n    env->SetFloatField(output, viewPointX, m_view_info.viewPointX);\n    env->SetFloatField(output, viewPointY, m_view_info.viewPointY);\n    return 0;\n}\n```\n# `C++`访问`java`的变量\n```cpp\n\nJNIEXPORT jint JNICALL\nJava_com_fibocom_multicamera_AvmSurfaceViewNative_nativeBSDInfo(JNIEnv *env,\n                                                                jobject obj, \n                                                                jobjectArray objectArray)\n{\n    jint ret = 0;\n    // 1. 获取数组的长度\n    jsize length = env->GetArrayLength(objectArray);\n    // XXX:数据长度永远为7，目前测试暂时支取第一个结果\n    if (length)\n        length = 1;\n\n    // 2. 获取Person类的Class对象\n    jclass class_Rect = env->FindClass(\"com/fibocom/aidl/Rect\");\n    if (class_Rect == NULL)\n    {\n        return ret;\n    }\n    else\n    {\n        LOGI(1, \"====FindClass success===== \\n\");\n    }\n\n    // 3. 获取Person的sayHello方法字段\n    jmethodID getX1 = env->GetMethodID(class_Rect, \"getX1\", \"()I\"); //(A)B---A为输入参数，B为输出参数\n    if (getX1 == nullptr)\n    {\n        return ret;\n    }\n    jmethodID getX2 = env->GetMethodID(class_Rect, \"getX2\", \"()I\"); //(A)B---A为输入参数，B为输出参数\n    if (getX2 == nullptr)\n    {\n        return ret;\n    }\n    jmethodID getY1 = env->GetMethodID(class_Rect, \"getY1\", \"()I\"); //(A)B---A为输入参数，B为输出参数\n    if (getY1 == nullptr)\n    {\n        return ret;\n    }\n    jmethodID getY2 = env->GetMethodID(class_Rect, \"getY2\", \"()I\"); //(A)B---A为输入参数，B为输出参数\n    if (getY2 == nullptr)\n    {\n        return ret;\n    }\n    jmethodID getCamID = env->GetMethodID(class_Rect, \"getCamID\", \"()I\"); //(A)B---A为输入参数，B为输出参数\n    if (getCamID == nullptr)\n    {\n        return ret;\n    }\n    jmethodID getTimestamp = env->GetMethodID(class_Rect, \"getTimestamp\", \"()J\"); //(A)B---A为输入参数，B为输出参数\n    if (getTimestamp == nullptr)\n    {\n        return ret;\n    }\n\n    // 4. 循环调用每个方法\n    jint aaa=0;\n    avmmanager::TBsdBox *avm_bsd = new avmmanager::TBsdBox[length];\n    for (int i = 0; i < length; i++)\n    {\n        // 获取引用类型数组的对象\n        jobject element = env->GetObjectArrayElement(objectArray, i);\n        // 判断数组元素是否是Person类对象\n        LOGI(1, \"====nativeBSDInfo==== [%d] ===== \\n\", i);\n        if (element != nullptr)\n        {\n            // 调用Person对象的sayHello()方法\n            avm_bsd[i].left = env->CallIntMethod(element, getX1);\n            avm_bsd[i].right = env->CallIntMethod(element, getX2);\n            avm_bsd[i].top = env->CallIntMethod(element, getY1);\n            avm_bsd[i].bottom = env->CallIntMethod(element, getY2);\n\n            int camID = env->CallIntMethod(element, getCamID);\n            LOGI(1, \"CallIntMethod %d \\n\", camID);\n            switch (camID)\n            {\n            case 7:\n                avm_bsd[i].cam_index = 0;\n                break;\n            case 4:\n                avm_bsd[i].cam_index = 1;\n                break;\n            case 6:\n                avm_bsd[i].cam_index = 2;\n                break;\n            case 5:\n                avm_bsd[i].cam_index = 3;\n                break;\n            default:\n                LOGI(1, \"nativeBSDInfo cam_index %d \\n\", camID);\n                avm_bsd[i].cam_index = camID;\n                break;\n            }\n\n            avm_bsd[i].timestamp = env->CallLongMethod(element, getTimestamp);\n            avm_bsd[i].size = length;\n            LOGI(1, \"====nativeBSDInfo==== X1[%d] %d  \\n\", i, avm_bsd[i].left);\n            LOGI(1, \"====nativeBSDInfo==== X2[%d] %d  \\n\", i, avm_bsd[i].right);\n            LOGI(1, \"====nativeBSDInfo==== Y1[%d] %d  \\n\", i, avm_bsd[i].top);\n            LOGI(1, \"====nativeBSDInfo==== Y2[%d] %d  \\n\", i, avm_bsd[i].bottom);\n            LOGI(1, \"====nativeBSDInfo==== id[%d] %d  \\n\", i, avm_bsd[i].cam_index);\n            LOGI(1, \"====nativeBSDInfo==== timestamp[%d] %ld  \\n\", i, avm_bsd[i].timestamp);\n            LOGI(1, \"====nativeBSDInfo==== size[%d] %d  \\n\", i, avm_bsd[i].size);\n        }\n    }\n\n    EventSystem::Instance()->SendEvent(\"avm_get_bsd_info\", avm_bsd, [](void *ptr_event)\n                                       {\n        Event *event = (Event *) ptr_event;\n        bool *buf = (bool *) event->Parameter();\n        delete buf;\n        delete event; });\n    return ret;\n}\n```","tags":["C++","jni"],"categories":["jni"]},{"title":"Json文件读写","slug":"Json文件读写","url":"/2022/12/14/json-wen-jian-du-xie/","content":"\n# java读写Json文件\n\n## json格式介绍\njson与xml相比, 对数据的描述性比XML较差,但是数据体积小,传递速度更快.  \n\njson数据的书写格式是\"名称:值对\",比如:\n```json\n\"Name\" : \"John\"                        //name为名称,值对为\"john\"字符串\n```\n值对类型共分为:  \n- 数字（整数或浮点数）\n- 字符串（在双引号中）\n- 逻辑值（true 或 false）\n- 数组（在方括号[]中）\n- 对象（在花括号{}中）\n- null\n当然数组也可以包含多对象:  \n```json\n{\n    \"employees\": [\n        { \"Name\":\"John\" , \"Age\":19 },\n        { \"Name\":\"Anna\" , \"Age\":22 },\n        { \"Name\":\"Peter\", \"Age\":23 }\n    ]\n}\n```\n表示\"employees\"对象中有3个对象数组(每个对象数组表示一条员工信息),其中并列的数据都必须用逗号\",\"隔开.  \n\n## json文件读写示例\n\n```java\npackage com.fibocom.multicamera;\n\nimport android.util.Log;\n\nimport org.json.JSONArray;\nimport org.json.JSONException;\nimport org.json.JSONObject;\n\nimport java.io.File;\nimport java.io.FileInputStream;\nimport java.io.FileNotFoundException;\nimport java.io.FileOutputStream;\nimport java.io.InputStreamReader;\nimport java.io.OutputStreamWriter;\nimport java.io.UnsupportedEncodingException;\n\nclass carParameter  extends Object{\n    public int on_TrajectoryLine;\n    public int on_BSD;\n    public int on_Bright;\n    public double scale_size; // 缩放\n    public int car_length;//车辆长度\n    public int car_width;//车辆宽度\n    public int suspension_front;//前悬挂\n    public int suspension_back;//后悬挂\n}\n\npublic class AvmSetParm {\n    public String jsonFileName;\n    public carParameter readJson() throws Exception {\n            carParameter carParm=new carParameter();\n            char cbuf[] = new char[10000];\n            InputStreamReader input =new InputStreamReader(new FileInputStream(new File(jsonFileName)),\"UTF-8\");\n            int len =input.read(cbuf);\n            String text =new String(cbuf,0,len);\n            //1.构造一个json对象\n            JSONObject obj = new JSONObject(text.substring(text.indexOf(\"{\")));   //过滤读出的utf-8前三个标签字节,从{开始读取\n\n            //获取数组\n            JSONArray dataArr = obj.getJSONArray(\"data\");\n            JSONObject carParameterObj =dataArr.getJSONObject(3);\n            JSONObject carParameter=carParameterObj.getJSONObject(\"carParameter\");\n\n            carParm.car_length=carParameter.getInt(\"car_length\");\n            carParm.car_width=carParameter.getInt(\"car_width\");\n            carParm.suspension_front=carParameter.getInt(\"suspension_front\");\n            carParm.suspension_back=carParameter.getInt(\"suspension_back\");\n            carParm.scale_size=carParameter.getDouble(\"scale_size\");\n            carParm.on_Bright=carParameter.getInt(\"BE_Switch\");\n            carParm.on_BSD=carParameter.getInt(\"BSD_Switch\");\n            carParm.on_TrajectoryLine=carParameter.getInt(\"TrajectoryLine_Switch\");\n            input.close();\n\n            Log.d(\"AvmSetParm\",\"car_length:\"+carParm.car_length);\n            Log.d(\"AvmSetParm\",\"car_width:\"+carParm.car_width);\n            Log.d(\"AvmSetParm\",\"suspension_front:\"+carParm.suspension_front);\n            Log.d(\"AvmSetParm\",\"suspension_back:\"+carParm.suspension_back);\n            Log.d(\"AvmSetParm\",\"scale_size:\"+carParm.scale_size);\n            return carParm;\n    }\n    public void writeJson(carParameter carParm) throws Exception {\n        char cbuf[] = new char[10000];\n        InputStreamReader input =new InputStreamReader(new FileInputStream(new File(jsonFileName)),\"UTF-8\");\n\n        int len =input.read(cbuf);\n        String text =new String(cbuf,0,len);\n        //1.构造一个json对象\n        JSONObject obj = new JSONObject(text.substring(text.indexOf(\"{\")));   //过滤读出的utf-8前三个标签字节,从{开始读取\n\n        //获取数组\n        JSONArray data = obj.getJSONArray(\"data\");\n        JSONObject carParameterObj =data.getJSONObject(3);\n        JSONObject carParameter=carParameterObj.getJSONObject(\"carParameter\");\n\n        carParameter.put(\"car_length\",carParm.car_length);\n        carParameter.put(\"car_width\",carParm.car_width);\n        carParameter.put(\"suspension_front\",carParm.suspension_front);\n        carParameter.put(\"suspension_back\",carParm.suspension_back);\n        carParameter.put(\"BE_Switch\",carParm.on_Bright);\n        carParameter.put(\"BSD_Switch\",carParm.on_BSD);\n        carParameter.put(\"TrajectoryLine_Switch\",carParm.on_TrajectoryLine);\n        Log.d(\"AvmSetParm\", \"car_length\"+carParm.car_length);\n        Log.d(\"AvmSetParm\", \"car_width\"+carParm.car_width);\n        Log.d(\"AvmSetParm\", \"suspension_front\"+carParm.suspension_front);\n        Log.d(\"AvmSetParm\", \"suspension_back\"+carParm.suspension_back);\n        Log.d(\"AvmSetParm\", \"BE_Switch\"+carParm.on_Bright);\n        Log.d(\"AvmSetParm\", \"BSD_Switch\"+carParm.on_BSD);\n        Log.d(\"AvmSetParm\", \"TrajectoryLine_Switch\"+carParm.on_TrajectoryLine);\n\n        carParameterObj.put(\"carParameter\",carParameter);\n        data.put(3,carParameterObj);\n        obj.put(\"data\",data);\n\n        OutputStreamWriter osw = new OutputStreamWriter( new FileOutputStream(jsonFileName),\"UTF-8\");\n        osw.write(obj.toString(4));\n        osw.flush();//清空缓冲区，强制输出数据\n        osw.close();//关闭输出流\n    }\n}\n\n```\n\n# c++读写Json文件\n\n- 模板函数定义\n```cpp\n/**\n * @brief 从文本中加载json\n * @tparam R json类型\n * @tparam T 自动推断的字符串类型\n * @param config json字符串\n * @return R\n */\ntemplate<typename R, typename T>\ninline R LoadJsonFromText(const T &config)\n{\n    // static_assert(JsonHasParse<R>::value,\n    //               \"error: the type must has static method [parse].\");\n    // nlohmann json\n    return R::parse(config, nullptr, true, true);\n}\n\n/**\n * @brief 通用类型\n * @tparam R\n * @tparam T\n * @tparam U\n * @param config\n * @param key\n * @param val\n * @return R\n */\ntemplate<typename R, typename T, typename U>\ninline R OptionalContain(const T &config, const U &key, const R &val, JsonGenericType)\n{\n    if (config.count(key) > 0)\n    {\n        return config.at(key);\n    }\n    return val;\n}\n```\n\n- 使用\n```cpp\n# include\"json.hpp\"\nusing nlohmann::json;\nstd::string config= \"example.jsonc\";\nauto json_config = LoadJsonFromText<json>(config);\n\nconst auto &vs_config = json_config[\"video_source\"];\n\nconst auto width  = vs_config[\"width\"].get<int>();\nconst auto height = vs_config[\"height\"].get<int>();\n\nconst auto width1  = json_config[\"video_source\"][\"width\"].get<int>();\nconst auto height1 = json_config[\"video_source\"][\"height\"].get<int>();\n\njson_config[\"video_source\"][\"width\"]  = 720;\njson_config[\"video_source\"][\"height\"] = 480;\n\n// 将jsonc文件转换为string\nconst auto &json_config_str = json_config.dump();\n\nconst auto &fake_config = vs_config[\"fake\"];\nconst auto fake_enable = ac::OptionalContain(fake_config, \"enable\", false);\n\n```\n\n- `json.hpp`\n![json.hpp](https://github.com/geiyiren/MyBlogFile1/blob/other/json%E6%96%87%E4%BB%B6%E8%AF%BB%E5%86%99/json.hpp)\n\n- `example.jsonc`\n```jsonc\n{\n    // 当前配置文件的版本，此版本用于兼容性处理\n    \"version\": \"1.0.0.0\",\n    \"camera_id\": \"camera_1\",\n\n    \"video_source\": {\n        \"width\" : 1280,                        // 需要设置为平台相应的分辨率\n        \"height\": 720,\n        \"format\": \"kRGB888\",                  // 内部自行生成, 这里实际上无效\n        \"device\": \"/dev/video0\",\n        \"fps\"   : 20,\n        \"connect\": true,                      // true：把回调的图像送入算法； false：不给算法送入图像。\n                                              // 这个选项对假视频源依然有效\n        \"fake\": {\n            \"enable\": false,                  // true表示启用假视频源\n            \"img\": \"assets/ssd_test_img.jpg\", // 使用这张图片来冒充，注意仅支持jpg格式图片，且最好是720或1080P图像\n            \"out_fmt\": \"kYUV422SP\"            // 假视频源的输出格式（模拟输出的视频格式）\n        }\n    },\n\n}\n\n```\n\n> 参考连接： https://cloud.tencent.com/developer/article/1556944","tags":["java","json文件"],"categories":["java"]},{"title":"车辆动态辅助轨迹线生成方法","slug":"车辆动态辅助轨迹线生成方法","url":"/2022/12/14/che-liang-dong-tai-fu-zhu-gui-ji-xian-sheng-cheng-fang-fa/","content":"\n# 汽车动力学原理\n在研究辅助泊车时，第一要研究一下汽车在运动的时候的轨迹，要建立一个汽车在泊车时的运动学模型来作为后面研究的理论基础。车辆在泊车的过程中有一个特点即它是低速行驶的，这时**车轮在滚动过程中不会发生侧方向的滑动**，由于汽车在缓慢行驶的过程中不会有侧向力，这时系统的约束条件是允许车轮发生滚动和侧转，但不会有滑动的发生，由此建立了车辆的运动学模型。下面是倒车的时候汽车的运动学模型：\n\n![](https://cdn.jsdelivr.net/gh/geiyiren/MyBlogImage1/车辆动态辅助轨迹线生成方法/Vehicle_dynamics_model.png) \n\n其中：(x_{f},y_{f})为汽车前轴中心点的坐标；(x_{r},y_{r})为汽车的后轴中心点的坐标；v指前轴中心点的速度；l_{m}为轴距；h_{r}为后轮距；φ为前轴中心的转向角；θ为汽车的航向角，指汽车的中心轴与参考方向上的夹角。\n\n![](https://cdn.jsdelivr.net/gh/geiyiren/MyBlogImage1/车辆动态辅助轨迹线生成方法/1.png) \n\n![](https://cdn.jsdelivr.net/gh/geiyiren/MyBlogImage1/车辆动态辅助轨迹线生成方法/2.png) \n\n![](https://cdn.jsdelivr.net/gh/geiyiren/MyBlogImage1/车辆动态辅助轨迹线生成方法/3.png) \n\n![](https://cdn.jsdelivr.net/gh/geiyiren/MyBlogImage1/车辆动态辅助轨迹线生成方法/4.png) \n\n![](https://cdn.jsdelivr.net/gh/geiyiren/MyBlogImage1/车辆动态辅助轨迹线生成方法/5.png) \n\n![](https://cdn.jsdelivr.net/gh/geiyiren/MyBlogImage1/车辆动态辅助轨迹线生成方法/6.png) \n\n\n\n总结：\n- 轨迹和速度没有关系\n- 车辆的两个后轮是沿着圆在运动的\n- **汽车在低速行驶且不考虑有侧滑的情况下，汽车的车身上每一点的运动轨迹都是指向同样的一个圆心的圆，并且只和汽车的转向角有关系，和汽车的车速没有关系**\n\n## 阿克曼转弯几何原理\n- 示意图：  \n![](https://cdn.jsdelivr.net/gh/geiyiren/MyBlogImage1/车辆动态辅助轨迹线生成方法/Ackerman_turning_geometry.png)\n\n \n- 讲解视频：https://www.youtube.com/watch?v=8AimxDPWKcM\n\n# 参考专利\n\n[参考专利](https://github.com/geiyiren/MyBlogFile1/blob/pdf/%E8%BD%A6%E8%BE%86%E5%8A%A8%E6%80%81%E8%BE%85%E5%8A%A9%E8%BD%A8%E8%BF%B9%E7%BA%BF%E7%94%9F%E6%88%90%E6%96%B9%E6%B3%95/%E4%B9%98%E7%94%A8%E8%BD%A6%E5%8A%A8%E6%80%81%E5%80%92%E8%BD%A6%E8%BE%85%E5%8A%A9%E7%BA%BF%E8%AE%BE%E8%AE%A1.pdf)","tags":["360环视","辅助驾驶"],"categories":["辅助驾驶"]},{"title":"linux常用命令","slug":"linux常用命令","url":"/2022/12/12/linux-chang-yong-ming-ling/","content":"\n# find命令\n```bash\nfind 位置 -name '名称'\n```\n# aiApp执行命令\n## 打印\n```bash\ntail -F /mnt/data/log/ylog | grep aiApp\n```\n## 运行\n```bash\n/data/hq/bin/hqsetprop ctl.start aiApp\n```\n## 停止\n```bash\n/data/hq/bin/hqsetprop ctl.stop aiApp\n```\n## 重启\n```bash\n/data/hq/bin/hqsetprop ctl.restart aiApp\n```\n# 查看与转换YUV图像：\n```bash\nffplay -pixel_format nv12 -f rawvideo -video_size 240x576 stitch_view.yuv\n```\n```bash\nffmpeg -pix_fmt nv12 -video_size 1280x720 -i src_1.yuv -y src_1.jpg\n```\n# ubuntu终端查看历史命令\n```bash\nhistory | grep some_command\n```\n# 查看cup限制\n```bash\nps | grep limit \n```\n# 1126关闭DNS验证\n```bash\nvi /etc/nsswitch.conf\n```\n或者直接替换对应字段\n```bash\nsed -i \"s/dns/#dns/g\" `grep \"dns\" -rl /etc/nsswitch.conf`\n```\n- 注释 dns选项，如下所示：\n\t> hosts:          files #dns\n\t> networks:       files #dns\n\n# 强制关闭窗口\n```bash\nxkill\n```\n- 然后移动鼠标点击需要关闭的窗口即可\n\n# 修改aiapp的cpu限制\n```bash\nvi /exapp/sh/run.sh\n```\n- 修改允许aiapp使用的cpu百分比 XX\n\t> #...............aiApp...CPU.........                         \n\t> /data/hq/bin/cpulimit -l XX -e aiApp &\n\n# 本地gitlab库添加远程库信任\n```bash\ngit config --global --add safe.directory /media/geiyiren/MyCode/AVM/avm_2d/master/avm_cpu_algo\n```\n\n# 保存yuv buf图像\n```cpp\nFILE *fp_dump = fopen(\"bsd_1.yuv\", \"wb+\");\nif (fp_dump == NULL)\n{\n\tprintf(\"fp_dump open fail\\n\");\n}\nelse\n{\n\tprintf(\"fp_dump cam  yuv open success\\n\");\n}\nsize_t bytes_write = fwrite(p_yuv_buf[1], width * height * 3 / 2 , 1, fp_dump);\n\nif (bytes_write <= 0)\n{\n\tprintf(\"write raw_stream fail !!!\\n\");\n}\nfclose(fp_dump);\n```\n\n# 批量将jpg转换为yuv\n```bash\n#! /bin/bash\nfiles=$(ls $folder)\nyuv=\"yuv\"\nfor file in $files\ndo\n  echo ${file:0:13}\n  file_name=${file:0:13}\n  str=$file_name$yuv\n  ffmpeg -i $file -s 1280*720 -pix_fmt nv12 $str\ndone\n```\n# abd 常用命令\n## 打开调试端口\n```bash\nadb tcpip 5555\n```\n## 连接\n```bash\nadb connect 10.10.200.140\n```\n## 进入远程终端\n```bash\nadb shell\n```\n## 关闭服务\n```bash\nadb kill-server\n```\n## 启动服务\n```bash\nadb start-server\n```\n## 重新挂载\n```bash\nadb remount\n```\n## 获取root权限\n```bash\nadb root\n```\n## 安卓录制屏幕\n```bash\nadb shell screenrecord  --time-limit 12 /sdcard/name.mp4\n```\n## \n# 安卓设备开启USB\n```bash\nsetprop persist.otg.mode device\n```\n- 远程登录后使用上述命令\n\n# 远程为安卓设备安装软件\n```bash\nadb install Launcher3.apk\n```\n- 在本地执行上述命令\n\n# 查看当前文件下所有文件大小\n```bash\n#以M为单位查看当前文件下所有文件的大小，包含隐藏文件\ndu -sm .[!.]* * | sort -hr\n```\n# 查看磁盘剩余空间\n```bash\ndf -hl\n```\n# github访问加速\n## 查询IP\n```bash\n#github.global.ssl.fastly.net 网站IP\nnslookup github.global.ssl.fastly.net\n#github.com 网站IP\nnslookup github.com\n```\n\n\n\n## 更改host文件\n```bash\nsudo gedit /etc/hosts\n```\n- 将上述查询到的IP复制到对应位置\n## 更新host文件\n```bash\nsudo /etc/init.d/network-manager restart\n```\n\n# BSD测试程序运行命令\n```bash\n#801-s(rv1126)测试BSD程序运行命令\ncd /exapp/app\n./bsd_proc_test -d /dev/video0 -w 1280 -h 720\n```\n\n# 鸿鹄\n\n## 鸿鹄设备常用命令\n\n\n- 以root身份挂载\n```bash\nadb root && adb remount\n```\n- 推送apk\n```bash\ncd /media/geiyiren/MyCode/AVM/avm_gpu_algo/branch/MultiCameraDemo/avm_gpu_algo/app/build/outputs/apk/debug\n```\n```\nadb push MultiCameraDemo.apk /system/priv-app/MultiCameraDemo/\n```\n- 推送库文件\n```bash\ncd /media/geiyiren/MyCode/AVM/avm_gpu_algo/branch/AVM_BSD_honghu/avm_gpu_algo/libs/arm64-v8a\n```\n```bash\nadb push libavmjni.so /system/priv-app/MultiCameraDemo/lib/arm64/\n```\n- 查看log日志\n```bash\nadb shell logcat > log.txt\n```\n- 保存NATIVE_LOG日志(cpp端打印信息)\n```bash\nadb shell logcat -s NATIVE_LOG > log.txt\n```\n- 保存程序运行严重错误日志(一般程序异常退出时打印该log)\n```bash\nadb shell logcat *:F > log.txt\n```\n\n## 鸿鹄设备资源存储位置\n```bash\n data\n └── gpu0------------\n     ├── calibrate\n     │   ├── **CALMAT.BIN**\n     │   └── **LENS.BIN**\n     └── shader\n         ├── **avm_3d_blend_lut.bin**\n         ├── **avm_3d_indices.bin**\n         ├── **avm_3d_lut.bin**\n         ├── car_model_line.fs\n         ├── car_model_line.vs\n         ├── car_model_test.fs\n         ├── car_model_test.vs\n```\n## 鸿鹄Bug查询关键字\n\n| 关键字     | 说明                 |\n| ---------- | :------------------- |\n| dlopen     | 文件缺失标志         |\n| crash      | 程序报错抛出异常标志 |\n| NATIVE_LOG | AVM cpp端的打印      |\n\n## 鸿鹄CPU占用与GPU占用查看\n\n```bash\n# adb登录后执行如下命令:\n## GPU\ncat /sys/class/kgsl/kgsl-3d0/gpu_busy_percentage\nwatch -n 1 cat /sys/class/kgsl/kgsl-3d0/gpu_busy_percentage\n## CPU\ntop\n```\n\n> 更加详细的资源查看可参照：软件snapdragonprofiler_external_linux\n>\n> Snapdragon Profiler是高通开发的用于调试分析高通Adreno GPU的一款桌面应用，支持Windows、MacOS 和 Linux 。在调试opengles应用程序上能发挥非常重要的作用。该工具能够捕捉CPU、GPU、DSP、内存、功率、网络连接和设备运行时的发热数据等，具有Realtime、Trace Capture、Snapshot Capture 三种模式。实时(Realtime)模式用于实时跟踪数据，跟踪(Trace Capture)模式用于跟踪事件和数据，默认最大值是10秒。快照(Snapshot Capture)模式用于捕获OpenGL ES应用程序的当前帧并可以进行调试，包括单步调试绘制指令，查看和编辑着色器、程序、纹理以及查看像素历史的能力。着色器代码是通过反编译得到，得到的代码跟原glsl代码基本一致，并且可以在截图后修改glsl进行调试。\n>\n> \n>\n> 作者：cain_huang\n> 链接：https://www.jianshu.com/p/d8d1a231dada\n> 来源：简书\n> 著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。\n\n# ssh相关\n\n## 主机A免密登录主机B\n\n在主机A执行如下命令\n\n```bash\nssh-copy-id 主机B的用户名@主机B的IP地址\n```\n\n# NEON优化相关函数\n\n## internal::prefetch()\n\n作用：将数据放在缓存中\n\n## vld1q()\n\n作用：加载数据\n\n例如：\n\n```cpp\nfloat32x4_t q0 = vld1q_f32(d0); // 加载 d0 地址起始的 4 个 float 数据到 q0\n```\n\n## internal::getRowPtr()\n\n例如：\n\n```cpp\ninternal::getRowPtr(src0Base, src0Stride, y);  //返回src0Base+src0Stride*y的地址\n```\n## YUV图像转换\n\n- 安装ffmpeg\n```bash\nsudo apt-get install ffmpeg\n```\n- yuv查看\n```bash\n ffplay -pixel_format nv12 -f rawvideo -video_size 1920x1080 test.yuv\n```\n\n- jpg --> yuv\n```bash\n ffmpeg -i front0.jpg -s 1280*720 -pix_fmt nv12 front0.yuv\n```\n- yuv --> jpg\n```bash\n ffmpeg -pix_fmt nv12 -video_size 1280x800 -i src_1.yuv -y src_1.jpg\n```\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","tags":["linux","终端"],"categories":["linux"]},{"title":"C++变量命名常用缩写表","slug":"C++变量命名常用缩写表","url":"/2022/12/12/c-bian-liang-ming-ming-chang-yong-suo-xie-biao/","content":"\n\n|全 称| 缩 写|  \n|:---:|:---:|  \n| Address | addr |\n| Administrator | adm |\n| average | avg |\n| Application | app|\n| Argument | arg|\n| Database | DB|\n| assemble | asm|\n| Bitmap | bmp|\n| back | bk|\n| asynchronization | asyn\n| Button | btn\n| Buffer | buf\n| Calculate | calc\n| Character | char\n| Change | chg\n| Click | clk\n| color | clr\n| Command | cmd\n|Compare | cmp\n|Column | col\n|coordinates | coord\n|copy | cpy\n|Control | ctl / ctrl\n|Current | cur\n|Cylinder | cyl\n|Debug | dbg\n|Double | dbl\n|Decrease | dec\n|default | def\n|Delete | del\n|Destination | dest / dst\n|Device | dev\n|dictionary | dict\n|different | diff\n|directory | dir\n|Display | disp\n|Divide | div\n|Dialog | dlg\n|Document | doc\n|Driver | drv\n|Dynamic | dyna\n|Environment | env\n|error | err\n|Extend | ex/ext\n|execute | exec\n|flag | flg\n|Frame | frm\n|Function | func / fn\n|group | grp\n|Horizontal | horz\n|Index | idx / ndx\n|Image | img\n|Implement | Impl\n|Increase | inc\n|Information | info\n|Initial/Initialize/Initialization | init\n|Insert | ins\n|Instance | inst\n|Interrupt | INT / intr\n|Length | len\n|Library | lib\n|Link | lnk\n|logical | log\n|List | lst\n|maximum | max\n|Memory | mem\n|Manage / Manager | mgr / man\n|middle | mid\n|minimum | min\n|Message | msg\n|Multiply | mul\n|Number | num\n|Object | obj\n|Offset | ofs\n|Origin / Original | org\n|Parameter | param\n|picture | pic\n|package | pkg\n|Point | pnt / pt\n|Position | pos\n|previous | pre / prev\n|program | prg\n|Print | prn\n|Process / Procedure | proc\n|Properties | prop\n|Password | psw\n| Pointer|ptr \n| Public|pub \n| rect|rc \n| Reference|ref \n| Register|reg \n| request|req \n| Resource|res \n| return|ret \n| region|rgn \n| screen|scr\n| Second|sec \n| Segment|seg \n| Select|sel \n| Source|src \n| Standard|std \n| Storage|stg \n| Stream|stm \n| String|str\n| Subtract|sub\n| summation|sum \n| Server|svr \n| Synchronization|sync \n| System|sys \n| Table|tbl \n| Temporary|temp / tmp \n| translate/transation/transparent|tran / trans \n| Test|tst \n| text|txt \n| Unknown|unk \n| Update|upd \n| Upgrade|upg \n| Utility|util \n| Variable|var \n| Version|ver \n| Vertical|vert \n| Virus|vir \n| Window|wnd \n","tags":["C++","变量命名"],"categories":["C++"]},{"title":"ubuntu 16.04 LTS下安装docker并创建深度学习环境","slug":"ubuntu16_04_LTS下安装docker并创建深度学习环境","url":"/2022/11/23/ubuntu16-04-lts-xia-an-zhuang-docker-bing-chuang-jian-shen-du-xue-xi-huan-jing/","content":"\n## 1.安装docker\n\nubuntu下安装docker的官方教程：[点我查看](https://docs.docker.com/engine/install/ubuntu/)\n\nubuntu下安装参考教程：[点我查看](https://yeasy.gitbook.io/docker_practice/install/ubuntu)\n\n### 1.1卸载旧版本\n\n```\nsudo apt-get remove docker docker-engine docker.io containerd runc\n```\n\n### 1.2使用apt安装\n\n官网提供多种安装方式，这里使用apt安装\n\n由于 `apt` 源使用 HTTPS 以确保软件下载过程中不被篡改。因此，我们首先需要添加使用 HTTPS 传输的软件包以及 CA 证书。\n\n```\nsudo apt-get update\n\nsudo apt-get install \\\n    apt-transport-https \\\n    ca-certificates \\\n    curl \\\n    gnupg \\\n    lsb-release\n```\n\n添加docker密匙：\n\n```\ncurl -fsSL https://mirrors.aliyun.com/docker-ce/linux/ubuntu/gpg | sudo gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg\n\n\n# 官方密匙\ncurl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg\n```\n\n然后，我们需要向 `sources.list` 中添加 Docker 软件源：\n\n```\necho \\\n  \"deb [arch=amd64 signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://mirrors.aliyun.com/docker-ce/linux/ubuntu \\\n  $(lsb_release -cs) stable\" | sudo tee /etc/apt/sources.list.d/docker.list > /dev/null\n\n\n# 官方源\necho \\\n   \"deb [arch=amd64 signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://download.docker.com/linux/ubuntu \\\n   $(lsb_release -cs) stable\" | sudo tee /etc/apt/sources.list.d/docker.list > /dev/null\n```\n\n以上命令会添加稳定版本的 Docker APT 镜像源，如果需要测试版本的 Docker 请将 stable 改为 test。\n\n安装docker:\n\n```\nsudo apt-get update\nsudo apt-get install docker-ce docker-ce-cli containerd.io\n```\n\n### 1.3配置阿里云镜像加速器\n\n参考网址：[点我查看](https://cr.console.aliyun.com/cn-hangzhou/instances/mirrors)\n\n需要个人注册阿里云账号并开启容器镜像服务，该服务免费。\n\n然后查看镜像加速地址，例如我的镜像加速地址为：\n\n```\nhttps://znrurdgu.mirror.aliyuncs.com\n```\n\n注意：这里需要是自己的镜像加速器，否则没有权限访问。\n\n执行如下命令配置docker：\n\n```\n# 生成配置文件\ndocker-machine ssh default\n# 设置加速器地址：\n# sed -i \"s|EXTRA_ARGS='|EXTRA_ARGS='--registry-mirror=自己的镜像加速地址|g\" /var/lib/boot2docker/profile\nsed -i \"s|EXTRA_ARGS='|EXTRA_ARGS='--registry-mirror=https://znrurdgu.mirror.aliyuncs.com|g\" /var/lib/boot2docker/profile\n# 退出docker\nexit\n# 重启\ndocker-machine restart default\n# 查看\ndocker info\n```\n\n查看docker信息后，可以发现 Registory mirrors 项的内容为刚刚设置的阿里云镜像地址。\n\n```\nsudo mkdir -p /etc/docker\nsudo tee /etc/docker/daemon.json <<-'EOF'\n{\n  \"registry-mirrors\": [\"https://znrurdgu.mirror.aliyuncs.com\"]\n}\nEOF\nsudo systemctl daemon-reload\nsudo systemctl restart docker\n```\n\n\n\n## 2.安装 nvidia-docker\n\ndocker 默认是不支持在容器内 GPU 加速的，NVIDIA 官方做了个工具箱来支持容器内 GPU 加速运算，这大大方便了深度学习开发者。\n\n官方教程：[点我查看](https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/install-guide.html#installing-on-ubuntu-and-debian)\n\n参考教程：[点我查看](https://blog.csdn.net/zhouchen1998/article/details/110679750)\n\n依次执行如下命令即可：\n\n```\ndistribution=$(. /etc/os-release;echo $ID$VERSION_ID) \\\n   && curl -s -L https://nvidia.github.io/nvidia-docker/gpgkey | sudo apt-key add - \\\n   && curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.list | sudo tee /etc/apt/sources.list.d/nvidia-docker.list\n\n\ncurl -s -L https://nvidia.github.io/nvidia-container-runtime/experimental/$distribution/nvidia-container-runtime.list | sudo tee /etc/apt/sources.list.d/nvidia-container-runtime.list\n\n\nsudo apt-get update\n\n\nsudo apt-get install -y nvidia-docker2\n\n\nsudo systemctl restart docker\n```\n\n## 3.拉取cuda、cudnn的镜像\n\ndocker hub地址：[点我查看](https://hub.docker.com/r/nvidia/cuda)\n\n官网给出多个版本可供拉取，这里使用cuda:10.0-cudnn7-devel-ubuntu16.04\n\n```\ndocker pull nvidia/cuda:10.0-cudnn7-devel-ubuntu16.04\n```\n\n## 4.新建容器\n\n容器与镜像的关系好比：镜像为C++中的类，而容器为镜像的实例话，这里基于拉去的cuda:10.0-cudnn7-devel-ubuntu16.04镜像创建一个新的容器并进入容器中：\n\n```\ndocker container run --name pytorch1.1-gpu -it --gpus all  nvidia/cuda:10.0-cudnn7-devel-ubuntu16.04 /bin/bash\n```\n\n解释：\n\n- docker container run：容器启动命令，同时会新建一个容器，因此该命令是在新建容器时使用\n- --name ：后的参数为新建容器的名称\n- -it：其实是 -i -t 的缩写，该参数使得容器具备交互性并与终端进行连接，将shell切换至终端\n- --gpu all：表示允许容器使用宿主机的所有GPU\n- nvidia/cuda:10.0-cudnn7-devel-ubuntu16.04：创建新的容器所基于的镜像名称\n- /bin/bash：指定在容器内部运行的进程，该进程是通过docker container run命令来通知容器运行的\n\n以该命令创建并进入容器后，该容器就具有了nvidia/cuda:10.0-cudnn7-devel-ubuntu16.04镜像的配置，相当于实现了“实例话”\n\n退出该容器后，可以使用以下命令进行查看：\n\n- 查看正在运行的容器：\n\n```\ndocker container ls\n```\n\n- 查看容器运行历史：\n\n```\ndocker container ls -a\n```\n\n这里可以看到刚才运行的容器pytorch1.1-gpu的信息。\n\n### 4.1.重启容器\n\ndocker container start + 容器名或容器ID，启动一个已经完成创建并停止运行的容器：\n\n```\ndocker container start pytorch1.1-gpu\n```\n\n查看正在运行的容器：\n\n```\ndocker container ls\n```\n\ndocker container exec   命令用于进入正在运行的容器：\n\n```\ndocker container exec -it pytorch1.1-gpu /bin/bash\n```\n\n### 4.2停止容器\n\ndocker container stop   用于停止正在运行的容器：\n\n```\ndocker container stop pytorch1.1-gpu\n```\n\n### 4.3删除容器\n\n```\ndocker container rm  待删除的容器命令或ID\n```\n\n注意：删除容器之前需要停止容器，避免报错。\n\n## 5.安装常用工具\n\n```\n# 安装git\napt-get install git -y\n\n# 安装vim\napt install vim\n\n# 安装cmake\napt install cmake\n\n# 安装updatedb\napt-get install mlocate\n\n# 安装wget\napt-get install wget\n# 安装curl\napt-get install curl\n```\n\n## 6.在容器中安装python\n\n新建的容器默认没有python或pip、vim等工具，除非新建容器时将这些包一并装入，因此需要手动安装一些需要的包。新的容器中 apt-get 或 apt 命令是可以使用的：\n\n参考网站：[点我查看](https://www.digitalocean.com/community/questions/unable-to-install-pyhton-3-7-version-on-ubuntu-16-04-error-couldn-t-find-any-package-by-regex-python3-7)\n\n```\n#更新源\napt update\n\n#安装python依赖\napt install software-properties-common\n\n#添加源\nadd-apt-repository ppa:deadsnakes/ppa\n\n#更新源\napt update\n\n#安装python\napt install python3.7\n\n#查看python版本\npython --version 或 python -V\npython3 --version 或 python3 -V\n```\n\n安装完python3.7可能需要修改默认python指向才能正常使用python3.7：\n\n参考网站：[点我查看](https://blog.csdn.net/qq_33188180/article/details/109723636)\n\n查看默认python指向：\n\n```\nls -l /usr/bin | grep python \n```\n\n删除原有python软连接：\n\n```\nrm /usr/bin/python\n```\n\n建立python到新的软链接python3.7：\n\n```\nln -s /usr/bin/python3.7  /usr/bin/python\n```\n\n## 7.在容器中安装pip\n\n这里也有个小坑！如果你写的是python3-pip 执行安装后，如果系统自带了python3.5，其实pip这时是装在了python3.5环境下了！！正确的指定方式，应该把小版本号也加上！\n\n```\napt-get install python3.7-pip\n```\n\n但是执行上述命令可能会报错，如果报错需要安装下面的方法添加pip安装源：\n\n```\ncurl https://bootstrap.pypa.io/get-pip.py -o get-pip.py\n```\n\n由于上面已经将python指向了python3，因此下面直接使用python安装即可，否者要使用python3安装：\n\n```\npython get-pip.py --force-reinstall\n```\n\n查看pip位置：\n\n```\nwhich pip\n```\n\n我在安装后显示安装在：/usr/local/bin/pip\n\n建立pip软链接：\n\n```\nln -s /usr/local/bin/pip /usr/bin/pip\n```\n\n注意：第一个地址  /usr/local/bin/pip  为  which pip  的显示地址\n\n查看pip版本：\n\n```\npip -V 或 pip --version\n```\n\n我的显示位置为：pip 20.3.4 from /usr/local/lib/python3.7/dist-packages/pip (python 3.7)\n\n至此，python将指向python3.7，pip将指向python 3.7的pip 20.3.4，实现python和pip的版本对应，且目标容器内二者都是唯一存在，不需要再使用python3和pip3调用python3的对应版本，这样使用pip安装的包将默认存放在  /usr/local/lib/python3.7/dist-packages  中。\n\n## 8.安装PyTorch\n\n最新版本安装方法：[点我查看](https://pytorch.org/get-started/locally/)\n\n历史版本安装方法：[点我查看](https://pytorch.org/get-started/previous-versions/)\n\n```\npip install torch==1.1.0 torchvision==0.3.0\n```\n\n## 9.安装eigen3\n\n参考网址：[点我查看](https://blog.csdn.net/xiangxianghehe/article/details/81236299?utm_medium=distribute.pc_relevant.none-task-blog-2~default~BlogCommendFromMachineLearnPai2~default-4.control&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2~default~BlogCommendFromMachineLearnPai2~default-4.control)\n\n### 9.1安装依赖\n\n```\napt-get install libopenblas-dev\napt-get install --no-install-recommends libboost1.58-all-dev\napt-get install libx11-dev\napt-get install libgl1-mesa-dev \napt-get install libglu1-mesa-dev \napt-get install freeglut3-dev\napt-get install doxygen\nwget https://nchc.dl.sourceforge.net/project/glew/glew/2.1.0/glew-2.1.0.tgz --no-check-certificate\ntar -xzvf glew-2.1.0.tgz\ncd glew-2.1.0/\nmake \nmake install\nldconfig -v\n```\n\n### 9.2安装Eigen3.3.5\n\n```\nwget https://github.com/eigenteam/eigen-git-mirror/archive/3.3.5.tar.gz\ntar -xzvf 3.3.5.tar.gz \nmv eigen-git-mirror-3.3.5/ eigen-3.3.5/\ncd eigen-3.3.5/\nmkdir build\ncd build\ncmake ..\nmake\nmake install \nldconfig -v\n```\n\n### 9.3测试\n\n在容器中创建测试文件夹：\n\n```\nmkdir install_test\n```\n\n在宿主机上创建如下文件：\n\n- CMakeLists.txt\n\n```\ncmake_minimum_required( VERSION 2.8 )\nproject(useEigen)\n\nset( CMAKE_BUILD_TYPE \"Release\" )\nset( CMAKE_CXX_FLAGS \"-O3\" )\nset( CMAKE_CXX_FLAGS \"-std=c++11\")\n\n# 添加Eigen头文件\ninclude_directories( \"/usr/local/include/eigen3\" )\n\n\nadd_executable(useEigen  main.cpp)\nfind_package(Eigen3 REQUIRED)\ntarget_link_libraries(${PROJECT_NAME}  ${EIGEN3_LIBS})\n```\n\n- main.cpp\n\n```\n#include <iostream>\n#include <fstream>\n#include <vector>\n\n#include <Eigen/Core>\n#include <Eigen/Dense>\n#include <Eigen/Geometry>\n#include <Eigen/StdVector>\n\nusing namespace std;\nint main()\n{\n    //1.rotation vector to  rotation matrix\n    Eigen::AngleAxisd rotationVector(M_PI/4,Eigen::Vector3d(0,0,1));\n    Eigen::Matrix3d rotationMatrix=Eigen::Matrix3d::Identity();\n    rotationMatrix=rotationVector.toRotationMatrix();\n    cout<<\"rotationMatrix \\n\"<<rotationMatrix<<endl;\n\n    //2.rotation vector to quaterniond\n    Eigen::Quaterniond q=Eigen::Quaterniond( rotationVector );\n    cout<<\"rotation quaternion \\n\"<<q.coeffs()<<endl;\n\n    //3.rotaion vector to eulerAngles\n    Eigen::Vector3d eulerAngle=rotationVector.matrix().eulerAngles(0,1,2);\n    cout<<\"eulerAngle roll pitch yaw\\n\"<<180*eulerAngle/M_PI<<endl;\n    return 0;\n}\n```\n\n将宿主机上的两个文件拷贝至容器中的install_test里进行测试：\n\n```\ndocker cp CMakeLists.txt pytorch1.1-gpu:/home/eigen-3.3.5/install_test\ndocker cp main.cpp  pytorch1.1-gpu:/home/eigen-3.3.5/install_test\n```\n\n测试：\n\n```\ncd install_test\ncmake  .\nmake\n./useEigen\n```\n\n若显示结果如下，则说明测试成功。\n\n```\nrotationMatrix \n 0.707107 -0.707107         0\n 0.707107  0.707107         0\n        0         0         1\nrotation quaternion \n       0\n       0\n0.382683\n 0.92388\neulerAngle roll pitch yaw\n-0\n 0\n45\n```\n\n## 10.安装tensorflow\n\n- tensorflow与cuda的版本对应关系\n\n![](https://i.loli.net/2021/05/21/PEoKmlhbcXisCWt.png)\n\n安装命令：\n\n```\npip install tensorflow-gpu==2.0 -i http://pypi.douban.com/simple --trusted-host pypi.douban.com\n```\n\n","tags":["深度学习","docker","Ubuntu"],"categories":["docker"]},{"title":"Ubuntu16-04-LTS：anaconda3安装","slug":"ubuntu16_04_LTS_anaconda3安装","url":"/2022/11/23/ubuntu16-04-lts-anaconda3-an-zhuang/","content":"\n# 1. 下载清华源镜像文件 #\n网址：[https://mirrors.tuna.tsinghua.edu.cn/anaconda/archive/](https://mirrors.tuna.tsinghua.edu.cn/anaconda/archive/)\n\n版本：建议安装Anaconda3-5.2.0-Linux-x86_64.sh\n\n# 2. 进入下载目录执行以下命令进行安装 #\n\n```cpp\nbash Anaconda3-5.2.0-Linux-x86_64.sh\n```\n![](https://i.loli.net/2021/05/16/9curYTMUWmveogb.png)\n\n- 一路按回车至底部，出现提示：是否接受安装协议时：回复yes:\n\n![](https://i.loli.net/2021/05/16/JU2iRojd3vH4fsY.png)\n\n- 默认的路径为/home/username/anaconda3，默认的话直接按ENTER即可，等待安装过程完成即可。\n\n![](https://i.loli.net/2021/05/16/iVDa14zUNREPYKs.png)\n\n- 询问是否将Anaconda3加入到环境变量中，选：yes\n\n![](https://i.loli.net/2021/05/16/DBj5P8VMTzgYu2s.png)\n\n- 默认的话直接按ENTER即可，等待安装过程完成即可。  \n\n# 3.检查是否安装成功 #\n\n  \n\n  使用以下命令可以查看已经存在的conda虚拟环境\n\n  ```cpp\n  conda env list\n  ```\n\n  使用以下命令可以查看conda的路径是否添加成功\n\n  ```cpp\n  sudo gedit ~/.bashrc\n  ```\n\n  使其立即生效，在终端执行：\n\n  ```cpp\n  source ~/.bashrc\n  ```\n\n  **4.进入任意一个创建的虚拟环境里面检查python**\n\n  在虚拟环境中输入以下命令：\n\n  ```cpp\n  python\n  ```\n\n  会出现类似以下含有anaconda的字样：\n\n  ```cpp\n  Python 3.6.5 |Anaconda, Inc.| (default, Apr 29 2018, 16:14:56) \n  [GCC 7.2.0] on linux\n  Type \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n  ```\n\n  如果没有出现以下字样，说明系统的python版本需要指定，使用以下命令：\n\n  ```cpp\n  sudo gedit ~/.bashrc\n  ```\n\n  在bashrc中添加一行：\n\n  ```cpp\n  alias python=python3\n  ```\n\n  (注意这里的python3是和安装的anaconda3对应的默认pyrhon对应的，可以在conda虚拟环境中的base环境中查看对应的python版本)\n\n  然后激活bashrc\n\n  ```\n  source ~/.bashrc\n  ```\n\n  这样就可以使用conda创建的虚拟环境对应的python。\n\n","tags":["ubuntu","深度学习","anaconda"],"categories":["深度学习"]},{"title":"Ubuntu16-04手动安装英伟达显卡驱动","slug":"ubuntu16_04手动安装英伟达显卡驱动","url":"/2022/11/23/ubuntu16-04-shou-dong-an-zhuang-ying-wei-da-xian-qia-qu-dong/","content":"\n## 1.屏蔽开源驱动\n\n屏蔽开源驱动nouveau安装过程会询问是否屏蔽，手动屏蔽也有多种操作方式，可以使用如下方法：\n\n```bash\nsudo gedit /etc/modprobe.d/blacklist.conf\n```\n\n然后添加内容到最底段，要回车另起一行。添加的内容为：\n\n```bash\nblacklist nouveau \noptions nouveau modeset=0\n```\n\n保存再终端更新内核命令：\n\n```bash\nsudo update-initramfs -u\n```\n\n可能会出现如下警告，忽略即可：\n\n<img src=\"https://i.loli.net/2021/06/22/lkPBpOvA3MIsfXq.png\" style=\"zoom:50%;\" />\n\n## 2.下载驱动\n\n然后，重启电脑。下载NVIDIA的驱动形如：NVIDIA-Linux-x86_64-384.run 下载网址为：https://www.geforce.cn/drivers。\n\n在win10下的设备管理器中可以查看显卡的型号。型号为：NVIDIA GeForce GTX 1050 Ti电脑类型为：笔记本\n\n所以手动搜索驱动程序时，应该这样选择：\n\n![](https://i.loli.net/2021/06/22/S69TiRpgEc3ydPk.png)\n\n选择第一个驱动版本一般可以安装成功的，但不同电脑可能结果不同，安装失败的话还需要更换版本尝试安装。\n\n下好的\".run\"文件放在home ，目录下，最好将文件名称该为简单点的。\n\n## 3.进入root的命令行模型\n\n安装驱动重启电脑，进入ubuntu高级模式，然后选择下图中的 root 选项：\n\n<img src=\"https://i.loli.net/2021/06/22/rnKMFl81T4giEUf.png\" style=\"zoom:50%;\" />\n\n然后按\"回车”：\n\n<img src=\"https://i.loli.net/2021/06/22/I1ZeWDCaTcEx5X2.png\" style=\"zoom:50%;\" />\n\n## 4.安装驱动\n\n然后，按\"回车”，进入系统目录。安装驱动程序，执行如下命令：\n\n```bash\ncd /home/用户名\n```\n\n关闭当前图形环境\n\n```bash\nsudo service lightdm stop\n```\n\n因为之前的后缀为\".run”的驱动文件放在home目录下，所以， 到驱动所在文件夹后 执行如下命令修改权限并运行：\n\n```bash\nsudo chmod a+x NVIDIA-Linux-x86_64-xxx.run \nsudo sh NVIDIA-Linux-x86_64-xxx.run -no-opengl-files\n```\n\n然后剩余步骤均为默认即可，直接回车执行下一步。\n\n- 提示\"dkms\"安装时，需要安装。\n- 会提示有\"32\"字样，选择\"OK\"继续即可。\n\n最后重新启动图形环境：\n\n```bash\nsudo service lightdm start\n```\n\n## 5.查看是否安装成功\n\n检查安装是否成功并重启电脑，正常进入系统。\n\n如果出现循环输入登录密码但是无法登录成功的情况，则为驱动版本和自己的电脑不匹配，需要下载其他显卡驱动版本尝试。\n\n进一步检查，打开终端输入如下命令：\n\n```bash\nnvidia-smi\n```\n\n出现如下所示信息，即为安装成功:\n\n<img src=\"https://i.loli.net/2021/06/22/gZB9FKjSl2T8wGV.png\" style=\"zoom:50%;\" />\n","tags":["ubuntu","显卡驱动安装"],"categories":["ubuntu"]},{"title":"win10与ubuntu16-04-LTS双系统安装教程","slug":"win10与ubuntu16_04_LTS双系统安装教程","url":"/2022/11/23/win10-yu-ubuntu16-04-lts-shuang-xi-tong-an-zhuang-jiao-cheng/","content":"\n## 1.创建空闲分区\n\n在win系统下，在\"此电脑\"→右键”管理“→“磁盘管理”→右键一个不用的磁盘并”格式化“→”删除卷“，分出一个状态为“未分配”的磁盘用于安装ubuntu16.04 LTS\n\n## 2.开始安装\n\n插入具有ubuntu16.04 LTS系统的U盘开始安装系统\n\n- 选择系统语言，可以是中文或英文。如需要安装tensflow的话建议安装英文版本\n- 选择安装类型为其它选项\n\n<img src=\"https://i.loli.net/2021/06/22/9FEvKkQmATYq7Ip.jpg\" style=\"zoom: 67%;\" />\n\n## 3.双击空闲盘进行分区\n\n### 3.1   /boot分区\n\n/boot：这个就是实现你双系统的原因了，这个就是用于启动 ubuntu 的目录，里面会有系统的引导，这个文件其实只有几十兆，但是我们建议将其划分为 200M 文件格式为 ext4，这个分区必不可少，否则后果你懂得！\n\n### 3.2   swap分区\n\nswap:这个是 Linux 也就是 ubuntu 的交换区目录，这个一般的大小为内存的 2 倍左右， 主要是用来在电脑内存不足的情况下，系统会调用这片区域，来运行程序，我们可以将其分为 4G， 这个把ext4换成交换空间，英文swap\n\n### 3.3    /分区\n\n/:这是 linux 也就是 ubuntu 的根目录就一个反斜杠表示，相当于windows的C盘， 我们将其分为 10G，文件格式为 ext4，条件允许可以大一点，可以20G，毕竟ubuntu装软件默认是装在这里的，大一点可能会省去后面隐藏的麻烦。\n\n### 3.4   /home分区\n\n/home:这是 ubuntu 的“其他盘”， 这个也可以说是我们的个人目录，相当于windows的其他盘，所以为了让我们自己的目录大一点，剩下的全分给它，文件格式为 ext4\n\n\n\n<img src=\"https://i.loli.net/2021/06/22/IZixlEy6FC8vRKn.png\" style=\"zoom: 67%;\" />\n\n以上两步新建分区后的类似效果：\n\n<img src=\"https://i.loli.net/2021/06/22/KxGUtJWhYPMRS3p.png\" style=\"zoom:67%;\" />\n\n## 4.选择安装启动引导的设备\n\n安装启动引导的设备：windows boot manager\n\n<img src=\"https://i.loli.net/2021/06/22/v2JbClS7IwjU46a.png\" style=\"zoom:50%;\" />\n\n## 5.自动安装\n\n<img src=\"https://i.loli.net/2021/06/22/oMECN25eyXsIAKS.jpg\" style=\"zoom: 50%;\" />\n\n<img src=\"https://i.loli.net/2021/06/22/T7CP1BcVWb9wxIR.jpg\" style=\"zoom:50%;\" />\n\n安装完成后可能显示画面模糊，这是因为没有安装显卡驱动，可以按照教程\"Ubuntu16.04手动安装英伟达显卡驱动\"安装即可\n\n","tags":["ubuntu","windows"],"categories":["ubuntu"]},{"title":"手眼标定-Ros-Kinetic-Realsense-D435-AUBOi5-Ubuntu-16-04","slug":"手眼标定_Ros_Kinetic_Realsense_D435_AUBOi5_Ubuntu_16_04","url":"/2022/11/23/shou-yan-biao-ding-ros-kinetic-realsense-d435-auboi5-ubuntu-16-04/","content":"\n## 1.安装AUBOi5的Moveit功能包\n\n### 1.1环境配置\n\n下载Move-it package\n\n```bash\nsudo apt-get install ros-kinetic-moveit\n```\n\n下载moveit_visual_tools\n\n```bash\nsudo apt-get install ros-kinetic-moveit-visual-tools\n```\n\n下载industrial_core package\n\n```bash\nsudo apt-get install ros-kinetic-industrial-core\n```\n\n### 1.2建立ROS工作空间\n\n```bash\nsource /opt/ros/kinetic/setup.bash\n\n# catkin_ws为工作空间名称\nmkdir -p ~/catkin_ws/src\ncd ~/catkin_ws/\ncatkin_make\n```\n\n### 1.2 在  ~/catkin_ws/src  目录中下载Moveit功能包，并编译\n\n```bash\ncd ~/catkin_ws/src\ngit clone https://github.com/lg609/aubo_robot.git\ncd ~/catkin_ws/\ncatkin_make\nsource ~/catkin_ws/devel/setup.bash\n```\n\n注释：如果提示下列错误，则说明在安装Ros的时候没有安装Ros-moveit功能包：\n\n![](https://i.loli.net/2021/05/28/jShBMoz9apcKVXE.png)\n\n解决办法：\n\n```bash\nsudo apt-get install ros-kinetic-moveit*\n```\n\n注：参考网址：[点我查看](https://github.com/tahsinkose/hector-moveit/issues/4)\n\n## 2.安装Realsense D435相机驱动与功能包\n\n### 2.1驱动安装\n\n官方安装教程：[点我查看](https://github.com/IntelRealSense/librealsense/blob/master/doc/distribution_linux.md)\n\n参考教程：[点我查看](https://zhuanlan.zhihu.com/p/93127918)\n\n注册公匙：\n\n```bash\nsudo apt-key adv --keyserver keys.gnupg.net --recv-key F6E65AC044F831AC80A06380C8B3A55A6F3EFCDE || sudo apt-key adv --keyserver hkp://keyserver.ubuntu.com:80 --recv-key F6E65AC044F831AC80A06380C8B3A55A6F3EFCDE\n```\n\n添加服务器至存储列表：\n\n```bash\nsudo add-apt-repository \"deb https://librealsense.intel.com/Debian/apt-repo xenial main\" -u\n```\n\n安装所需库：\n\n```bash\nsudo apt-get install librealsense2-dkms\nsudo apt-get install librealsense2-utils\n```\n\n安装功能包：\n\n```bash\nsudo apt-get install librealsense2-dev\nsudo apt-get install librealsense2-dbg\n```\n\n启动连接界面，进行测试，若可以看到相机图像则证明驱动安装成功：\n\n```bash\nrealsense-viewer\n```\n\n### 2.2功能包安装\n\n创建工作空间：\n\n```bash\nmkdir -p ~/catkin_ws/src && cd ~/catkin_ws/src\n```\n\n下载源码，并检查依赖:\n\n```bash\ngit clone -b 2.2.7 https://github.com/IntelRealSense/realsense-ros.git \ncd realsense-ros/realsense2_camera git checkout `git tag | sort -V | grep -P \"^\\d+\\.\\d+\\.\\d+\" | tail -1`\nsudo apt-get install ros-kinetic-ddynamic-reconfigure\n```\n\n编译：\n\n```bash\ncd ~/catkin_ws\ncatkin_make -DCATKIN_ENABLE_TESTING=False -DCMAKE_BUILD_TYPE=Release \ncatkin_make install \necho \"source ~/catkin_ws/devel/setup.bash\" >> ~/.bashrc \nsource ~/.bashrc\n```\n\n测试，启动相机节点：\n\n```bash\nroslaunch realsense2_camera rs_camera.launch\n\n# 查看发布的话题\nrostopic list\n```\n\n## 3.安装ros-kinetic-visp依赖包\n\n```bash\nsudo apt-get install ros-kinetic-visp\n```\n\n## 4.安装aruco_ros二维码检测功能包\n\n```bash\ncd ~/catkin_ws/src\ngit clone -b kinetic-devel https://github.com/pal-robotics/aruco_ros.git\ncd ..\ncatkin_make\nsource ~/catkin_ws/devel/setup.bash\n```\n\n## 5.安装visp_hand2eye_calibration\n\n```bash\ncd ~/catkin_ws/src\ngit clone -b kinetic-devel https://github.com/lagadic/vision_visp.git\ncd ..\ncatkin_make --pkg visp_hand2eye_calibration\nsource ~/catkin_ws/devel/setup.bash\n```\n\n## 6.安装easy_handeye手眼标定功能包\n\n```bash\ncd ~/catkin_ws/src\ngit clone https://github.com/IFL-CAMP/easy_handeye\ncd ..\ncatkin_make\nsource ~/catkin_ws/devel/setup.bash\n```\n\n## 7.标定方法\n\n### 7.1眼在手上 eye-in-hand标定方法\n\n#### 7.1.1修改launch文件\n\n标定过程需启动 ur5 机械臂的相关节点，realsense 节点，aruco 节点，easy_handeye 节点，可以写一个 launch 文件同时启动上述节点，也可以分别启动。easy_handeye 包中给出了用一个 launch 文件实现的示例，在如下的目录中：\n\n```bash\ncd ~/catkin_ws/src/easy_handeye/docs/example_launch/ur5_kinect_calibration.launch\n```\n\n我们可以在此基础上进行修改。\n\n```bash\n# 将 launch 文件拷贝到 easy_handeye 功能包的 launch 目录中，顺便改个名字\ncd ~/catkin_ws/src/easy_handeye/docs/example_launch\ncp ur5_kinect_calibration.launch ~/catkin_ws/src/easy_handeye/easy_handeye/launch/eye_in_hand_calibration.launch\ngedit  ~/catkin_ws/src/easy_handeye/easy_handeye/launch/eye_in_hand_calibration.launch\n```\n\n修改 launch 文件如下：\n\n```html\n<launch>\n    <arg name=\"namespace_prefix\" default=\"aubo_i5_kinect_handeyecalibration\" />\n\n\t<!-- 169.254.3.20为AUBOi5机械臂的IP地址,根据实际情况修改 -->\n    <arg name=\"robot_ip\" doc=\"The IP address of the UR5 robot\" default=\"169.254.3.20\"/>\n\n\t\n    <arg name=\"marker_size\" doc=\"Size of the ArUco marker used, in meters\" default=\"0.1\" />\n    <arg name=\"marker_id\" doc=\"The ID of the ArUco marker used\" default=\"100\"/>\n\n\n    <!-- 1. start the Realsense435 -->\n    <include file=\"$(find realsense2_camera)/launch/rs_camera.launch\" />\n\n\n    <!-- 2. start ArUco -->\n    <node name=\"aruco_tracker\" pkg=\"aruco_ros\" type=\"single\">\n        <remap from=\"/camera_info\" to=\"/camera/color/camera_info\" />\n        <remap from=\"/image\" to=\"/camera/color/image_raw\" />\n        <param name=\"image_is_rectified\" value=\"true\"/>\n        <param name=\"marker_size\"        value=\"$(arg marker_size)\"/>\n        <param name=\"marker_id\"          value=\"$(arg marker_id)\"/>\n        <param name=\"reference_frame\"    value=\"camera_color_frame\"/>\n        <param name=\"camera_frame\"       value=\"camera_color_frame\"/>\n        <param name=\"marker_frame\"       value=\"camera_marker\" />\n    </node>\n\n\n    <!-- 3. start the robot -->\n    <include file=\"$(find aubo_i5_moveit_config)/launch/moveit_planning_execution.launch\">\n    </include>\n\n\n    <!-- 4. start easy_handeye -->\n    <include file=\"$(find easy_handeye)/launch/calibrate.launch\" >\n        <arg name=\"namespace_prefix\" value=\"$(arg namespace_prefix)\" />\n        <!-- true：相机安装在机械臂末端 false: 相机安装在机械臂外-->\n        <arg name=\"eye_on_hand\" value=\"true\" />\n\n\t\t<!-- tracking_base_frame 为相机坐标系 camera_color_frame -->\n        <arg name=\"tracking_base_frame\" value=\"camera_color_frame\" />\n        <arg name=\"tracking_marker_frame\" value=\"camera_marker\" />\n        <!-- robot_base_frame 为机器人基座坐标系 -->\n        <arg name=\"robot_base_frame\" value=\"base_link\" />\n        <!-- robot_effector_frame 为工具坐标系，即：与相机相连的关节名称 -->\n        <arg name=\"robot_effector_frame\" value=\"wrist3_Link\" />\n\n\n        <arg name=\"freehand_robot_movement\" value=\"false\" />\n        <arg name=\"robot_velocity_scaling\" value=\"0.5\" />\n        <arg name=\"robot_acceleration_scaling\" value=\"0.2\" />\n        \n        <arg name=\"move_group\" value=\"manipulator_i5\" />\n\n\n    </include>\n\n\n</launch>\n```\n\n#### 7.1.2启动 launch 文件，开始标定\n\n启动 launch 文件：\n\n```bash\nroslaunch easy_handeye eye_to_hand_calibration.launch\n```\n\n成功运行后，会同时打开三个界面：\n\n<img src=\"https://i.loli.net/2021/05/28/4Xmzb3hFrnd5R7c.jpg\" alt=\"界面1\" style=\"zoom:50%;\" />\n\n<img src=\"https://i.loli.net/2021/05/28/Av7F6K9Gu8pfZs3.jpg\"  alt=\"界面2\" style=\"zoom: 67%;\" />\n\n![界面3](https://i.loli.net/2021/05/28/2ydewHu76InBqfs.jpg)\n\n在界面 2 中，点击菜单栏(菜单栏在屏幕左上角)的 Plugins -> Visulization -> Image View，选择 /aruco_tracker/result 话题，界面会如下所示：\n\n<img src=\"https://i.loli.net/2021/05/28/YTKPw46HouZGpk9.jpg\" style=\"zoom: 50%;\" />\n\n#### 7.1.3标定步骤\n\n1. 手动调节机械臂，使 aruco 二维码移动至相机视野中心处附近，作为 home config。在界面 3 中，点击 check starting pose，若检查成功，界面会出现： 0/17，ready to start\n2. 界面 3 中依次点击 Next Pose，Plan，Execute，机械臂会移动至新的位置，若二维码在相机视野范围内，且能检测成功，则进行下一步\n3. 界面 2 中点击 Take Sample，若 Samples 对话框中出现有效信息，说明第一个点标定成功\n4. 重复执行步骤 2 和步骤 3，直至 17 个点全部标定完毕\n5. 界面 2 中点击 Compute，则 Result 对话框中会出现结果\n6. 界面 2 中 Save，会将结果保存为一个 YAML 文件，路径为 `~/.ros/easy_handeye`\n\n![](https://i.loli.net/2021/05/28/gV9AWphbyU5mFlP.jpg)\n\n### 7.2眼在手外 eye-to-hand标定方法\n\n方法与“眼在手上”基本相同，需要修改一下 launch 文件，注意两个 launch 文件不要重名。\n\n唯一修改的地方是 easy_handeye 功能包 calibrate.launch 文件中 \"eye_on_hand\" 参数改成 true，如下所示\n\n```bash\n# 将 launch 文件拷贝到 easy_handeye 功能包的 launch 目录中，顺便改个名字\ncd ~/catkin_ws/src/easy_handeye/docs/example_launch\ncp ur5_kinect_calibration.launch ~/catkin_ws/src/easy_handeye/easy_handeye/launch/eye_to_hand_calibration.launch\ngedit  ~/catkin_ws/src/easy_handeye/easy_handeye/launch/eye_to_hand_calibration.launch\n```\n\n## 8.将标定结果发送至TF树\n\neasy_handeye 功能包提供了 publish.launch 文件，可以将标定好的 TF 发布出去\n\n### 8.1眼在手上eye-in-hand\n\n修改publish.launch 文件,要修改 \"namespace_prefix\" 参数，与眼在手上标定 launch 文件中的 \"namespace_prefix\" 一致，这样才能找到标定好的 YAML 文件\n\n```html\n<?xml version=\"1.0\"?>\n<launch>\n    <arg name=\"eye_on_hand\" doc=\"eye-on-hand instead of eye-on-base\" default=\"true\"/>\n    <arg name=\"namespace_prefix\" default=\"ur5_realsense_handeyecalibration\" />\n    <arg if=\"$(arg eye_on_hand)\" name=\"namespace\" value=\"$(arg namespace_prefix)_eye_on_hand\" />\n    <arg unless=\"$(arg eye_on_hand)\" name=\"namespace\" value=\"$(arg namespace_prefix)_eye_on_base\" />\n\n    <!--it is possible to override the link names saved in the yaml file in case of name clashes, for example-->\n    <arg if=\"$(arg eye_on_hand)\" name=\"robot_effector_frame\" default=\"\" />\n    <arg unless=\"$(arg eye_on_hand)\" name=\"robot_base_frame\" default=\"\" />\n    <arg name=\"tracking_base_frame\" default=\"\" />\n    \n    <arg name=\"inverse\" default=\"false\" />\n    \n    <!--publish hand-eye calibration-->\n    <group ns=\"$(arg namespace)\">\n        <param name=\"eye_on_hand\" value=\"$(arg eye_on_hand)\" />\n        <param unless=\"$(arg eye_on_hand)\" name=\"robot_base_frame\" value=\"$(arg robot_base_frame)\" />\n        <param if=\"$(arg eye_on_hand)\" name=\"robot_effector_frame\" value=\"$(arg robot_effector_frame)\" />\n        <param name=\"tracking_base_frame\" value=\"$(arg tracking_base_frame)\" />\n        <param name=\"inverse\" value=\"$(arg inverse)\" />\n        <node name=\"$(anon handeye_publisher)\" pkg=\"easy_handeye\" type=\"publish.py\" output=\"screen\"/>\n    </group>\n</launch>\n```\n\n### 8.2眼在手外 eye-to-hand\n\n修改 \"namespace_prefix\" 外（同上），还要将 \"eye_on_hand\" 参数设为false\n\n```html\n<?xml version=\"1.0\"?>\n<launch>\n    <arg name=\"eye_on_hand\" doc=\"eye-on-hand instead of eye-on-base\" default=\"false\" />\n    <arg name=\"namespace_prefix\" default=\"ur5_realsense_handeyecalibration\" />\n    <arg if=\"$(arg eye_on_hand)\" name=\"namespace\" value=\"$(arg namespace_prefix)_eye_on_hand\" />\n    <arg unless=\"$(arg eye_on_hand)\" name=\"namespace\" value=\"$(arg namespace_prefix)_eye_on_base\" />\n\n    <!--it is possible to override the link names saved in the yaml file in case of name clashes, for example-->\n    <arg if=\"$(arg eye_on_hand)\" name=\"robot_effector_frame\" default=\"\" />\n    <arg unless=\"$(arg eye_on_hand)\" name=\"robot_base_frame\" default=\"\" />\n    <arg name=\"tracking_base_frame\" default=\"\" />\n    \n    <arg name=\"inverse\" default=\"false\" />\n    \n    <!--publish hand-eye calibration-->\n    <group ns=\"$(arg namespace)\">\n        <param name=\"eye_on_hand\" value=\"$(arg eye_on_hand)\" />\n        <param unless=\"$(arg eye_on_hand)\" name=\"robot_base_frame\" value=\"$(arg robot_base_frame)\" />\n        <param if=\"$(arg eye_on_hand)\" name=\"robot_effector_frame\" value=\"$(arg robot_effector_frame)\" />\n        <param name=\"tracking_base_frame\" value=\"$(arg tracking_base_frame)\" />\n        <param name=\"inverse\" value=\"$(arg inverse)\" />\n        <node name=\"$(anon handeye_publisher)\" pkg=\"easy_handeye\" type=\"publish.py\" output=\"screen\"/>\n    </group>\n</launch>\n```\n\n## 9.测试\n\n```bash\n# 开启 publish.luanch 文件，以眼在手上为例\nroslaunch easy_handeye publish.launch\n\n# 查看 TF（改成自己的工具坐标系与相机坐标系）\nrosrun tf tf_echo /tool0_controller /camera_color_frame\n```\n\n![](https://i.loli.net/2021/05/28/BgCzvN85MxAsUJV.jpg)\n\n注意：这里四元数的顺序是 [qx, qy, qz, qw]\n","tags":["手眼标定","AUBOi5","Realsense"],"categories":["机器人"]},{"title":"Pycharm使用ssh连接服务器中的docker容器","slug":"Pycharm使用ssh连接服务器中的docker容器","url":"/2022/11/23/pycharm-shi-yong-ssh-lian-jie-fu-wu-qi-zhong-de-docker-rong-qi/","content":"\n## 1.拉取cuda、cudnn的docker镜像\n\n```bash\ndocker pull nvidia/cuda:10.0-cudnn7-devel-ubuntu16.04\n```\n\n## 2.新建并启动交互式容器\n\n```bash\ndocker run -it --name tensorflow1.2.1-gpu -v /home/docker_share/:/home/ -p 2201:22 --gpus all nvidia/cuda:10.0-cudnn7-devel-ubuntu16.04 /bin/bash\n```\n\n解释：\n\n--name ：设置新容器的名称为tensorflow1.2.1-gpu\n\n-v ：设置文件映射，将宿主机的文件/home/docker_share/映射到该容器的/home/目录下\n\n-p ：设置容器的端口与宿主机的端口映射，格式为：**主机(宿主)端口:容器端口**\n\n--gpus all 许容器使用所有GPU\n\nnvidia/cuda:10.0-cudnn7-devel-ubuntu16.04：容器的依赖镜像\n\n/bin/bash：指定在容器内部运行的进程，该进程是通过docker container run命令来通知容器运行的\n\n注释：\n\n为了构建有序且规范的端口映射关系，这里设置一个默认规则用于设置容器的端口与宿主机的端口映射：主机端口固定，容器端口以主机端口为起始位依次排开\n\n```\n容器端口\t主机端口\n2201\t\t22\n2202\t\t22\n```\n\n\n\n## 3.进入容器后修改容器的root密码\n\n```bash\n# 设置用户名为root,密码为passwd(将其该为自己想要的密码)\necho 'root:passwd' | chpasswd\n```\n\n## 4.安装openssh-server并启动\n\n```bash\n#更新源\napt-get update\n#或\napt-get -y update\n# 安装openssh-server\napt-get install openssh-server\n# 启动之前需手动创建/var/run/sshd，不然启动sshd的时候会报错\nmkdir -p /var/run/sshd\n# sshd以守护进程运行\n/usr/sbin/sshd -D &\n# 安装netstat，查看sshd是否监听22端口\napt-get install net-tools\nnetstat -apn | grep ssh\n# 显示如下\n# root@a78aa2e72670:/# netstat -apn | grep ssh\n# tcp        0      0 0.0.0.0:22              0.0.0.0:*               LISTEN      1266/sshd\n# tcp6       0      0 :::22                   :::*                    LISTEN      1266/sshd\n```\n\n## 5.ssh登录设置\n\n```bash\n# 生成ssh key\nssh-keygen -t rsa \n# 然后提示的设置用默认设置，一直回车即可\n# 修改sshd-config允许root登陆\nvim /etc/ssh/sshd_config\n```\n\n检查下面的命令是否被注释，会后面的参数是否为yes，若没有该命令需要在文件尾部新增该命令以允许root用户使用ssh登录：\n\n```bash\nPermitRootLogin yes # 约在28行：将PermitRootLogin prohibit-password改为PermitRootLogin yes\n```\n\n修改完sshd-config之后需要重启sshd服务:\n\n```bash\n# 找到sshd的进程pid\nps -aux | grep ssh\n# 杀掉sshd的进程pid\nkill -9 sshd的进程pid号\n# 重启\n/usr/sbin/sshd -D &\n# 再次查看\nps -aux | grep ssh\n```\n\n示例:\n\n```bash\nroot@a78aa2e72670:/# ps -aux | grep ssh\nroot      1266  0.0  0.0  65512  5468 pts/0    S    01:14   0:00 /usr/sbin/sshd -D\nroot      1301  0.0  0.0  11284   932 pts/0    S+   01:18   0:00 grep --color=auto ssh\nroot@a78aa2e72670:/# kill -9 1266\nroot@a78aa2e72670:/# /usr/sbin/sshd -D &\n[2] 1302\n[1]   Killed                  /usr/sbin/sshd -D\nroot@a78aa2e72670:/# ps -aux | grep ssh\nroot      1302  0.0  0.0  65512  5756 pts/0    S    01:19   0:00 /usr/sbin/sshd -D\nroot      1304  0.0  0.0  11284   944 pts/0    S+   01:19   0:00 grep --color=auto ssh\n```\n\n\n\n## 6.退出容器，但不要停止容器，并进行连接测试\n\n```bash\n# 在主机登录，需要输入的root密码为前面设置的root密码\nssh root@localhost -p 8080 # 8080为刚开始创建容器时候设置的主机端口映射，与容器的22端口形成映射\n# 在其他机器上可以使用以下命令登陆，假设宿主机ip为10.12.11.xx\nssh root@10.12.11.xx -p 8080\n```\n\n这里如果提示：ssh_exchange_identification: read: Connection reset by peer\n\n则：可能是容器的 sshd服务未开启，再次进入容器重启sshd服务即可：\n\n```bash\n /usr/sbin/sshd -D &\n```\n\n示例：\n\n```bash\nroot@dc627a3adc4d:/# ps -aux | grep ssh\nroot        32  0.0  0.0  11284   932 pts/1    S+   03:43   0:00 grep --color=auto ssh\nroot@dc627a3adc4d:/# /usr/sbin/sshd -D &\n[1] 33\nroot@dc627a3adc4d:/# ps -aux | grep ssh\nroot        33  0.0  0.0  65512  5420 pts/1    S    03:43   0:00 /usr/sbin/sshd -D\nroot        35  0.0  0.0  11284   936 pts/1    S+   03:43   0:00 grep --color=auto ssh\n```\n\n注释：配置完成后可以将容器保存为镜像\n\ndocker commit -a \"提交的镜像作者名称\" -m \"提交时的说明文字\" 容器ID或容器名称  保存镜像名称:标签\n\n示例:\n\n```bash\nroot@dc627a3adc4d:/# docker commit -a \"runoob.com\" -m \"my apache\" a404c6c174a2  mymysql:v1\nroot@dc627a3adc4d:/# docker images mymysql:v1\nREPOSITORY          TAG                 IMAGE ID            CREATED             SIZE\nmymysql             v1                  37af1236adef        15 seconds ago      329 MB\n```\n\n\n\n## 7.配置pycharm并连接docker容器\n\n参考网址：[点我查看](https://blog.csdn.net/Thanours/article/details/109265315)\n\n在 Tools >>> Deployment >>> Configuration选项中新建 SFTP 连接：\n\n![](https://i.loli.net/2021/05/21/YMm8PE6Hd9ySQ2h.png)\n\n<img src=\"https://i.loli.net/2021/05/21/z4dMrhtOH8xvZCR.png\"/>\n\n![](https://i.loli.net/2021/06/10/TYq9sIE2aRfdyGC.png)\n\n- 路径映射(本地程序文件目录与docker文件目录的映射)：\n\n\n![](https://i.loli.net/2021/05/21/yigpdXIMG5QTaLw.png)\n\n- 同步本地代码数据到docker容器中：\n\n\n![](https://i.loli.net/2021/05/21/mQJGDp1xaB6EjO9.png)\n\n- 上传完代码数据后， 需要选择设置python编译器：\n\n\n![](https://i.loli.net/2021/05/21/htdvCb2qlnOas1Y.png)\n\n![](https://i.loli.net/2021/05/21/O3yU6kINc9AT8ea.png)\n\n![](https://i.loli.net/2021/05/21/bH5aVPAMXDIz42j.png)\n\n![](https://i.loli.net/2021/06/10/BH7mE9diJMrcWCp.png)\n\n- 设置好python解释器就可以run代码了：\n\n\n![](https://i.loli.net/2021/05/21/jDGmP8npQtaFCY7.png)\n\n这里要注意一下，代码所要的运行环境还需要在docker容器安装配置好，比如我这里需要pytorch环境以及python代码运行所需的依赖库都已经在docker容器中通过pip安装好了。\n","tags":["ubuntu","深度学习","Pycharm","docker"],"categories":["docker"]},{"title":"函数参数传递之引用与指针","slug":"函数参数传递之引用与指针","url":"/2022/11/12/han-shu-can-shu-chuan-di-zhi-yin-yong-yu-zhi-zhen/","content":"# 定义\n\n## 值传递\n**形参是实参的拷贝**，改变形参的值并不会影响外部实参的值。从被调用函数的角度来说，值传递是单向的（实参->形参），参数的值只能传入，不能传出。当函数内部需要修改参数，并且不希望这个改变影响调用者时，采用值传递。\n\n## 指针传递\n**形参为指向实参地址的指针**，当对形参的指向操作时，就相当于对实参本身进行的操作\n\n## 引用传递\n**形参相当于是实参的“别名”**，对形参的操作其实就是对实参的操作，在引用传递过程中，被调函数的形式参数虽然也作为局部变量在栈中开辟了内存空间，但是这时存放的是由主调函数放进来的实参变量的地址。被调函数对形参的任何操作都被处理成间接寻址，即通过栈中存放的地址访问主调函数中的实参变量。正因为如此，被调函数对形参做的任何操作都影响了主调函数中的实参变量。\n\n引用引入了对象的一个同义词。定义引用的表示方法与定义指针相似，只是用“&”代替了“*”。例如：\n```cpp\nPoint pt1(10,10);\nPoint &pt2=pt1; \n```\n定义了pt2为pt1的引用。通过这样的定义，pt1和pt2表示同一对象。需要特别强调的是引用并不产生对象的副本，仅仅是对象的同义词。因此，当下面的语句执行后：\n```cpp\npt1.offset（2，2）；\n```\npt1和pt2都具有（12，12）的值。\n引用必须在定义时马上被初始化，因为它必须是某个东西的同义词。你不能先定义一个引用后才\n初始化它。例如下面语句是非法的：\n```cpp\nPoint &pt3；\npt3=pt1；\n```\n# 引用传递和指针传递的区别与联系\n\n## 引用的规则\n- 引用被创建的同时必须被初始化（指针则可以在任何时候被初始化）。 \n- 不能有NULL引用，引用必须与合法的存储单元关联（指针则可以是NULL）。 \n- 一旦引用被初始化，就不能改变引用的关系（指针则可以随时改变所指的对象）。 \n\n## 相同点\n-都是地址的概念：指针指向一块内存，它的内容是所指内存的地址；而引用则是某块内存的别名。\n\n## 不同点\n- 指针是一个实体，而引用仅是个别名；\n\n- 引用只能在定义时被初始化一次，之后不可变；指针可变；引用“从一而终”，指针可以“见异思迁”；\n\n- 引用没有const，指针有const，const的指针不可变；（具体指没有int& const a这种形式，而const int& a是有 的， 前者指引用本身即别名不可以改变，这是当然的，所以不需要这种形式，后者指引用所指的值不可以改变）\n\n- 引用不能为空，指针可以为空；\n\n- “sizeof 引用”得到的是所指向的变量(对象)的大小，而“sizeof 指针”得到的是指针本身的大小；\n\n- 指针和引用的自增(++)运算意义不一样；\n\n- 引用是类型安全的，而指针不是 (引用比指针多了类型检查\n  \n## 分析\n从概念上讲，**指针从本质上讲就是存放变量地址的一个变量**，在逻辑上是独立的，它可以被改变，包括其所指向的地址的改变和其指向的地址中所存放的数据的改变。\n\n而引用是一个别名，它在逻辑上不是独立的，它的存在具有依附性，所以引用必须在一开始就被初始化，而且其引用的对象在其整个生命周期中是不能被改变的（自始至终只能依附于同一个变量）。\n\n在C++中，指针和引用经常用于函数的参数传递，然而，指针传递参数和引用传递参数是有本质上的不同的：\n\n指针传递参数本质上是值传递的方式，它所传递的是一个地址值。*值传递过程中，被调函数的形式参数作为被调函数的局部变量处理，即在栈中开辟了内存空间以存放由主调函数放进来的实参的值，从而成为了实参的一个副本。值传递的特点是被调函数对形式参数的任何操作都是作为局部变量进行，不会影响主调函数的实参变量的值。（这里是在说实参指针本身的地址值不会变）*\n\n而在引用传递过程中，被调函数的形式参数虽然也作为局部变量在栈中开辟了内存空间，但是这时**存放的是由主调函数放进来的实参变量的地址。被调函数对形参的任何操作都被处理成间接寻址，即通过栈中存放的地址访问主调函数中的实参变量**。正因为如此，被调函数对形参做的任何操作都影响了主调函数中的实参变量。\n\n**引用传递和指针传递是不同的，虽然它们都是在被调函数栈空间上的一个局部变量，但是任何对于引用参数的处理都会通过一个间接寻址的方式操作到主调函数中的相关变量。而对于指针传递的参数，如果改变被调函数中的指针地址，它将影响不到主调函数的相关变量。如果想通过指针参数传递来改变主调函数中的相关变量，那就得使用指向指针的指针，或者指针引用。**\n\n为了进一步加深大家对指针和引用的区别，下面我从编译的角度来阐述它们之间的区别：\n\n程序在编译时分别将指针和引用添加到符号表上，符号表上记录的是变量名及变量所对应地址。指针变量在符号表上对应的地址值为**指针变量的地址值**，指针变量中的值为其指向变量的地址；而引用在符号表上对应的地址值为引用对象的地址值。符号表生成后就不会再改，因此指针可以改变其指向的对象（指针变量中的值可以改），而引用对象则不能修改.\n## 规范\n使用引用传递参数和使用指针传递参数都可传递变量的地址，但对于int,float等占用内存较少，其作为函数参数时一般使用引用传递参数；而对于结构体而言一般采用指针传递结构体变量的地址。\n# 使用示例\n## 传递可变参数\n传统的c中，函数在调用时参数是通过值来传递的，这就是说函数的参数不具备返回值的能力。所以在传统的c中，如果需要函数的参数具有返回值的能力，往往是通过指针来实现的。比如，实现两整数变量值交换的c程序如下：\n```cpp\nvoid swap_int(int *a,int *b)\n{\n    int temp;\n    temp=*a;\n    a=*b;\n    *b=temp;\n}\n```\n使用引用机制后，以上程序的c++版本为：\n```cpp\nvoid swap_int(int &a,int &b)\n{\n    int temp;\n    temp=a;\n    a=b;\n    b=temp;\n}\n```\n调用该函数的c++方法为：\n```cpp\nswap_int,y); \n```\nc++自动把x,y的地址作为参数传递给swap_int函数。\n\n## 给函数传递大型对象\n当大型对象被传递给函数时，使用引用参数可使参数传递效率得到提高，因为引用并不产生对象的副本，也就是参数传递时，对象无须复制。下面的例子定义了一个有限整数集合的类：\n```cpp\nconst maxCard=100;\nClass Set\n{\n    int elems[maxCard]; // 集和中的元素，maxCard 表示集合中元素个数的最大值。\n    int card; // 集合中元素的个数。\n    public:\n    Set () {card=0;} //构造函数\n    friend Set operator * (Set ,Set ) ; //重载运算符号*，用于计算集合的交集 用对象作为传值参数\n    // friend Set operator * (Set & ,Set & ) 重载运算符号*，用于计算集合的交集 用对象的引用作为传值参数\n    ...\n}\n```\n先考虑集合交集的实现\n```cpp\nSet operator *( Set Set1,Set Set2)\n{\n    Set res;\n    for(int i=0;i<Set1.card;++i)\n    {\n        for(int j=0;j>Set2.card;++j)\n        {\n            if(Set1.elems[i]==Set2.elems[j])\n                {\n                    res.elems[res.card++]=Set1.elems[i];\n                    break;\n                }\n        }\n        \n    }\n    return res;\n}\n```\n由于重载运算符不能对指针单独操作，我们必须把运算数声明为 Set 类型而不是 Set * 。每次使用*做交集运算时，整个集合都被复制，这样效率很低。我们可以用引用来避免这种情况。\n```cpp\nSet operator *( Set &Set1,Set &Set2)\n{ \n    Set res;\n    for(int i=0;i<Set1.card;++i)\n    {\n        for(int j=0;j>Set2.card;++j){\n            if(Set1.elems[i]==Set2.elems[j])\n            {\n                res.elems[res.card++]=Set1.elems[i];\n                break;\n            }\n        }\n            \n    }\n    \n    return res;\n}\n```\n## 引用返回值\n\n如果一个函数返回了引用，那么该函数的调用也可以被赋值。这里有一函数，它拥有两个引用参数并返回一个双精度数的引用：\n```cpp\ndouble &max(double &d1,double &d2)\n{\n    return d1>d2?d1:d2;\n}\n```\n由于max()函数返回一个对双精度数的引用，那么我们就可以用max() 来对其中较大的双精度数加1：\n```cpp\nmax(x,y)+=1.0;\n```\n\n# 二级指针\n\n## 引入\n\n在函数的使用过程中，我们都明白传指针和传引用会使实参的值发生改变。那么能够通过传指针改变指针所指向的地址吗？\n在解决这个问题之前，也许我们应该先了解指针非常容易混淆的三个属性：\n- 指针变量地址（&p）\n- 指针变量指向的地址（p，存储数据的地址）\n- 指针变量指向的地址的值（*p）\n  \n当我们将指针变量与其它变量比较之后就会发现，指针变量同其它变量是相似的，只是多了最后一种操作。比如一个int类型的变量,```int x=5;```,```&x```取出存储```5```这个数据的地址，同样，```&p```也是存储指针的地址，```p```就是这个地址里面保存的值，也就是指向的地址。只是与其它变量不同的是，它除了这两种操作之外，还有一个解引用操作符```*p```去获取指针变量指向的地址里面保存的值。\n\n## 指针引用\n```cpp\nvoid make(int *pp)\n{\n    pp=new int(66); //试图改变p指向的地址\n}\nint main()\n{\n     int a=5;\n     int *p=&a; //指针变量指向一个int类型的地址\n     cout<<\"address:\"<<&a<<\"value:\"<<a<<endl;\n     cout<<\"address:\"<<p<<\"value:\"<<*p<<endl;\n     make(p);\n     cout<<\"address:\"<<p<<\"value:\"<<*p<<endl;\n}\n```\n运行结果如下：我们这里虽然使用的是传指针，但是却不是直接改变指针变量指向的地址的值，却是想通过改变指针变量指向的地址来修改它的值，显然这样失败了。\n\n![](https://cdn.jsdelivr.net/gh/geiyiren/MyBlogImage1/函数参数传递之引用与指针/no.png)\n\n如果我们希望在函数里面修改指针变量存储的地址而不是它的值，这个时候就需要指针引用了。类似于普通变量传入变量引用，我们也传入一个指针引用，在函数里面，你可以将pp认为和p都是这个指针变量（&p==&pp），不似传入指针参数的时候形参和实参的变量（&p！=&pp）地址不一样。此时我们操作pp的值就是更改了p的值。\n```cpp\nvoid make(int *&pp)\n{\n    pp=new int(66); //改变p指向的地址\n}\n```\n运行结果如下：当我们修改传入参数为指针的引用的时候就可以修改指针变量所指向的地址了，可以看见，传入指针引用可以修改指针变量的值（p）和指向的值（*p）。\n\n![](https://cdn.jsdelivr.net/gh/geiyiren/MyBlogImage1/函数参数传递之引用与指针/yes.png)\n\n## 二级指针\n指向指针的指针变量称为二级指针。\n如果pp是一个二级指针，那么有如下属性：\n- 二级指针的地址（&pp）\n- 二级指针的地址保存的地址（pp）\n- 二级指针的地址保存的地址，该地址里面保存的地址（*pp）\n- 二级指针的地址保存的地址，该地址里面保存的地址里面的数据（**pp）\n\n![](https://cdn.jsdelivr.net/gh/geiyiren/MyBlogImage1/函数参数传递之引用与指针/kuangtu.png) \n\n除了上面传入指针引用改变一级指针指向的地址以外，我们还可以通过传入一个二级指针去修改它对应的一级指针指向的地址，同样达到了修改指针变量的效果。二级指针的指向的地址存储的值就是一级指针指向的地址。对一级指针变量解引用得到的是指针指向的地址存储的数据，二级指针变量解引用得到的也是该二级指针指向的地址存储的地址值。\n\n```cpp\nvoid make(int **pp)\n{\n   int * p=new int(66);\n    *pp=p; //二级指针的解引用被赋值需要得到一个一级指针变量，上图中二级指针的示意图中*pp=p\n}\nint main()\n{\n     int a=5;\n     int *q=&a;\n     int **pp=&q;\n     cout<<\"address:\"<<&pp<<\"  \"<<pp<<\"    \"<<&q<<\"   \"<<q<<\"       value:\"<<*q<<endl;\n     make(pp);\n     cout<<\"address:\"<<&pp<<\"  \"<<pp<<\"    \"<<&q<<\"   \"<<q<<\"       value:\"<<*q<<endl;\n}\n```\n\n运行结果如下：通过对二级指针的解引用赋值成功修改了一级指针指向的地址。如果仅仅在make函数里面对**pp=66;操作，那么所有的地址不会改变，仅仅会改变值为66。\n\n![](https://cdn.jsdelivr.net/gh/geiyiren/MyBlogImage1/函数参数传递之引用与指针/yes2.png)\n\n# 各种类型的函数参数传递\n## 声明.h\n```C ++\n// 结构体数组   (in_ldc)\nvoid getLdc(TLensDistortionCorrection (&in_ldc)[NUM_CAMERAS]);\n// cv::Mat  (in_MatK)\nvoid getMatK(cv::Mat *in_MatK);\n// 内存块(map)  (in_BEMap)\nvoid getBEMap(unsigned short *&in_BEMap);\n// cv::Rect数组 (in_BESetRoi)\nvoid getBESetRoi(cv::Rect *in_BESetRoi);\n// cv::Mat 数组 (in_wide_angle_map)\nvoid getWideAngleMap(float **in_wide_angle_map);\n// 整数 (in_wide_angle_width,in_wide_angle_height)\nvoid getWideAngleSize(int &in_wide_angle_width, int &in_wide_angle_height);\n```\n## 定义.cpp\n\n- 结构体数组\n```cpp\ntypedef struct\n{\n    float distCenterX;\n    float distCenterY;\n    float distFocalLength;\n    float distFocalLengthInv;\n    float *lut_d2u;\n    int32_t lut_d2u_indMax;\n    float lut_d2u_step;\n    float lut_d2u_stepInv;\n    float *lut_u2d;\n    int32_t lut_u2d_indMax;\n    float lut_u2d_step;\n    float lut_u2d_stepInv;\n\n    bool if_get_matrix = false;\n    cv::Mat intrinsics = cv::Mat(3, 3, CV_32FC1, cv::Scalar::all(0));\n    cv::Mat distortionCoeff = cv::Mat(4, 1, CV_32FC1, cv::Scalar::all(0));\n} TLensDistortionCorrection;\nTLensDistortionCorrection TLdc[NUM_CAMERAS];\nvoid ParametersInit::getLdc(TLensDistortionCorrection (&in_ldc)[NUM_CAMERAS])\n{\n    for (int i = 0; i < NUM_CAMERAS; i++)\n    {\n        in_ldc[i] = TLdc[i];\n    }\n}\n```\n\n- map\n```cpp\nunsigned short *BEMap = NULL;\nBEMap = (unsigned short *)malloc(sizeof(unsigned short) * BEGetRoiSize * 2 * 2 * 4);\nvoid getBEMap(unsigned short *&in_BEMap)\n{\n    in_BEMap = BEMap;\n}\n\n// cv::Rect\nfor (int rect_index = 0; rect_index < 4; rect_index++)\n{\n    BESetRoi[rect_index] = cv::Rect(BE_set_roi[rect_index * 4 + 0], BE_set_roi[rect_index * 4 + 1],\n                                        BE_set_roi[rect_index * 4 + 2], BE_set_roi[rect_index * 4 + 3]);\n}\nvoid getBESetRoi(cv::Rect *in_BESetRoi)\n{\n    for (int i = 0; i < NUM_CAMERAS; i++)\n    {\n        in_BESetRoi[i] = BESetRoi[i];\n    }\n}\n```\n- cv::Mat []\n```cpp\nfloat *wideAngleViewMap[NUM_CAMERAS] = {NULL};\nfor (int index = 0; index < NUM_CAMERAS; index++)\n{\n    wideAngleViewMap[index] = (float *)malloc(wideAngle_width * wideAngle_height * 3 / 2 * 2 * sizeof(float));\n}\nvoid ParametersInit::getWideAngleMap(float **in_wide_angle_map)\n{\n    for (int i = 0; i < NUM_CAMERAS; i++)\n    {\n        if (wideAngleViewMap[i] != NULL)\n        {\n            in_wide_angle_map[i] = wideAngleViewMap[i];\n        }\n        else\n        {\n            LOGI(1,\"getWideAngleMap failed!\");\n        }\n    }\n}\n```\n\n- int\n```cpp\nint wideAngle_width = 720; //广角视图的尺寸，需要为偶数\nint wideAngle_height = 720;\nvoid ParametersInit::getWideAngleSize(int &in_wide_angle_width, int &in_wide_angle_height)\n{\n    in_wide_angle_width = wideAngle_width;\n    in_wide_angle_height = wideAngle_height;\n}\n```\n\n## 使用.cpp\n```cpp\n// \nTLensDistortionCorrection m_ldc[NUM_CAMERAS];\ngetLdc(my_avm_bsd.m_ldc);\n// \ncv::Mat m_MatK[NUM_CAMERAS];\ngetMatK(my_avm_bsd.m_MatK);\n// \nunsigned short *BE_Map;\ngetBEMap(my_BB_YUV.BE_Map);\n// \ncv::Rect BE_SetRoi[4];\ngetBESetRoi(my_BB_YUV.BE_SetRoi);\n// \nfloat *wide_angle_map[NUM_CAMERAS] = {NULL};\ngetWideAngleMap(g_avm_set->wide_angle_map);\n// \nint m_wideAngle_width;\nint m_wideAngle_height;\ngetWideAngleSize(g_avm_set->m_wideAngle_width, g_avm_set->m_wideAngle_height);\n```\n# 参考网站\n- [C++中引用传递与指针传递区别（进一步整理）](https://www.pudn.com/news/62615ba10e75e420124071b2.html) \n- [二级指针和指针引用函数传参（C++）](https://blog.csdn.net/qq_32483145/article/details/52901230)\n","tags":["C++","函数参数传递","引用与指针"],"categories":["C++"]}]